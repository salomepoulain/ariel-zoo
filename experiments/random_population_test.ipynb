{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f3cd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from collections.abc import Callable\n",
    "from pathlib import Path\n",
    "from typing import Any\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Third-party libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from joblib import Parallel, delayed\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "from networkx import DiGraph\n",
    "from rich.console import Console\n",
    "from rich.progress import track\n",
    "\n",
    "# Local libraries\n",
    "from ariel.body_phenotypes.robogen_lite.config import (\n",
    "    NUM_OF_FACES,\n",
    "    NUM_OF_ROTATIONS,\n",
    "    NUM_OF_TYPES_OF_MODULES,\n",
    ")\n",
    "from ariel.body_phenotypes.robogen_lite.decoders.hi_prob_decoding import (\n",
    "    HighProbabilityDecoder,\n",
    ")\n",
    "from ariel.body_phenotypes.robogen_lite.decoders.visualize_tree import (\n",
    "    visualize_tree_from_graph,\n",
    ")\n",
    "\n",
    "console = Console()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626efb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global constants\n",
    "SCRIPT_NAME = \"Initial\"\n",
    "CWD = Path.cwd()\n",
    "DATA = Path(CWD / \"__data__\" / SCRIPT_NAME)\n",
    "DATA.mkdir(exist_ok=True)\n",
    "SEED = 40\n",
    "\n",
    "# Global functions\n",
    "console = Console()\n",
    "RNG = np.random.default_rng(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81edc0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_body(num_modules: int = 20) -> DiGraph:\n",
    "    \"\"\"Generate random robot with HighProbabilityDecoder.\"\"\"\n",
    "    # System parameters\n",
    "\n",
    "    # \"Type\" probability space\n",
    "    type_probability_space = RNG.random(\n",
    "        size=(num_modules, NUM_OF_TYPES_OF_MODULES),\n",
    "        dtype=np.float32,\n",
    "    )\n",
    "\n",
    "    # \"Connection\" probability space\n",
    "    conn_probability_space = RNG.random(\n",
    "        size=(num_modules, num_modules, NUM_OF_FACES),\n",
    "        dtype=np.float32,\n",
    "    )\n",
    "\n",
    "    # \"Rotation\" probability space\n",
    "    rotation_probability_space = RNG.random(\n",
    "        size=(num_modules, NUM_OF_ROTATIONS),\n",
    "        dtype=np.float32,\n",
    "    )\n",
    "\n",
    "    # Decode the high-probability graph\n",
    "    hpd = HighProbabilityDecoder(num_modules)\n",
    "    hpd.probability_matrices_to_graph(\n",
    "        type_probability_space,\n",
    "        conn_probability_space,\n",
    "        rotation_probability_space,\n",
    "    )\n",
    "\n",
    "    # Decode the high-probability graph\n",
    "    hpd = HighProbabilityDecoder(num_modules)\n",
    "    return hpd.probability_matrices_to_graph(\n",
    "        type_probability_space,\n",
    "        conn_probability_space,\n",
    "        rotation_probability_space,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e4d21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run(\n",
    "#     robot: CoreModule,\n",
    "#     *,\n",
    "#     with_viewer: bool = False,\n",
    "# ) -> None:\n",
    "#     \"\"\"Entry point.\"\"\"\n",
    "#     # MuJoCo configuration\n",
    "#     viz_options = mujoco.MjvOption()  # visualization of various elements\n",
    "\n",
    "#     # Visualization of the corresponding model or decoration element\n",
    "#     viz_options.flags[mujoco.mjtVisFlag.mjVIS_TRANSPARENT] = True\n",
    "#     viz_options.flags[mujoco.mjtVisFlag.mjVIS_ACTUATOR] = True\n",
    "#     viz_options.flags[mujoco.mjtVisFlag.mjVIS_BODYBVH] = True\n",
    "\n",
    "#     # MuJoCo basics\n",
    "#     world = TiltedFlatWorld()\n",
    "\n",
    "#     # Set random colors for geoms\n",
    "#     for i in range(len(robot.spec.geoms)):\n",
    "#         robot.spec.geoms[i].rgba[-1] = 0.5\n",
    "\n",
    "#     # Spawn the robot at the world\n",
    "#     world.spawn(robot.spec)\n",
    "\n",
    "#     # Compile the model\n",
    "#     model = world.spec.compile()\n",
    "#     data = mujoco.MjData(model)\n",
    "\n",
    "#     # Save the model to XML\n",
    "#     xml = world.spec.to_xml()\n",
    "#     with (DATA / f\"{SCRIPT_NAME}.xml\").open(\"w\", encoding=\"utf-8\") as f:\n",
    "#         f.write(xml)\n",
    "\n",
    "#     # Number of actuators and DoFs\n",
    "#     console.log(f\"DoF (model.nv): {model.nv}, Actuators (model.nu): {model.nu}\")\n",
    "\n",
    "#     # Reset state and time of simulation\n",
    "#     mujoco.mj_resetData(model, data)\n",
    "\n",
    "#     # Render\n",
    "#     # single_frame_renderer(model, data, steps=10)\n",
    "\n",
    "#     # View\n",
    "#     if with_viewer:\n",
    "#         viewer.launch(model=model, data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e4673c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delta = 10000  # just a random nr that bigger than 0.1\n",
    "# diversity = 0\n",
    "# nr_of_blocks = []\n",
    "# old_avg_b = 0\n",
    "# old_avg_h = 0\n",
    "# nr_of_hinges = []\n",
    "# learnability = 0  # maybe later\n",
    "# graph_list = []\n",
    "# while delta > 0.00001:\n",
    "#     graph = generate_body()\n",
    "#     graph_list.append(graph)\n",
    "#     graph = dict(graph.nodes)\n",
    "#     hinges = sum(graph[node][\"type\"] == \"HINGE\" for node in graph)\n",
    "#     blocks = sum(graph[node][\"type\"] == \"BRICK\" for node in graph)\n",
    "#     nr_of_blocks.append(blocks)\n",
    "#     nr_of_hinges.append(hinges)\n",
    "\n",
    "#     # skip the first 100\n",
    "#     if len(nr_of_blocks) < 100:\n",
    "#         continue\n",
    "\n",
    "#     # go until we broke\n",
    "#     new_avg_b = np.average(nr_of_blocks)\n",
    "#     new_avg_h = np.average(nr_of_hinges)\n",
    "#     delta = max(abs(old_avg_b - new_avg_b), abs(old_avg_h - new_avg_h))\n",
    "\n",
    "#     if len(graph_list) >= 100_000:\n",
    "#         break\n",
    "\n",
    "#     old_avg_b = new_avg_b\n",
    "#     old_avg_h = new_avg_h\n",
    "\n",
    "# print(\n",
    "#     f\"Done!\\nEnded with a delta of {max(abs(old_avg_b - new_avg_b), abs(old_avg_h - new_avg_h))}\\nThe avg nr of blocks are: {new_avg_b}\\nThe avg nr of hinges is: {new_avg_h}\\nConcluded after {len(graph_list)} generated robots!\"\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48509caa",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a07edc4",
   "metadata": {},
   "source": [
    "### Functions for analysis on individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5d9af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counts(individual: DiGraph) -> dict[str, int]:\n",
    "    counts: dict[str, int] = {\n",
    "        \"core\": sum(\n",
    "            data[\"type\"] == \"CORE\" for _, data in individual.nodes(data=True)\n",
    "        ),\n",
    "        \"brick\": sum(\n",
    "            data[\"type\"] == \"BRICK\" for _, data in individual.nodes(data=True)\n",
    "        ),\n",
    "        \"hinge\": sum(\n",
    "            data[\"type\"] == \"HINGE\" for _, data in individual.nodes(data=True)\n",
    "        ),\n",
    "        \"none\": sum(\n",
    "            data[\"type\"] == \"NONE\" for _, data in individual.nodes(data=True)\n",
    "        ),\n",
    "        \"edges\": len(individual.edges()),\n",
    "    }\n",
    "    counts[\"not-none\"] = counts[\"core\"] + counts[\"brick\"] + counts[\"hinge\"]\n",
    "    assert counts[\"core\"] == 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da2c55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_mass(individual: DiGraph) -> dict[str, float]:\n",
    "    from ariel.body_phenotypes.robogen_lite.modules.brick import (\n",
    "        BRICK_MASS as bm,\n",
    "    )\n",
    "    from ariel.body_phenotypes.robogen_lite.modules.core import CORE_MASS as cm\n",
    "    from ariel.body_phenotypes.robogen_lite.modules.hinge import (\n",
    "        ROTOR_MASS as rm,\n",
    "    )\n",
    "    from ariel.body_phenotypes.robogen_lite.modules.hinge import (\n",
    "        STATOR_MASS as sm,\n",
    "    )\n",
    "\n",
    "    counts = get_counts(individual)\n",
    "    core_mass = counts[\"core\"] * cm\n",
    "    brick_tot_mass = counts[\"brick\"] * bm\n",
    "    hinge_tot_mass = counts[\"hinge\"] * (rm + sm)\n",
    "    total_mass = core_mass + brick_tot_mass + hinge_tot_mass\n",
    "    return {\"mass\": total_mass}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7235f8",
   "metadata": {},
   "source": [
    "### Parallel running method for individual analysis data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb02d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_individual(analyzers, num_modules=None):\n",
    "    individual = generate_body(num_modules) if num_modules else generate_body()\n",
    "    results = {}\n",
    "    results[\"population\"] = [individual]\n",
    "    for analyzer in analyzers:\n",
    "        results.update(analyzer(individual))\n",
    "    return results\n",
    "\n",
    "\n",
    "def analyze_population(\n",
    "    population_size: int,\n",
    "    *,\n",
    "    num_modules: int | None = None,\n",
    "    analyzers: Callable[[DiGraph], dict[str, Any]] | None = None,\n",
    "    n_jobs: int = -1,\n",
    ") -> tuple[dict[str, Any], list[DiGraph]]:\n",
    "    if analyzers is None:\n",
    "        analyzers = [get_counts, analyze_mass]\n",
    "\n",
    "    if n_jobs == -1:\n",
    "        available_cpus = os.cpu_count()\n",
    "        if available_cpus is not None and available_cpus > 2:\n",
    "            n_jobs = available_cpus - 2\n",
    "        elif available_cpus is not None and available_cpus > 1:\n",
    "            n_jobs = available_cpus - 1\n",
    "        else:\n",
    "            n_jobs = 1\n",
    "\n",
    "    console.log(f\"Using {n_jobs} cpus\")\n",
    "    console.log(f\"Starting analysis of {population_size} individuals...\")\n",
    "\n",
    "    # Parallel execution with progress bar\n",
    "    with Parallel(n_jobs=n_jobs) as parallel:\n",
    "        results = parallel(\n",
    "            delayed(analyze_individual)(analyzers)\n",
    "            for _ in track(\n",
    "                range(population_size), description=\"Analyzing population\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "    properties_dict = defaultdict(list)\n",
    "    for result in results:\n",
    "        for key, value in result.items():\n",
    "            properties_dict[key].append(value)\n",
    "\n",
    "    console.log(\"Analysis complete.\")\n",
    "    final_dict = dict(properties_dict)\n",
    "    population = final_dict.pop(\"population\")\n",
    "    return final_dict, population"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0cbe07",
   "metadata": {},
   "source": [
    "### Visualization methods for the analysis on a population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1693e9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_boxplot_from_dict(\n",
    "    properties_dict: dict[str, Any], keys: list[str] | None = None\n",
    ") -> None:\n",
    "    # If no keys provided, plot all except 'population'\n",
    "    if keys is None:\n",
    "        keys = list(properties_dict.keys())\n",
    "    # Prepare data for seaborn\n",
    "    data = []\n",
    "    labels = []\n",
    "    for key in keys:\n",
    "        if key in properties_dict:\n",
    "            data.append(properties_dict[key])\n",
    "            labels.append(key)\n",
    "    # Create boxplot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(data=data)\n",
    "    plt.xticks(ticks=range(len(labels)), labels=labels)\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.title(\"Boxplot of Robot Properties\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0ddcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_histogram_from_dict(\n",
    "    properties_dict: dict[str, Any],\n",
    "    keys: list[str] | None = None,\n",
    "    bins: int = 30,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Draw a grouped histogram of the selected keys.\n",
    "    Title is the key names if there are fewer than 3,\n",
    "    otherwise \"Histogram of Robot Properties\".\n",
    "    \"\"\"\n",
    "    if keys is None:\n",
    "        keys = list(properties_dict.keys())\n",
    "\n",
    "    # Keep only keys that exist in the dictionary\n",
    "    valid_keys = [k for k in keys if k in properties_dict]\n",
    "    data = [properties_dict[k] for k in valid_keys]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    counts, bins, _patches = plt.hist(\n",
    "        data,\n",
    "        bins=bins,\n",
    "        label=valid_keys,\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=1.2,\n",
    "        alpha=0.8,\n",
    "        histtype=\"bar\",\n",
    "        rwidth=0.9,\n",
    "    )\n",
    "    total = counts.sum()\n",
    "    plt.gca().yaxis.set_major_formatter(PercentFormatter(xmax=total))\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "\n",
    "    # Dynamic title\n",
    "    if len(valid_keys) <= 3:\n",
    "        plt.title(\", \".join(valid_keys))\n",
    "    else:\n",
    "        plt.title(\"Histogram of Robot Properties\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5858fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistical_data_from_dict(\n",
    "    properties_dict: dict[str, Any],\n",
    "    keys: list[str] | None = None,\n",
    "    save_file: Path | str | None = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each numeric key in properties_dict, return a DataFrame with:\n",
    "      mean, std, median, count,\n",
    "      Q1, Q3,\n",
    "      list of outlier indexes (Tukey's method),\n",
    "      number of outliers.\n",
    "    \"\"\"\n",
    "    if keys is None:\n",
    "        keys = [k for k in properties_dict if k != \"population\"]\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for key in keys:\n",
    "        if key not in properties_dict:\n",
    "            continue\n",
    "\n",
    "        arr = np.asarray(properties_dict[key], dtype=float)\n",
    "\n",
    "        if arr.size == 0:\n",
    "            continue  # skip empty arrays\n",
    "\n",
    "        mean = arr.mean()\n",
    "        std = arr.std(ddof=1)\n",
    "        median = np.median(arr)\n",
    "        q1 = np.percentile(arr, 25)\n",
    "        q3 = np.percentile(arr, 75)\n",
    "        iqr = q3 - q1\n",
    "\n",
    "        # Tukey's fences for outliers (same as seaborn)\n",
    "        lower = q1 - 1.5 * iqr\n",
    "        upper = q3 + 1.5 * iqr\n",
    "        outlier_indexes = np.where((arr < lower) | (arr > upper))[0].tolist()\n",
    "\n",
    "        results.append({\n",
    "            \"key\": key,\n",
    "            \"count\": len(arr),\n",
    "            \"mean\": mean,\n",
    "            \"std\": std,\n",
    "            \"median\": median,\n",
    "            \"Q1\": q1,\n",
    "            \"Q3\": q3,\n",
    "            \"num_outliers\": len(outlier_indexes),\n",
    "            \"outlier_indexes\": outlier_indexes,\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "\n",
    "    if save_file:\n",
    "        df.to_csv(save_file)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf37376",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519c7521",
   "metadata": {},
   "source": [
    "### Running the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56489ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "properties_dict, population = analyze_population(100_000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a052ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_boxplot_from_dict(properties_dict)\n",
    "\n",
    "create_histogram_from_dict(properties_dict, keys=[\"brick\", \"hinge\", \"none\"])\n",
    "create_histogram_from_dict(properties_dict, keys=[\"not-none\"])\n",
    "create_histogram_from_dict(properties_dict, keys=[\"mass\"])\n",
    "create_histogram_from_dict(properties_dict, keys=[\"edges\"])\n",
    "\n",
    "stats_df = statistical_data_from_dict(properties_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e91cf25",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6468e55b",
   "metadata": {},
   "source": [
    "### Visualize Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2c7ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(properties_dict.keys())\n",
    "\n",
    "\n",
    "# Compute keys_with_outliers once and use for key_index logic\n",
    "def get_keys_with_outliers():\n",
    "    outlier_keys = []\n",
    "    for key in keys:\n",
    "        outlier_row = stats_df[stats_df[\"key\"] == key]\n",
    "        total_outliers = (\n",
    "            len(outlier_row.iloc[0][\"outlier_indexes\"])\n",
    "            if not outlier_row.empty\n",
    "            else 0\n",
    "        )\n",
    "        if total_outliers > 0:\n",
    "            outlier_keys.append(key)\n",
    "    return outlier_keys\n",
    "\n",
    "\n",
    "# Use keys_with_outliers for key_index, but keep all keys for lookup\n",
    "if \"keys_with_outliers\" not in globals():\n",
    "    keys_with_outliers = get_keys_with_outliers()\n",
    "if \"key_index\" not in globals():\n",
    "    key_index = 0  # Tracks current key (in keys_with_outliers)\n",
    "if \"outlier_index\" not in globals():\n",
    "    outlier_index = 0  # Tracks index in outlier list\n",
    "if \"direction\" not in globals():\n",
    "    direction = 1  # 1 for forward, -1 for backward\n",
    "\n",
    "\n",
    "def select_key(delta=1) -> None:\n",
    "    \"\"\"Cycle through keys with outliers only, highlight current, and show total outliers for each key.\"\"\"\n",
    "    global key_index, outlier_index, keys_with_outliers\n",
    "    keys_with_outliers = get_keys_with_outliers()\n",
    "    outlier_counts = []\n",
    "    for key in keys_with_outliers:\n",
    "        outlier_row = stats_df[stats_df[\"key\"] == key]\n",
    "        total_outliers = (\n",
    "            len(outlier_row.iloc[0][\"outlier_indexes\"])\n",
    "            if not outlier_row.empty\n",
    "            else 0\n",
    "        )\n",
    "        outlier_counts.append(total_outliers)\n",
    "\n",
    "    if not keys_with_outliers:\n",
    "        console.print(\"[red]No keys with outliers found.[/red]\")\n",
    "        return\n",
    "\n",
    "    key_index = (key_index + delta) % len(keys_with_outliers)\n",
    "    outlier_index = 0  # Reset outlier index when changing key\n",
    "\n",
    "    key_lines = []\n",
    "    for i, (key, total_outliers) in enumerate(\n",
    "        zip(keys_with_outliers, outlier_counts, strict=False)\n",
    "    ):\n",
    "        if i == key_index:\n",
    "            key_lines.append(\n",
    "                f\"[bold green]> {key} <[/bold green] [yellow]({total_outliers} outliers)[/yellow]\",\n",
    "            )\n",
    "        else:\n",
    "            key_lines.append(\n",
    "                f\"{key} [dim]({total_outliers} outliers)[/dim]\",\n",
    "            )\n",
    "    console.print(\"\\n\".join(key_lines))\n",
    "    # show_current_selection()\n",
    "\n",
    "\n",
    "def toggle_direction() -> None:\n",
    "    \"\"\"Toggle direction for cycling outlier indexes.\"\"\"\n",
    "    global direction\n",
    "    direction = -direction\n",
    "    console.print(\n",
    "        f\"[cyan]Direction toggled. Now: {'forward' if direction == 1 else 'backward'}[/cyan]\"\n",
    "    )\n",
    "\n",
    "\n",
    "def get_outlier_list():\n",
    "    # Use keys_with_outliers for key_index\n",
    "    key = keys_with_outliers[key_index]\n",
    "    outlier_row = stats_df[stats_df[\"key\"] == key]\n",
    "    if not outlier_row.empty:\n",
    "        return outlier_row.iloc[0][\"outlier_indexes\"]\n",
    "    return []\n",
    "\n",
    "\n",
    "def cycle_through_outlier_index():\n",
    "    \"\"\"Cycle through outlier indexes for the selected key.\"\"\"\n",
    "    global outlier_index\n",
    "    outliers = get_outlier_list()\n",
    "    if outliers:\n",
    "        outlier_index = (outlier_index + direction) % len(outliers)\n",
    "    show_current_selection()\n",
    "    return get_current_outlier_value()\n",
    "\n",
    "\n",
    "def show_current_selection() -> None:\n",
    "    key = keys_with_outliers[key_index]\n",
    "    outliers = get_outlier_list()\n",
    "    total = len(outliers)\n",
    "    if outliers:\n",
    "        idx = outlier_index % total\n",
    "        progress_str = f\"[{idx + 1}/{total}]\"\n",
    "        console.print(\n",
    "            f\"[bold green]Key:[/bold green] {key} | \"\n",
    "            f\"[blue]Outlier index:[/blue] {idx} {progress_str} | \"\n",
    "            f\"[magenta]Value:[/magenta] {outliers[idx]} | \"\n",
    "            f\"[yellow]Total outliers:[/yellow] {total}\",\n",
    "        )\n",
    "    else:\n",
    "        console.print(\n",
    "            f\"[bold green]Key:[/bold green] {key} | [red]No outliers[/red]\"\n",
    "        )\n",
    "\n",
    "\n",
    "def get_current_outlier_value():\n",
    "    \"\"\"Return the value of the current outlier for the selected key.\"\"\"\n",
    "    outliers = get_outlier_list()\n",
    "    if outliers:\n",
    "        return outliers[outlier_index % len(outliers)]\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535ed35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cf49e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "toggle_direction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a355d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_tree_from_graph(population[cycle_through_outlier_index()][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a9be5e",
   "metadata": {},
   "source": [
    "The exeperiment shows that the outliers seem to have the same genotype. This leads to the question for how many unique genotypes are actually being created. To run this experiment, a new function should be created that easily parses the given phenotype into a deterministic string. this can than be used in a histogram to count the unique types?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0553e5a1",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21b088e",
   "metadata": {},
   "source": [
    "### To be implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a39d82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_branching(individual: DiGraph) -> dict[str, float]:\n",
    "    \"\"\"\n",
    "    Measures the level of branching in the robot's morphology (M1).\n",
    "\n",
    "    Calculation Method: The specific formula for 'Branching' (M1) is not detailed in this source material,\n",
    "    but it is noted that this descriptor ranges in value from 0 to 1 [1].\n",
    "    This descriptor is positively correlated with the 'Number of Limbs' [2].\n",
    "    \"\"\"\n",
    "    return {\"branching\": 0.0}\n",
    "\n",
    "\n",
    "def analyze_number_of_limbs(individual: DiGraph) -> dict[str, float]:\n",
    "    \"\"\"\n",
    "    Measures the number of effective limbs attached to the robot (M2).\n",
    "\n",
    "    Calculation Method: The specific formula for 'Number of Limbs' (M2) is not detailed in this source material,\n",
    "    but it is noted that this descriptor ranges in value from 0 to 1 [1].\n",
    "    It is used to assess the tendency for morphologies to have few limbs [2, 3].\n",
    "    \"\"\"\n",
    "    return {\"number_of_limbs\": 0.0}\n",
    "\n",
    "\n",
    "def analyze_length_of_limbs(individual: DiGraph) -> dict[str, float]:\n",
    "    \"\"\"\n",
    "    Measures the relative length of the limbs (M3).\n",
    "\n",
    "    Calculation Method: The measure 'Length of Limbs' (E or M3) is defined by the following equation\n",
    "    (used, for example, in the S3 fitness function as a penalty) [4]:\n",
    "\n",
    "    E = { e / e_max, if m >= 3\n",
    "        { 0, otherwise\n",
    "\n",
    "    Where 'm' is the total number of modules in the body, 'e' is the number of modules\n",
    "    which have two of their faces attached to other modules (excluding the core-component),\n",
    "    and 'e_max' is the maximum amount of modules that a body with 'm' modules could have\n",
    "    with two attached faces, calculated as m - 2 [4].\n",
    "    A higher value suggests fewer, longer limbs, as it rewards maximizing the length relative to body size [2, 3].\n",
    "    This descriptor ranges in value from 0 to 1 [1].\n",
    "    \"\"\"\n",
    "    return {\"length_of_limbs\": 0.0}\n",
    "\n",
    "\n",
    "def analyze_coverage(individual: DiGraph) -> dict[str, float]:\n",
    "    \"\"\"\n",
    "    Measures how much of the morphology space is covered (M4).\n",
    "\n",
    "    Calculation Method: The specific formula for 'Coverage' (M4) is not detailed in this source material,\n",
    "    but it is noted that this descriptor ranges in value from 0 to 1 [1].\n",
    "    Morphologies similar to snakes (like those predominant under S1 fitness) tended to have high coverage,\n",
    "    covering the whole body area [5].\n",
    "    \"\"\"\n",
    "    return {\"coverage\": 0.0}\n",
    "\n",
    "\n",
    "def analyze_joints(individual: DiGraph) -> dict[str, float]:\n",
    "    \"\"\"\n",
    "    Measures the number of effective joints in the morphology (M5).\n",
    "\n",
    "    Calculation Method: This descriptor was reformulated for the study.\n",
    "    The concept of an effective joint is defined by a joint module that is attached to any other module type [1].\n",
    "    (Previously, attachment was required to be specifically to the core-component or a structural brick [1, 6].)\n",
    "    This reformulation was done because robots were often observed developing limbs purely formed by a sequence of joints [1].\n",
    "    The descriptor ranges in value from 0 to 1 [1].\n",
    "    \"\"\"\n",
    "    return {\"joints\": 0.0}\n",
    "\n",
    "\n",
    "def analyze_proportion(individual: DiGraph) -> dict[str, float]:\n",
    "    \"\"\"\n",
    "    Measures the proportionality or balance of the robot's shape (M6).\n",
    "\n",
    "    Calculation Method: The specific formula for 'Proportion' (M6) is not detailed in this source material,\n",
    "    but it is noted that this descriptor ranges in value from 0 to 1 [1].\n",
    "    Proportion was observed to drop drastically for fitness S1, which was dominated by single-limb, disproportional robots [5].\n",
    "    \"\"\"\n",
    "    return {\"proportion\": 0.0}\n",
    "\n",
    "\n",
    "def analyze_symmetry(individual: DiGraph) -> dict[str, float]:\n",
    "    \"\"\"\n",
    "    Measures the symmetry of the robot's structure (M7).\n",
    "\n",
    "    Calculation Method: The specific formula for 'Symmetry' (M7) is not detailed in this source material,\n",
    "    but it is noted that this descriptor ranges in value from 0 to 1 [1].\n",
    "    Symmetry tended to be higher when a penalty for long limbs (S3 fitness) was applied [7].\n",
    "    The results suggest that higher symmetry is correlated with lower average speed [8].\n",
    "    \"\"\"\n",
    "    return {\"symmetry\": 0.0}\n",
    "\n",
    "\n",
    "def analyze_size(individual: DiGraph) -> dict[str, float]:\n",
    "    \"\"\"\n",
    "    Measures the overall size of the robot's morphology (M8).\n",
    "\n",
    "    Calculation Method: The specific formula for 'Size' (M8) is not detailed in this source material,\n",
    "    but it is noted that this descriptor ranges in value from 0 to 1 [1].\n",
    "    All behavior-oriented searches tended to explore larger Size, as a large body can more easily produce a large displacement for high speed [5].\n",
    "    \"\"\"\n",
    "    return {\"size\": 0.0}\n",
    "\n",
    "\n",
    "def analyze_sensors(individual: DiGraph) -> dict[str, float]:\n",
    "    \"\"\"\n",
    "    Measures the ratio of sensors to available slots in the morphology (M9).\n",
    "\n",
    "    Calculation Method: This is a new descriptor introduced in the study [1]. It is defined by the equation [9]:\n",
    "\n",
    "    C = { c / c_max, if c_max > 0\n",
    "        { 0, otherwise\n",
    "\n",
    "    Where 'c' is the number of sensors in the morphology, and 'c_max' is the number of free slots in the morphology [9].\n",
    "    The descriptor ranges in value from 0 to 1 [1].\n",
    "    \"\"\"\n",
    "    return {\"sensors\": 0.0}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ariel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
