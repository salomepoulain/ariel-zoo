{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f3cd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library\n",
    "import json\n",
    "import os\n",
    "from collections import Counter, defaultdict\n",
    "from collections.abc import Callable\n",
    "from hashlib import sha256\n",
    "from pathlib import Path\n",
    "from typing import Any, Never\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Third-party libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from joblib import Parallel, delayed\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "from networkx import DiGraph\n",
    "from rich.console import Console\n",
    "from rich.progress import track\n",
    "\n",
    "from ariel.body_phenotypes.robogen_lite.config import (\n",
    "    NUM_OF_FACES,\n",
    "    NUM_OF_ROTATIONS,\n",
    "    NUM_OF_TYPES_OF_MODULES,\n",
    ")\n",
    "from ariel.body_phenotypes.robogen_lite.decoders.hi_prob_decoding import (\n",
    "    HighProbabilityDecoder,\n",
    ")\n",
    "from ariel.body_phenotypes.robogen_lite.decoders.visualize_tree import (\n",
    "    visualize_tree_from_graph,\n",
    ")\n",
    "\n",
    "# Local libraries\n",
    "from ariel.body_phenotypes.robogen_lite.modules.brick import BRICK_MASS\n",
    "from ariel.body_phenotypes.robogen_lite.modules.core import CORE_MASS\n",
    "from ariel.body_phenotypes.robogen_lite.modules.hinge import (\n",
    "    ROTOR_MASS,\n",
    "    STATOR_MASS,\n",
    ")\n",
    "\n",
    "console = Console()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626efb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global constants\n",
    "SCRIPT_NAME = \"Initial\"\n",
    "CWD = Path.cwd()\n",
    "DATA = Path(CWD / \"__data__\" / SCRIPT_NAME)\n",
    "DATA.mkdir(exist_ok=True)\n",
    "SEED = 40\n",
    "\n",
    "# Global functions\n",
    "console = Console()\n",
    "RNG = np.random.default_rng(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81edc0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_body(num_modules: int = 20) -> DiGraph:\n",
    "    \"\"\"Generate random robot with HighProbabilityDecoder.\"\"\"\n",
    "    # System parameters\n",
    "\n",
    "    # \"Type\" probability space\n",
    "    type_probability_space = RNG.random(\n",
    "        size=(num_modules, NUM_OF_TYPES_OF_MODULES),\n",
    "        dtype=np.float32,\n",
    "    )\n",
    "\n",
    "    # \"Connection\" probability space\n",
    "    conn_probability_space = RNG.random(\n",
    "        size=(num_modules, num_modules, NUM_OF_FACES),\n",
    "        dtype=np.float32,\n",
    "    )\n",
    "\n",
    "    # \"Rotation\" probability space\n",
    "    rotation_probability_space = RNG.random(\n",
    "        size=(num_modules, NUM_OF_ROTATIONS),\n",
    "        dtype=np.float32,\n",
    "    )\n",
    "\n",
    "    # Decode the high-probability graph\n",
    "    hpd = HighProbabilityDecoder(num_modules)\n",
    "    hpd.probability_matrices_to_graph(\n",
    "        type_probability_space,\n",
    "        conn_probability_space,\n",
    "        rotation_probability_space,\n",
    "    )\n",
    "\n",
    "    # Decode the high-probability graph\n",
    "    hpd = HighProbabilityDecoder(num_modules)\n",
    "    return hpd.probability_matrices_to_graph(\n",
    "        type_probability_space,\n",
    "        conn_probability_space,\n",
    "        rotation_probability_space,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e4d21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run(\n",
    "#     robot: CoreModule,\n",
    "#     *,\n",
    "#     with_viewer: bool = False,\n",
    "# ) -> None:\n",
    "#     \"\"\"Entry point.\"\"\"\n",
    "#     # MuJoCo configuration\n",
    "#     viz_options = mujoco.MjvOption()  # visualization of various elements\n",
    "\n",
    "#     # Visualization of the corresponding model or decoration element\n",
    "#     viz_options.flags[mujoco.mjtVisFlag.mjVIS_TRANSPARENT] = True\n",
    "#     viz_options.flags[mujoco.mjtVisFlag.mjVIS_ACTUATOR] = True\n",
    "#     viz_options.flags[mujoco.mjtVisFlag.mjVIS_BODYBVH] = True\n",
    "\n",
    "#     # MuJoCo basics\n",
    "#     world = TiltedFlatWorld()\n",
    "\n",
    "#     # Set random colors for geoms\n",
    "#     for i in range(len(robot.spec.geoms)):\n",
    "#         robot.spec.geoms[i].rgba[-1] = 0.5\n",
    "\n",
    "#     # Spawn the robot at the world\n",
    "#     world.spawn(robot.spec)\n",
    "\n",
    "#     # Compile the model\n",
    "#     model = world.spec.compile()\n",
    "#     data = mujoco.MjData(model)\n",
    "\n",
    "#     # Save the model to XML\n",
    "#     xml = world.spec.to_xml()\n",
    "#     with (DATA / f\"{SCRIPT_NAME}.xml\").open(\"w\", encoding=\"utf-8\") as f:\n",
    "#         f.write(xml)\n",
    "\n",
    "#     # Number of actuators and DoFs\n",
    "#     console.log(f\"DoF (model.nv): {model.nv}, Actuators (model.nu): {model.nu}\")\n",
    "\n",
    "#     # Reset state and time of simulation\n",
    "#     mujoco.mj_resetData(model, data)\n",
    "\n",
    "#     # Render\n",
    "#     # single_frame_renderer(model, data, steps=10)\n",
    "\n",
    "#     # View\n",
    "#     if with_viewer:\n",
    "#         viewer.launch(model=model, data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e4673c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delta = 10000  # just a random nr that bigger than 0.1\n",
    "# diversity = 0\n",
    "# nr_of_blocks = []\n",
    "# old_avg_b = 0\n",
    "# old_avg_h = 0\n",
    "# nr_of_hinges = []\n",
    "# learnability = 0  # maybe later\n",
    "# graph_list = []\n",
    "# while delta > 0.00001:\n",
    "#     graph = generate_body()\n",
    "#     graph_list.append(graph)\n",
    "#     graph = dict(graph.nodes)\n",
    "#     hinges = sum(graph[node][\"type\"] == \"HINGE\" for node in graph)\n",
    "#     blocks = sum(graph[node][\"type\"] == \"BRICK\" for node in graph)\n",
    "#     nr_of_blocks.append(blocks)\n",
    "#     nr_of_hinges.append(hinges)\n",
    "\n",
    "#     # skip the first 100\n",
    "#     if len(nr_of_blocks) < 100:\n",
    "#         continue\n",
    "\n",
    "#     # go until we broke\n",
    "#     new_avg_b = np.average(nr_of_blocks)\n",
    "#     new_avg_h = np.average(nr_of_hinges)\n",
    "#     delta = max(abs(old_avg_b - new_avg_b), abs(old_avg_h - new_avg_h))\n",
    "\n",
    "#     if len(graph_list) >= 100_000:\n",
    "#         break\n",
    "\n",
    "#     old_avg_b = new_avg_b\n",
    "#     old_avg_h = new_avg_h\n",
    "\n",
    "# print(\n",
    "#     f\"Done!\\nEnded with a delta of {max(abs(old_avg_b - new_avg_b), abs(old_avg_h - new_avg_h))}\\nThe avg nr of blocks are: {new_avg_b}\\nThe avg nr of hinges is: {new_avg_h}\\nConcluded after {len(graph_list)} generated robots!\"\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48509caa",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a07edc4",
   "metadata": {},
   "source": [
    "### Functions for analysis on individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5d9af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_module_counts(individual: DiGraph) -> dict[str, int]:\n",
    "    counts: dict[str, int] = {\n",
    "        \"core\": sum(\n",
    "            data[\"type\"] == \"CORE\" for _, data in individual.nodes(data=True)\n",
    "        ),\n",
    "        \"brick\": sum(\n",
    "            data[\"type\"] == \"BRICK\" for _, data in individual.nodes(data=True)\n",
    "        ),\n",
    "        \"hinge\": sum(\n",
    "            data[\"type\"] == \"HINGE\" for _, data in individual.nodes(data=True)\n",
    "        ),\n",
    "        \"none\": sum(\n",
    "            data[\"type\"] == \"NONE\" for _, data in individual.nodes(data=True)\n",
    "        ),\n",
    "        \"edges\": len(individual.edges()),\n",
    "    }\n",
    "    counts[\"not-none\"] = counts[\"core\"] + counts[\"brick\"] + counts[\"hinge\"]\n",
    "    assert counts[\"core\"] == 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da2c55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_mass(individual: DiGraph) -> dict[str, float]:\n",
    "    counts = analyze_module_counts(individual)\n",
    "    core_mass = counts[\"core\"] * CORE_MASS\n",
    "    brick_tot_mass = counts[\"brick\"] * BRICK_MASS\n",
    "    hinge_tot_mass = counts[\"hinge\"] * (ROTOR_MASS + STATOR_MASS)\n",
    "    total_mass = core_mass + brick_tot_mass + hinge_tot_mass\n",
    "    return {\"mass\": total_mass}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd620555",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_json_hash(individual: DiGraph) -> dict[str, str]:\n",
    "    \"\"\"Return a SHA-256 hash of a deterministic representation of the graph.\"\"\"\n",
    "    # Collect nodes and edges with attributes, sorted for determinism\n",
    "    nodes = sorted([(n, dict(individual.nodes[n])) for n in individual.nodes()])\n",
    "    edges = sorted([\n",
    "        (u, v, dict(individual.edges[u, v])) for u, v in individual.edges()\n",
    "    ])\n",
    "    # Create a canonical dict\n",
    "    canonical = {\"nodes\": nodes, \"edges\": edges}\n",
    "    # Hash the canonical JSON string\n",
    "    hash_string = sha256(\n",
    "        json.dumps(canonical, sort_keys=True).encode(\"utf-8\"),\n",
    "    ).hexdigest()\n",
    "    return {\"hash\": hash_string}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7235f8",
   "metadata": {},
   "source": [
    "### Parallel running method for individual analysis data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb02d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_individual(\n",
    "    analyzers: Callable[[DiGraph], dict[str, Any]], num_modules=None,\n",
    "):\n",
    "    individual = generate_body(num_modules) if num_modules else generate_body()\n",
    "    results = {\"population\": [individual]}\n",
    "    for analyzer in analyzers:\n",
    "        results.update(analyzer(individual))\n",
    "    return results\n",
    "\n",
    "\n",
    "def analyze_population(\n",
    "    population_size: int,\n",
    "    *,\n",
    "    num_modules: int | None = None,\n",
    "    analyzers: Callable[[DiGraph], dict[str, Any]] | None = None,\n",
    "    n_jobs: int = -1,\n",
    ") -> tuple[dict[str, Any], list[DiGraph]]:\n",
    "    if analyzers is None:\n",
    "        analyzers = [analyze_module_counts, analyze_mass, analyze_json_hash]\n",
    "\n",
    "    if n_jobs != 1:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    if n_jobs == -1:\n",
    "        available_cpus = os.cpu_count()\n",
    "        if available_cpus is not None and available_cpus > 2:\n",
    "            n_jobs = available_cpus - 2\n",
    "        elif available_cpus is not None and available_cpus > 1:\n",
    "            n_jobs = available_cpus - 1\n",
    "        else:\n",
    "            n_jobs = 1\n",
    "\n",
    "    console.log(f\"Using {n_jobs} cpu(s)\")\n",
    "    console.log(f\"Starting analysis of {population_size} individuals...\")\n",
    "\n",
    "    # Parallel execution with progress bar\n",
    "    with Parallel(n_jobs=n_jobs) as parallel:\n",
    "        results = parallel(\n",
    "            delayed(analyze_individual)(analyzers)\n",
    "            for _ in track(\n",
    "                range(population_size),\n",
    "                description=\"Analyzing population\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "    properties_dict = defaultdict(list)\n",
    "    # cast(results, dict)\n",
    "    for result in results:\n",
    "        for key, value in result.items():\n",
    "            properties_dict[key].append(value)\n",
    "\n",
    "    console.log(\"Analysis complete.\")\n",
    "    final_dict = dict(properties_dict)\n",
    "    population = final_dict.pop(\"population\")\n",
    "    return final_dict, population"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0cbe07",
   "metadata": {},
   "source": [
    "### Visualization methods for the analysis on a population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1693e9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_boxplot_from_dict(\n",
    "    properties_dict: dict[str, Any],\n",
    "    keys: list[str] | None = None,\n",
    ") -> None:\n",
    "    # If no keys provided, plot all except 'population'\n",
    "    if keys is None:\n",
    "        keys = list(properties_dict.keys())\n",
    "    # Prepare data for seaborn\n",
    "    data = []\n",
    "    labels = []\n",
    "    for key in keys:\n",
    "        if key in properties_dict:\n",
    "            data.append(properties_dict[key])\n",
    "            labels.append(key)\n",
    "    # Create boxplot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(data=data)\n",
    "    plt.xticks(ticks=range(len(labels)), labels=labels)\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.title(\"Boxplot of Robot Properties\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9596215f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_histogram_from_dict(\n",
    "    properties_dict: dict[str, Any],\n",
    "    keys: list[str] | None = None,\n",
    "    bins: int = 30,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Draw a grouped histogram of the selected keys.\n",
    "    For string-valued keys (e.g., hashes), plot the distribution of their frequencies (separately).\n",
    "    For numeric keys, plot all together in one histogram.\n",
    "    Title is the key names if there are fewer than 3, otherwise \"Histogram of Robot Properties\".\n",
    "    \"\"\"\n",
    "    if keys is None:\n",
    "        keys = list(properties_dict.keys())\n",
    "\n",
    "    valid_keys = [k for k in keys if k in properties_dict]\n",
    "\n",
    "    # Check if all selected keys are numeric\n",
    "    if all(isinstance(properties_dict[k][0], (int, float)) for k in valid_keys):\n",
    "        # Plot all numeric keys together\n",
    "        data = [properties_dict[k] for k in valid_keys]\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        n, bins_, _patches = plt.hist(\n",
    "            data,\n",
    "            bins=bins,\n",
    "            label=valid_keys,\n",
    "            edgecolor=\"black\",\n",
    "            linewidth=1.2,\n",
    "            alpha=0.8,\n",
    "            histtype=\"bar\",\n",
    "            rwidth=0.9,\n",
    "        )\n",
    "        total = n.sum()\n",
    "        plt.gca().yaxis.set_major_formatter(PercentFormatter(xmax=total))\n",
    "        plt.xlabel(\"Value\")\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        plt.legend()\n",
    "        plt.title(\n",
    "            \", \".join(valid_keys)\n",
    "            if len(valid_keys) <= 3\n",
    "            else \"Histogram of Robot Properties\",\n",
    "        )\n",
    "        plt.show()\n",
    "    else:\n",
    "        # Plot string-valued keys separately\n",
    "        for key in valid_keys:\n",
    "            values = properties_dict[key]\n",
    "            if not values:\n",
    "                continue\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            if isinstance(values[0], str):\n",
    "                counts = Counter(values)\n",
    "                freqs = list(counts.values())\n",
    "                n, bins_, _patches = plt.hist(\n",
    "                    freqs,\n",
    "                    bins=bins,\n",
    "                    edgecolor=\"black\",\n",
    "                    linewidth=1.2,\n",
    "                    alpha=0.8,\n",
    "                    rwidth=0.9,\n",
    "                    label=[key],\n",
    "                    histtype=\"bar\",\n",
    "                )\n",
    "                total = n.sum()\n",
    "                plt.gca().yaxis.set_major_formatter(\n",
    "                    PercentFormatter(xmax=total),\n",
    "                )\n",
    "                plt.xlabel(\"Genotype frequency\")\n",
    "                plt.ylabel(\"Number of unique genotypes\")\n",
    "                plt.title(key)\n",
    "                plt.legend()\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a628ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistical_df_from_dict(\n",
    "    properties_dict: dict[str, Any],\n",
    "    keys: list[str] | None = None,\n",
    "    save_file: Path | str | None = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each key in properties_dict:\n",
    "      - If numeric: mean, std, median, count, Q1, Q3, outlier indexes, num_outliers, uniques.\n",
    "      - If non-numeric: key, count, uniques.\n",
    "    Returns a DataFrame with correct dtypes.\n",
    "    \"\"\"\n",
    "    if keys is None:\n",
    "        keys = list(properties_dict)\n",
    "\n",
    "    rows = []\n",
    "    for key in keys:\n",
    "        values = properties_dict[key]\n",
    "        if not values:\n",
    "            continue\n",
    "        uniques = len(set(values))\n",
    "        if isinstance(values[0], (float, int)):\n",
    "            arr = np.asarray(values, dtype=float)\n",
    "            mean = arr.mean()\n",
    "            std = arr.std(ddof=1)\n",
    "            median = np.median(arr)\n",
    "            q1 = np.percentile(arr, 25)\n",
    "            q3 = np.percentile(arr, 75)\n",
    "            iqr = q3 - q1\n",
    "            lower = q1 - 1.5 * iqr\n",
    "            upper = q3 + 1.5 * iqr\n",
    "            outlier_indexes = np.where((arr < lower) | (arr > upper))[\n",
    "                0\n",
    "            ].tolist()\n",
    "            row = {\n",
    "                \"key\": key,\n",
    "                \"count\": len(arr),\n",
    "                \"uniques\": int(uniques),\n",
    "                \"mean\": float(mean),\n",
    "                \"std\": float(std),\n",
    "                \"median\": float(median),\n",
    "                \"Q1\": float(q1),\n",
    "                \"Q3\": float(q3),\n",
    "                \"num_outliers\": len(outlier_indexes),\n",
    "                \"outlier_indexes\": outlier_indexes,\n",
    "            }\n",
    "        else:\n",
    "            row = {\n",
    "                \"key\": key,\n",
    "                \"count\": len(values),\n",
    "                \"uniques\": int(uniques),\n",
    "                \"mean\": None,\n",
    "                \"std\": None,\n",
    "                \"median\": None,\n",
    "                \"Q1\": None,\n",
    "                \"Q3\": None,\n",
    "                \"num_outliers\": None,\n",
    "                \"outlier_indexes\": None,\n",
    "            }\n",
    "        rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame.from_records(rows)\n",
    "    df = df.set_index(\"key\")\n",
    "\n",
    "    # Set dtypes explicitly\n",
    "    df[\"count\"] = df[\"count\"].astype(\"Int64\")\n",
    "    df[\"uniques\"] = df[\"uniques\"].astype(\"Int64\")\n",
    "    for col in [\"mean\", \"std\", \"median\", \"Q1\", \"Q3\"]:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    df[\"num_outliers\"] = df[\"num_outliers\"].astype(\"Int64\")\n",
    "    df[\"outlier_indexes\"] = df[\"outlier_indexes\"].astype(object)\n",
    "\n",
    "    if save_file:\n",
    "        df.to_csv(save_file)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63223e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_df_from_list(value_list: list[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns a DataFrame with:\n",
    "      - index: hash value\n",
    "      - count: number of times the hash appears\n",
    "      - indexes: list of indexes in the original list where the hash appears.\n",
    "    \"\"\"\n",
    "    index_dict = defaultdict(list)\n",
    "    for idx, h in enumerate(value_list):\n",
    "        index_dict[h].append(idx)\n",
    "\n",
    "    results = []\n",
    "    for h, idxs in index_dict.items():\n",
    "        results.append({\n",
    "            \"value\": h,\n",
    "            \"count\": len(idxs),\n",
    "            \"indexes\": idxs,\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    return df.set_index(\"value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf37376",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519c7521",
   "metadata": {},
   "source": [
    "### Running the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56489ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set n_jobs = 1 to not use parallelization. MUST be used rn\n",
    "properties_dict, population = analyze_population(100_000, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a052ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_boxplot_from_dict(properties_dict)\n",
    "\n",
    "create_histogram_from_dict(properties_dict, keys=[\"brick\", \"hinge\", \"none\"])\n",
    "create_histogram_from_dict(properties_dict, keys=[\"not-none\"])\n",
    "create_histogram_from_dict(properties_dict, keys=[\"mass\"])\n",
    "create_histogram_from_dict(properties_dict, keys=[\"edges\"])\n",
    "create_histogram_from_dict(properties_dict, keys=[\"hash\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f606a9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df = statistical_df_from_dict(properties_dict)\n",
    "console.print(stats_df)\n",
    "\n",
    "console.rule(style=\"rule.line dim\")\n",
    "\n",
    "# To get the unique counts per property\n",
    "count_df = count_df_from_list(properties_dict[\"edges\"])\n",
    "console.print(count_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e91cf25",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6468e55b",
   "metadata": {},
   "source": [
    "### Visualize Outliers Interactively"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed630879",
   "metadata": {},
   "source": [
    "Visualize individuals from a key value dictionary where value contains indexes of the individuals from the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981b93e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndividualVisualizer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        index_dict: dict[str, list[int]],\n",
    "        population: list,\n",
    "        console=None,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        index_dict: dict mapping keys to lists of individual indexes (may be empty).\n",
    "        population: list of individuals (e.g., DiGraph objects).\n",
    "        console: rich.console.Console instance for printing (optional).\n",
    "        \"\"\"\n",
    "        self._index_dict = {\n",
    "            k: v\n",
    "            for k, v in index_dict.items()\n",
    "            if isinstance(v, (list, tuple, set))\n",
    "            and v  # only non-empty lists/tuples/sets\n",
    "        }\n",
    "        self._keys = list(self._index_dict.keys())\n",
    "        self._population = population\n",
    "        self._key_index = 0\n",
    "        self._individual_index = 0\n",
    "        self._direction = 1\n",
    "        self._console = console or Console()\n",
    "\n",
    "    def get_count_from_index(self) -> Never:\n",
    "        \"\"\"\n",
    "        Would be cool to select the counts? so switch from main_key to count_key?\n",
    "        maybe the index_dict is just smart and if it contains a dict, it will createa a sub key selection method??\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def select_key(self, index=None) -> None:\n",
    "        if not self._keys:\n",
    "            self._console.print(\"[red]No keys with individuals found.[/red]\")\n",
    "            return\n",
    "\n",
    "        if index is not None:\n",
    "            if 0 <= index < len(self._keys):\n",
    "                self._key_index = index\n",
    "                self._individual_index = 0\n",
    "\n",
    "            self._console.print(\"[red]Index for key out of bounds[/red]\")\n",
    "            return\n",
    "        self._key_index = (self._key_index + self._direction) % len(\n",
    "            self._keys,\n",
    "        )\n",
    "        self._individual_index = 0\n",
    "\n",
    "        index_count = [len(self._index_dict[key]) for key in self._keys]\n",
    "        selected_key = self._keys[self._key_index]\n",
    "        selected_count = index_count[self._key_index]\n",
    "        key_lines = []\n",
    "        display_key = selected_key\n",
    "        if isinstance(selected_key, str):\n",
    "            max_len = 20\n",
    "            display_key = (\n",
    "                (selected_key[:max_len] + \"…\")\n",
    "                if len(selected_key) > max_len\n",
    "                else selected_key\n",
    "            )\n",
    "        key_lines.append(\n",
    "            f\"[bold underline]Selected: {self._key_index}/{len(self._keys)} | {display_key} ({selected_count} indexes)[/bold underline]\\n\",\n",
    "        )\n",
    "        for i, (key, total_indexes) in enumerate(\n",
    "            zip(self._keys, index_count, strict=False),\n",
    "        ):\n",
    "            if i == self._key_index:\n",
    "                key_lines.append(\n",
    "                    f\"[bold green]{i:>3} > {key} <[/bold green] [yellow]({total_indexes} indexes)[/yellow]\",\n",
    "                )\n",
    "            else:\n",
    "                key_lines.append(\n",
    "                    f\"{i:>3} {key} [dim]({total_indexes} individuals)[/dim]\",\n",
    "                )\n",
    "        self._console.print(\"\\n\".join(key_lines))\n",
    "\n",
    "    def _print_direction(self) -> None:\n",
    "        arrow = \"→\" if self._direction == 1 else \"←\"\n",
    "        self._console.print(\n",
    "            f\"[cyan]Direction: {'forward' if self._direction == 1 else 'backward'} {arrow}[/cyan]\",\n",
    "        )\n",
    "\n",
    "    def toggle_direction(self) -> None:\n",
    "        self._direction = -self._direction\n",
    "        arrow = \"→\" if self._direction == 1 else \"←\"\n",
    "        self._console.print(\n",
    "            f\"[cyan]Direction toggled. Now: {'forward' if self._direction == 1 else 'backward'} {arrow}[/cyan]\",\n",
    "        )\n",
    "\n",
    "    def cycle_through_individual_index(self):\n",
    "        indexes = self._get_index_list()\n",
    "        if indexes:\n",
    "            self._individual_index = (\n",
    "                self._individual_index + self._direction\n",
    "            ) % len(indexes)\n",
    "        self._show_current_selection()\n",
    "        return self._get_current_individual_value()\n",
    "\n",
    "    def visualize_individual(\n",
    "        self,\n",
    "        cycle=True,\n",
    "        visualize_fn=visualize_tree_from_graph,\n",
    "    ) -> None:\n",
    "        \"\"\"visualize_fn: function to visualize an individual, e.g. visualize_tree_from_graph.\"\"\"\n",
    "        if cycle:\n",
    "            idx = self.cycle_through_individual_index()\n",
    "        else:\n",
    "            idx = self._get_current_individual_value()\n",
    "        if idx is not None and self._population:\n",
    "            visualize_fn(self._population[idx][0])\n",
    "        else:\n",
    "            self._console.print(\"[red]No individual to visualize.[/red]\")\n",
    "\n",
    "    def _get_index_list(self):\n",
    "        if not self._keys:\n",
    "            return []\n",
    "        key = self._keys[self._key_index]\n",
    "        return self._index_dict.get(key, [])\n",
    "\n",
    "    def _show_current_selection(self) -> None:\n",
    "        if not self._keys:\n",
    "            self._console.print(\"[red]No keys with individuals found.[/red]\")\n",
    "            return\n",
    "        key = self._keys[self._key_index]\n",
    "        indexes = self._get_index_list()\n",
    "        total = len(indexes)\n",
    "        if indexes:\n",
    "            idx = self._individual_index % total\n",
    "            progress_str = f\"[{idx + 1}/{total}]\"\n",
    "            self._console.print(\n",
    "                f\"[bold green]Key:[/bold green] {key} | \"\n",
    "                f\"[blue]Individual index:[/blue] {idx} {progress_str} | \"\n",
    "                f\"[magenta]Value:[/magenta] {indexes[idx]} | \"\n",
    "                f\"[yellow]Total individuals:[/yellow] {total}\",\n",
    "            )\n",
    "        else:\n",
    "            self._console.print(\n",
    "                f\"[bold green]Key:[/bold green] {key} | [red]No individuals[/red]\",\n",
    "            )\n",
    "\n",
    "    def _get_current_individual_value(self):\n",
    "        indexes = self._get_index_list()\n",
    "        if indexes:\n",
    "            return indexes[self._individual_index % len(indexes)]\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92cb526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing the outliers in the visualizer\n",
    "visualizer = IndividualVisualizer(\n",
    "    stats_df[\"outlier_indexes\"].to_dict(),\n",
    "    population,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a9bf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing the unique counts in the visualizer\n",
    "visualizer = IndividualVisualizer(count_df[\"indexes\"].to_dict(), population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a97135f",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.toggle_direction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f637272",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.select_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f37ac02",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.toggle_direction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785a3cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.visualize_individual()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a9be5e",
   "metadata": {},
   "source": [
    "<!-- The exeperiment shows that the outliers seem to have the same genotype. This leads to the question for how many unique genotypes are actually being created. To run this experiment, a new function should be created that easily parses the given phenotype into a deterministic string. this can than be used in a histogram to count the unique types? -->\n",
    "\n",
    "\n",
    "The visualizer shows that while the phenotype may be roughly the same, the genotypes are all unique. A new determinstic method needs to be invented to create a 1:1 genotype <-> phenotype canonical mapping.\n",
    "\n",
    "so going from (many) genotype -> 1 canonical genotype -> 1 phenotype\n",
    "\n",
    "with this new metric the follownig can be implemented"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54224212",
   "metadata": {},
   "source": [
    "step 1: normalize the ID's. and check again"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7164eeda",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21b088e",
   "metadata": {},
   "source": [
    "### To be implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a39d82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_branching(individual: DiGraph) -> dict[str, float]:\n",
    "    \"\"\"\n",
    "    Measures the level of branching in the robot's morphology (M1).\n",
    "\n",
    "    Calculation Method: The specific formula for 'Branching' (M1) is not detailed in this source material,\n",
    "    but it is noted that this descriptor ranges in value from 0 to 1 [1].\n",
    "    This descriptor is positively correlated with the 'Number of Limbs' [2].\n",
    "    \"\"\"\n",
    "    return {\"branching\": 0.0}\n",
    "\n",
    "\n",
    "def analyze_number_of_limbs(individual: DiGraph) -> dict[str, float]:\n",
    "    \"\"\"\n",
    "    Measures the number of effective limbs attached to the robot (M2).\n",
    "\n",
    "    Calculation Method: The specific formula for 'Number of Limbs' (M2) is not detailed in this source material,\n",
    "    but it is noted that this descriptor ranges in value from 0 to 1 [1].\n",
    "    It is used to assess the tendency for morphologies to have few limbs [2, 3].\n",
    "    \"\"\"\n",
    "    return {\"number_of_limbs\": 0.0}\n",
    "\n",
    "\n",
    "def analyze_length_of_limbs(individual: DiGraph) -> dict[str, float]:\n",
    "    \"\"\"\n",
    "    Measures the relative length of the limbs (M3).\n",
    "\n",
    "    Calculation Method: The measure 'Length of Limbs' (E or M3) is defined by the following equation\n",
    "    (used, for example, in the S3 fitness function as a penalty) [4]:\n",
    "\n",
    "    E = { e / e_max, if m >= 3\n",
    "        { 0, otherwise\n",
    "\n",
    "    Where 'm' is the total number of modules in the body, 'e' is the number of modules\n",
    "    which have two of their faces attached to other modules (excluding the core-component),\n",
    "    and 'e_max' is the maximum amount of modules that a body with 'm' modules could have\n",
    "    with two attached faces, calculated as m - 2 [4].\n",
    "    A higher value suggests fewer, longer limbs, as it rewards maximizing the length relative to body size [2, 3].\n",
    "    This descriptor ranges in value from 0 to 1 [1].\n",
    "    \"\"\"\n",
    "    return {\"length_of_limbs\": 0.0}\n",
    "\n",
    "\n",
    "def analyze_coverage(individual: DiGraph) -> dict[str, float]:\n",
    "    \"\"\"\n",
    "    Measures how much of the morphology space is covered (M4).\n",
    "\n",
    "    Calculation Method: The specific formula for 'Coverage' (M4) is not detailed in this source material,\n",
    "    but it is noted that this descriptor ranges in value from 0 to 1 [1].\n",
    "    Morphologies similar to snakes (like those predominant under S1 fitness) tended to have high coverage,\n",
    "    covering the whole body area [5].\n",
    "    \"\"\"\n",
    "    return {\"coverage\": 0.0}\n",
    "\n",
    "\n",
    "def analyze_joints(individual: DiGraph) -> dict[str, float]:\n",
    "    \"\"\"\n",
    "    Measures the number of effective joints in the morphology (M5).\n",
    "\n",
    "    Calculation Method: This descriptor was reformulated for the study.\n",
    "    The concept of an effective joint is defined by a joint module that is attached to any other module type [1].\n",
    "    (Previously, attachment was required to be specifically to the core-component or a structural brick [1, 6].)\n",
    "    This reformulation was done because robots were often observed developing limbs purely formed by a sequence of joints [1].\n",
    "    The descriptor ranges in value from 0 to 1 [1].\n",
    "    \"\"\"\n",
    "    return {\"joints\": 0.0}\n",
    "\n",
    "\n",
    "def analyze_proportion(individual: DiGraph) -> dict[str, float]:\n",
    "    \"\"\"\n",
    "    Measures the proportionality or balance of the robot's shape (M6).\n",
    "\n",
    "    Calculation Method: The specific formula for 'Proportion' (M6) is not detailed in this source material,\n",
    "    but it is noted that this descriptor ranges in value from 0 to 1 [1].\n",
    "    Proportion was observed to drop drastically for fitness S1, which was dominated by single-limb, disproportional robots [5].\n",
    "    \"\"\"\n",
    "    return {\"proportion\": 0.0}\n",
    "\n",
    "\n",
    "def analyze_symmetry(individual: DiGraph) -> dict[str, float]:\n",
    "    \"\"\"\n",
    "    Measures the symmetry of the robot's structure (M7).\n",
    "\n",
    "    Calculation Method: The specific formula for 'Symmetry' (M7) is not detailed in this source material,\n",
    "    but it is noted that this descriptor ranges in value from 0 to 1 [1].\n",
    "    Symmetry tended to be higher when a penalty for long limbs (S3 fitness) was applied [7].\n",
    "    The results suggest that higher symmetry is correlated with lower average speed [8].\n",
    "    \"\"\"\n",
    "    return {\"symmetry\": 0.0}\n",
    "\n",
    "\n",
    "def analyze_size(individual: DiGraph) -> dict[str, float]:\n",
    "    \"\"\"\n",
    "    Measures the overall size of the robot's morphology (M8).\n",
    "\n",
    "    Calculation Method: The specific formula for 'Size' (M8) is not detailed in this source material,\n",
    "    but it is noted that this descriptor ranges in value from 0 to 1 [1].\n",
    "    All behavior-oriented searches tended to explore larger Size, as a large body can more easily produce a large displacement for high speed [5].\n",
    "    \"\"\"\n",
    "    return {\"size\": 0.0}\n",
    "\n",
    "\n",
    "def analyze_sensors(individual: DiGraph) -> dict[str, float]:\n",
    "    \"\"\"\n",
    "    Measures the ratio of sensors to available slots in the morphology (M9).\n",
    "\n",
    "    Calculation Method: This is a new descriptor introduced in the study [1]. It is defined by the equation [9]:\n",
    "\n",
    "    C = { c / c_max, if c_max > 0\n",
    "        { 0, otherwise\n",
    "\n",
    "    Where 'c' is the number of sensors in the morphology, and 'c_max' is the number of free slots in the morphology [9].\n",
    "    The descriptor ranges in value from 0 to 1 [1].\n",
    "    \"\"\"\n",
    "    return {\"sensors\": 0.0}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ariel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
