{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef8c7f5f",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc54dde2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/salomepoulain/projects/ariel-zoo/.venv/lib/python3.13/site-packages/numba/np/ufunc/dufunc.py:346: NumbaWarning: Compilation requested for previously compiled argument types ((uint32,)). This has no effect and perhaps indicates a bug in the calling code (compiling a ufunc more than once for the same signature\n",
      "  warnings.warn(msg, errors.NumbaWarning)\n",
      "/Users/salomepoulain/projects/ariel-zoo/.venv/lib/python3.13/site-packages/numba/np/ufunc/dufunc.py:346: NumbaWarning: Compilation requested for previously compiled argument types ((uint32,)). This has no effect and perhaps indicates a bug in the calling code (compiling a ufunc more than once for the same signature\n",
      "  warnings.warn(msg, errors.NumbaWarning)\n",
      "/Users/salomepoulain/projects/ariel-zoo/.venv/lib/python3.13/site-packages/numba/np/ufunc/dufunc.py:346: NumbaWarning: Compilation requested for previously compiled argument types ((uint32,)). This has no effect and perhaps indicates a bug in the calling code (compiling a ufunc more than once for the same signature\n",
      "  warnings.warn(msg, errors.NumbaWarning)\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ariel_experiments.characterize.canonical'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfeature_extraction\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtext\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TfidfTransformer\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpairwise\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cosine_similarity\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mariel_experiments\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcharacterize\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcanonical\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtoolkit\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     33\u001b[39m     CanonicalToolKit \u001b[38;5;28;01mas\u001b[39;00m ctk,\n\u001b[32m     34\u001b[39m )\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mariel_experiments\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgui_vis\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mview_mujoco\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m view\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mariel_experiments\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minitialize\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m generate_random_individual\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'ariel_experiments.characterize.canonical'"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "from io import BytesIO\n",
    "from typing import Any\n",
    "from sklearn.neighbors import KernelDensity\n",
    "import numpy as np\n",
    "from typing import Dict, List, Any\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import umap\n",
    "import umap.plot\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.models import (\n",
    "    BasicTicker,\n",
    "    ColorBar,\n",
    "    ColumnDataSource,\n",
    "    HoverTool,\n",
    "    LinearColorMapper,\n",
    ")\n",
    "from bokeh.plotting import figure, show\n",
    "from matplotlib.colors import to_hex\n",
    "from PIL import Image\n",
    "from rich.console import Console\n",
    "from rich.progress import track\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from ariel_experiments.characterize.canonical.core.toolkit import (\n",
    "    CanonicalToolKit as ctk,\n",
    ")\n",
    "from ariel_experiments.gui_vis.view_mujoco import view\n",
    "from ariel_experiments.utils.initialize import generate_random_individual\n",
    "\n",
    "console = Console()\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b32c3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207e2a67",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81638bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap_row(\n",
    "    matrices: list[np.ndarray],\n",
    "    titles: list[str] = None,\n",
    "    suptitle: str = None,\n",
    "    figsize_per_plot: tuple[int, int] = (5, 6),\n",
    "    cmap: str = \"viridis\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots a horizontal row of heatmaps with local color scaling.\n",
    "\n",
    "    Args:\n",
    "        matrices: List of matrices to plot\n",
    "        titles: Optional list of titles for each subplot\n",
    "        suptitle: Optional overall figure title\n",
    "        figsize_per_plot: (width, height) for each subplot\n",
    "        cmap: Colormap to use\n",
    "    \"\"\"\n",
    "    num_plots = len(matrices)\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=1,\n",
    "        ncols=num_plots,\n",
    "        figsize=(figsize_per_plot[0] * num_plots, figsize_per_plot[1]),\n",
    "        squeeze=False,\n",
    "    )\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    if suptitle:\n",
    "        fig.suptitle(suptitle, fontsize=16)\n",
    "\n",
    "    for i, matrix in enumerate(matrices):\n",
    "        ax = axes[i]\n",
    "\n",
    "        # Local color scaling for maximum contrast\n",
    "        local_vmin = matrix.min()\n",
    "        local_vmax = matrix.max()\n",
    "\n",
    "        sns.heatmap(\n",
    "            matrix,\n",
    "            ax=ax,\n",
    "            cmap=cmap,\n",
    "            vmin=local_vmin,\n",
    "            vmax=local_vmax,\n",
    "            cbar_ax=None,\n",
    "        )\n",
    "\n",
    "        if titles and i < len(titles):\n",
    "            ax.set_title(titles[i])\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d987789",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparison_heatmaps(\n",
    "    all_matrix_data: dict[str, dict[int, Any]],  # Updated type hint\n",
    "    max_show_radius: int,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots a row of heatmaps for each radius.\n",
    "    Row = Radius\n",
    "    Column = Metric\n",
    "    \"\"\"\n",
    "    # 1. Iterate through radii (Rows of the visual)\n",
    "    for r in range(max_show_radius + 1):\n",
    "        row_matrices = []\n",
    "        row_titles = []\n",
    "\n",
    "        # 2. Iterate through metrics (Columns of the visual)\n",
    "        # CHANGE: We use .items() because input is now a dict, not a list of tuples\n",
    "        for name, matrix_dict in all_matrix_data.items():\n",
    "            # DIRECT ACCESS: Get the specific matrix for this radius\n",
    "            if r in matrix_dict:\n",
    "                matrix = matrix_dict[r]\n",
    "            else:\n",
    "                # Fallback if radius is missing\n",
    "                matrix = np.zeros((1, 1))\n",
    "\n",
    "            row_matrices.append(matrix)\n",
    "            row_titles.append(f\"r:{r} {name}\")\n",
    "\n",
    "        # 3. Plot the specific row\n",
    "        plot_heatmap_row(\n",
    "            matrices=row_matrices,\n",
    "            titles=row_titles,\n",
    "            suptitle=f\"Comparison at Radius {r}\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134e653b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cumsum_dict(matrix_dict):\n",
    "    \"\"\"\n",
    "    Calculates the cumulative sum of matrices keyed by integer radii.\n",
    "    \"\"\"\n",
    "    # 1. Sort the keys to ensure we process 0, then 1, then 2, etc.\n",
    "    sorted_radii = sorted(matrix_dict.keys())\n",
    "\n",
    "    cum_dict = {}\n",
    "    running_sum = None\n",
    "\n",
    "    for r in sorted_radii:\n",
    "        current_matrix = matrix_dict[r]\n",
    "\n",
    "        if running_sum is None:\n",
    "            # First iteration (e.g., radius 0)\n",
    "            # Use .copy() to ensure we don't accidentally modify the input\n",
    "            running_sum = current_matrix.copy()\n",
    "        else:\n",
    "            # Add the current matrix to the accumulated total\n",
    "            running_sum = running_sum + current_matrix\n",
    "\n",
    "        # Store the result in the new dictionary\n",
    "        cum_dict[r] = running_sum\n",
    "\n",
    "    return cum_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a294ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cumsum_dict(matrix_dict):\n",
    "    \"\"\"\n",
    "    Calculates the cumulative sum of matrices keyed by integer radii.\n",
    "    Assumes matrix addition (+) creates a NEW matrix object (e.g., NumPy).\n",
    "    \"\"\"\n",
    "    # 1. Sort the keys\n",
    "    sorted_radii = sorted(matrix_dict.keys())\n",
    "\n",
    "    cum_dict = {}\n",
    "    running_sum = None\n",
    "\n",
    "    for r in sorted_radii:\n",
    "        current_matrix = matrix_dict[r]\n",
    "\n",
    "        if running_sum is None:\n",
    "            # 1. First iteration (e.g., radius 0)\n",
    "            # running_sum now references the input matrix directly.\n",
    "            # This is safe because standard matrix addition below creates a new matrix.\n",
    "            running_sum = current_matrix\n",
    "        else:\n",
    "            # 2. Add the current matrix.\n",
    "            # running_sum = running_sum + current_matrix\n",
    "            # This line CREATES A NEW MATRIX object for running_sum, \n",
    "            # so the object previously stored in cum_dict[r-1] is unchanged.\n",
    "            running_sum = running_sum + current_matrix\n",
    "\n",
    "        # Store the result.\n",
    "        # This stores a reference to the running_sum object (which is either \n",
    "        # the first input matrix, or a newly created sum matrix).\n",
    "        cum_dict[r] = running_sum\n",
    "\n",
    "    return cum_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22db6cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorted_idx_dict(data_dict, *, max_first=True):\n",
    "    \"\"\"Return {key: sorted_coords} by applying get_sorted_coords to each item.\"\"\"\n",
    "    return {\n",
    "        k: get_sorted_coords(data, max_first=max_first)\n",
    "        for k, data in data_dict.items()\n",
    "    }\n",
    "\n",
    "def get_sorted_coords(data, *, max_first=True):\n",
    "    \"\"\"\n",
    "    If data is 2D: Returns (row, col) tuples from upper triangle, sorted by value.\n",
    "    If data is 1D: Returns a list of indices, sorted by value.\n",
    "    \"\"\"\n",
    "    # 1. Handle 1D Array\n",
    "    if data.ndim == 1:\n",
    "        sort_idx = np.argsort(data)\n",
    "        if max_first:\n",
    "            sort_idx = sort_idx[::-1]\n",
    "        return sort_idx.tolist() # Returns [5, 2, 9, ...]\n",
    "\n",
    "    # 2. Handle 2D Matrix\n",
    "    elif data.ndim == 2:\n",
    "        rows, cols = np.triu_indices_from(data, k=1)\n",
    "        values = data[rows, cols]\n",
    "        sort_idx = np.argsort(values)\n",
    "        if max_first:\n",
    "            sort_idx = sort_idx[::-1]\n",
    "        return list(zip(rows[sort_idx], cols[sort_idx])) # Returns [(0,1), (3,4), ...]\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Data must be 1D array or 2D matrix.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5270f4f0",
   "metadata": {},
   "source": [
    "images and interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37cf6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embeddable_image(data, scale=1.0):\n",
    "    \"\"\"\n",
    "    Simplified version: Accepts HxWx4 (RGBA) or HxWx3 (RGB).\n",
    "    Returns PNG data-url with aspect ratio AND relative scale preserved.\n",
    "    \"\"\"\n",
    "    arr = np.asarray(data)\n",
    "    \n",
    "    # Normalize types\n",
    "    if np.issubdtype(arr.dtype, np.floating):\n",
    "        if arr.max() <= 1.0:\n",
    "            arr = (arr * 255).astype(np.uint8)\n",
    "        else:\n",
    "            arr = arr.astype(np.uint8)\n",
    "    else:\n",
    "        arr = arr.astype(np.uint8)\n",
    "\n",
    "    # Detect Mode\n",
    "    if arr.ndim == 3:\n",
    "        mode = 'RGBA' if arr.shape[2] == 4 else 'RGB'\n",
    "    else:\n",
    "        mode = 'L' # Grayscale\n",
    "\n",
    "    # Create Image\n",
    "    img = Image.fromarray(arr, mode=mode)\n",
    "    \n",
    "    # Resize by a constant factor to preserve relative size differences\n",
    "    if scale != 1.0:\n",
    "        new_size = (int(img.width * scale), int(img.height * scale))\n",
    "        img = img.resize(new_size, Image.Resampling.BICUBIC)\n",
    "\n",
    "    buffer = BytesIO()\n",
    "    img.save(buffer, format='PNG', optimize=False, compress_level=1)\n",
    "    return 'data:image/png;base64,' + base64.b64encode(buffer.getvalue()).decode()\n",
    "\n",
    "def robot_image(i, scale=1.0):\n",
    "    \"\"\"\n",
    "    Generates the image for robot i using the global POPULATION and view function.\n",
    "    \"\"\"\n",
    "    graph = POPULATION[i].to_graph()  \n",
    "    # Using remove_background=True for transparent PNGs\n",
    "    img_arr = np.array(view(graph, return_img=True, tilted=True, remove_background=True))\n",
    "    \n",
    "    # SCALE 1.0: High Quality for Matplotlib.\n",
    "    return embeddable_image(img_arr, scale=1.0)\n",
    "\n",
    "def get_population_images(population_size, scale=1.0):\n",
    "    \"\"\"\n",
    "    Pre-generates all images for the population to avoid re-rendering.\n",
    "    \"\"\"\n",
    "    return [robot_image(i, scale=scale) for i in track(range(population_size), description=f\"Generating {population_size} images...\")]\n",
    "\n",
    "def decode_base64_image(data_url):\n",
    "    \"\"\"Helper to convert base64 string back to numpy array.\"\"\"\n",
    "    header, encoded = data_url.split(\",\", 1)\n",
    "    data = base64.b64decode(encoded)\n",
    "    return np.array(Image.open(BytesIO(data)))\n",
    "\n",
    "def create_thumbnails(image_list, scale=0.5):\n",
    "    \"\"\"\n",
    "    Takes a list of base64 images (HQ) and creates a new list of scaled-down \n",
    "    thumbnails (preserving relative aspect ratio) for use in web tooltips.\n",
    "    \"\"\"\n",
    "    thumbnails = []\n",
    "    for b64_str in image_list:\n",
    "        # Decode\n",
    "        header, encoded = b64_str.split(\",\", 1)\n",
    "        data = base64.b64decode(encoded)\n",
    "        img = Image.open(BytesIO(data))\n",
    "        \n",
    "        # Resize\n",
    "        new_size = (int(img.width * scale), int(img.height * scale))\n",
    "        img_small = img.resize(new_size, Image.Resampling.BICUBIC)\n",
    "        \n",
    "        # Re-encode\n",
    "        buffer = BytesIO()\n",
    "        img_small.save(buffer, format='PNG')\n",
    "        thumb_str = 'data:image/png;base64,' + base64.b64encode(buffer.getvalue()).decode()\n",
    "        thumbnails.append(thumb_str)\n",
    "    return thumbnails\n",
    "\n",
    "\n",
    "def matrix_to_heatmap_source(matrix, images, metric_name, radius):\n",
    "    \"\"\"Converts matrix to Bokeh DataSource.\"\"\"\n",
    "    N = matrix.shape[0]\n",
    "    x_indices, y_indices = np.meshgrid(np.arange(N), np.arange(N))\n",
    "    x_flat = x_indices.flatten()\n",
    "    y_flat = N - 1 - y_indices.flatten() \n",
    "    values = matrix.flatten()\n",
    "    imgs_i = [images[r] for r in y_indices.flatten()]\n",
    "    imgs_j = [images[c] for c in x_indices.flatten()]\n",
    "    ids_i = [str(r) for r in y_indices.flatten()]\n",
    "    ids_j = [str(c) for c in x_indices.flatten()]\n",
    "    data = {\n",
    "        'x': x_flat, 'y': y_flat, 'value': values,\n",
    "        'img_row': imgs_i, 'img_col': imgs_j,\n",
    "        'id_row': ids_i, 'id_col': ids_j,\n",
    "        'metric': [metric_name] * len(values),\n",
    "        'radius': [radius] * len(values)\n",
    "    }\n",
    "    return ColumnDataSource(data)\n",
    "\n",
    "def plot_interactive_heatmaps(all_matrix_data: dict, population_images: list, max_show_radius: int, plot_width=None, plot_height=None, palette=\"Reds256\", thumbnail_scale=0.5):\n",
    "    \"\"\"\n",
    "    Creates a Grid of Interactive Heatmaps using Bokeh.\n",
    "    Args:\n",
    "        thumbnail_scale: Factor to scale images down for the tooltip (default 0.5)\n",
    "    \"\"\"\n",
    "    # Create thumbnails specifically for this plot (leaves original list untouched)\n",
    "    thumb_images = create_thumbnails(population_images, scale=thumbnail_scale)\n",
    "\n",
    "    num_cols = len(all_matrix_data)\n",
    "    if plot_width is None: plot_width = 650 if num_cols == 1 else 200\n",
    "    if plot_height is None: plot_height = 600 if num_cols == 1 else 200\n",
    "\n",
    "    grid_layout = []\n",
    "    for r in range(max_show_radius + 1):\n",
    "        row_plots = []\n",
    "        for name, matrix_dict in all_matrix_data.items():\n",
    "            if r in matrix_dict: matrix = matrix_dict[r]\n",
    "            else: matrix = np.zeros((1, 1))\n",
    "            \n",
    "            # Use thumbnails here\n",
    "            source = matrix_to_heatmap_source(matrix, thumb_images, name, r)\n",
    "            vmin, vmax = matrix.min(), matrix.max()\n",
    "            mapper = LinearColorMapper(palette=palette, low=vmin, high=vmax)\n",
    "            \n",
    "            p = figure(title=f\"r:{r} {name}\", x_range=(-0.5, matrix.shape[1]-0.5), y_range=(-0.5, matrix.shape[0]-0.5), width=plot_width, height=plot_height, tools=\"hover,save,reset\", toolbar_location=\"above\")\n",
    "            p.axis.visible = False; p.grid.visible = False\n",
    "            p.rect(x='x', y='y', width=1, height=1, source=source, fill_color={'field': 'value', 'transform': mapper}, line_color=None)\n",
    "            color_bar = ColorBar(color_mapper=mapper, ticker=BasicTicker(), label_standoff=8, border_line_color=None, location=(0,0), width=8)\n",
    "            p.add_layout(color_bar, 'right')\n",
    "            \n",
    "            hover = p.select(dict(type=HoverTool))\n",
    "            # No CSS max-width constraints. We rely on the thumbnail being physically smaller (0.5x)\n",
    "            # but proportional.\n",
    "            hover.tooltips = \"\"\"\n",
    "            <div style=\"display: flex; flex-direction: column; align-items: center; background: white; padding: 5px;\">\n",
    "                <div style=\"font-weight: bold; margin-bottom: 5px;\">@metric (r=@radius) Val: @value{0.000}</div>\n",
    "                <div style=\"display: flex; flex-direction: row; gap: 10px;\">\n",
    "                    <div style=\"text-align: center;\"><span style=\"font-size: 10px;\">Row: @id_row</span><br><img src=\"@img_row\" style=\"width: auto; height: auto;\"></div>\n",
    "                    <div style=\"text-align: center;\"><span style=\"font-size: 10px;\">Col: @id_col</span><br><img src=\"@img_col\" style=\"width: auto; height: auto;\"></div>\n",
    "                </div>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "            row_plots.append(p)\n",
    "        grid_layout.append(row_plots)\n",
    "    show(gridplot(grid_layout))\n",
    "\n",
    "def plot_interactive_umap_grid(umap_data: dict, population_images: list, max_show_radius: int, follow_idx_list: list[int] | None= None, plot_width=None, plot_height=200, thumbnail_scale=0.5):\n",
    "    \"\"\"\n",
    "    Creates a Grid of Interactive UMAP Scatter plots.\n",
    "    Args:\n",
    "        thumbnail_scale: Factor to scale images down for the tooltip (default 0.5)\n",
    "    \"\"\"\n",
    "    # Create thumbnails specifically for this plot\n",
    "    thumb_images = create_thumbnails(population_images, scale=thumbnail_scale)\n",
    "\n",
    "    num_cols = len(umap_data)\n",
    "    if plot_width is None: plot_width = 700 if num_cols == 1 else 200\n",
    "    n = len(population_images)\n",
    "    \n",
    "    sizes = [4] * n\n",
    "    rgba_colors = plt.cm.rainbow(np.linspace(0, 1, n))\n",
    "\n",
    "    line_colors = [None] * n\n",
    "    if follow_idx_list:\n",
    "        follow_set = set(follow_idx_list)\n",
    "        sizes = [8 if i in follow_set else 3 for i in range(n)]\n",
    "        line_colors = ['black' if i in follow_set else None for i in range(n)]\n",
    "        \n",
    "        for i in range(n):\n",
    "            if i not in follow_set:\n",
    "                rgba_colors[i] = [0.0, 0.0, 0.0, 0.3]\n",
    "        \n",
    "        \n",
    "    hex_colors = [to_hex(c, keep_alpha=True) for c in rgba_colors]\n",
    "    \n",
    "    \n",
    "    grid_layout = []\n",
    "    for r in range(max_show_radius + 1):\n",
    "        row_plots = []\n",
    "        for name, matrix_dict in umap_data.items():\n",
    "            if r in matrix_dict:\n",
    "                emb = matrix_dict[r]\n",
    "                if emb.ndim != 2 or emb.shape[1] != 2:\n",
    "                    p = figure(title=f\"r:{r} {name} (No Data)\", width=plot_width, height=plot_height); row_plots.append(p); continue\n",
    "            else:\n",
    "                p = figure(title=f\"r:{r} {name} (Missing)\", width=plot_width, height=plot_height); row_plots.append(p); continue\n",
    "\n",
    "            # Use thumb_images here\n",
    "            robots_df = pd.DataFrame({\"x\": emb[:, 0], \"y\": emb[:, 1], \"digit\": [str(i) for i in range(n)], \"image\": thumb_images, \"color\": hex_colors, \"size\": sizes, 'line_color': line_colors})\n",
    "            \n",
    "            if follow_idx_list:\n",
    "                robots_df['sort_order'] = [1 if i in set(follow_idx_list) else 0 for i in range(n)]\n",
    "                robots_df = robots_df.sort_values('sort_order', ascending=True)\n",
    "            source = ColumnDataSource(robots_df)\n",
    "            p = figure(title=f\"r:{r} {name}\", width=plot_width, height=plot_height, tools=\"pan,wheel_zoom,reset,save\", toolbar_location=\"above\")\n",
    "            # p.scatter('x', 'y', source=source, color='color', line_alpha=1, line_color='white', line_width=2, size='size')\n",
    "            p.scatter('x', 'y', source=source, color='color', line_alpha=1, line_color='line_color', line_width=1, size='size')\n",
    "\n",
    "        \n",
    "            hover = HoverTool(tooltips=\"\"\"<div><img src='@image' style='float:left; margin:5px; width:auto; height:auto;'/></div><div style=\"font-size:12px; font-weight: bold;\"><span style='color:#224499'>ID: @digit</span></div>\"\"\")\n",
    "            p.add_tools(hover)\n",
    "            row_plots.append(p)\n",
    "        grid_layout.append(row_plots)\n",
    "    show(gridplot(grid_layout))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b751a9d9",
   "metadata": {},
   "source": [
    "for overview plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4c1cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _stitch_images_horizontally(images, target_height=None, gap_px=20):\n",
    "    \"\"\"\n",
    "    Stitches images horizontally with white background (handles transparency).\n",
    "    If target_height is provided, pads all images vertically to match that height (alignment: top).\n",
    "    \"\"\"\n",
    "    if not images or all(img is None for img in images):\n",
    "        return None, 0, 0\n",
    "    \n",
    "    valid_images = [img for img in images if img is not None]\n",
    "    if not valid_images: return None, 0, 0\n",
    "\n",
    "    # 1. Normalize Types to uint8 RGB and composite transparent images onto white\n",
    "    normalized_imgs = []\n",
    "    for img in valid_images:\n",
    "        # Handle float 0-1\n",
    "        if np.issubdtype(img.dtype, np.floating):\n",
    "            img = (np.clip(img, 0, 1) * 255).astype(np.uint8)\n",
    "        else:\n",
    "            img = img.astype(np.uint8)\n",
    "        \n",
    "        # Handle Alpha channel - composite onto white background\n",
    "        if len(img.shape) == 3 and img.shape[2] == 4:\n",
    "            # Extract RGB and Alpha\n",
    "            rgb = img[:, :, :3]\n",
    "            alpha = img[:, :, 3:4] / 255.0  # Normalize alpha to 0-1\n",
    "            \n",
    "            # Create white background\n",
    "            white_bg = np.full_like(rgb, 255, dtype=np.uint8)\n",
    "            \n",
    "            # Composite: result = foreground * alpha + background * (1 - alpha)\n",
    "            img = (rgb * alpha + white_bg * (1 - alpha)).astype(np.uint8)\n",
    "        elif len(img.shape) == 3 and img.shape[2] >= 3:\n",
    "            img = img[:, :, :3]\n",
    "            \n",
    "        normalized_imgs.append(img)\n",
    "\n",
    "    # 2. Determine Canvas Height\n",
    "    current_max_h = max(img.shape[0] for img in normalized_imgs)\n",
    "    final_h = target_height if target_height and target_height > current_max_h else current_max_h\n",
    "\n",
    "    # 3. Create White Gap Column\n",
    "    white_gap_col = np.full((final_h, gap_px, 3), 255, dtype=np.uint8)\n",
    "\n",
    "    # 4. Stitching Loop\n",
    "    stitched = None\n",
    "    \n",
    "    for i, img in enumerate(normalized_imgs):\n",
    "        h, w = img.shape[:2]\n",
    "        \n",
    "        # Pad image to final_h (fill bottom with white)\n",
    "        if h < final_h:\n",
    "            pad = np.full((final_h - h, w, 3), 255, dtype=np.uint8)\n",
    "            img = np.vstack((img, pad))\n",
    "            \n",
    "        if stitched is None:\n",
    "            stitched = img\n",
    "        else:\n",
    "            stitched = np.hstack((stitched, white_gap_col, img))\n",
    "            \n",
    "    return stitched, stitched.shape[1], final_h\n",
    "\n",
    "def view_grid_of_groups(rows_of_tuples, rows_of_titles=None, col_headers=None, main_title=None):\n",
    "    \"\"\"\n",
    "    Plots a grid of groups where ALL images are scaled equally (no auto-zoom).\n",
    "    \"\"\"\n",
    "    if not rows_of_tuples: return\n",
    "\n",
    "    n_rows = len(rows_of_tuples)\n",
    "    n_cols = len(rows_of_tuples[0])\n",
    "    ROBOT_GAP_PX = 20\n",
    "    \n",
    "    # --- PASS 1: Calculate Global Max Dimensions and Process Images ---\n",
    "    global_max_h = 0\n",
    "    global_max_w = 0\n",
    "    \n",
    "    grid_data = [[None for _ in range(n_cols)] for _ in range(n_rows)]\n",
    "    \n",
    "    for r in range(n_rows):\n",
    "        for c in range(n_cols):\n",
    "            group_base64_strings = rows_of_tuples[r][c]\n",
    "            images = [decode_base64_image(s) for s in group_base64_strings]\n",
    "            \n",
    "            # Find max height in this specific group to update global max\n",
    "            for img in images:\n",
    "                if img is not None:\n",
    "                    if img.shape[0] > global_max_h: global_max_h = img.shape[0]\n",
    "            \n",
    "            grid_data[r][c] = images\n",
    "\n",
    "    # --- PASS 2: Stitch and Measure Widths ---\n",
    "    processed_images = []\n",
    "    \n",
    "    for r in range(n_rows):\n",
    "        row_imgs = []\n",
    "        for c in range(n_cols):\n",
    "            images = grid_data[r][c]\n",
    "            # Stitch using GLOBAL height (pads bottom with white)\n",
    "            stitched, w, h = _stitch_images_horizontally(images, target_height=global_max_h, gap_px=ROBOT_GAP_PX)\n",
    "            \n",
    "            if w > global_max_w: global_max_w = w\n",
    "            row_imgs.append(stitched)\n",
    "        processed_images.append(row_imgs)\n",
    "\n",
    "    # --- PASS 3: Plot with Fixed Limits ---\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, \n",
    "                             figsize=(4 * n_cols, 2.5 * n_rows), \n",
    "                             squeeze=False,\n",
    "                             facecolor='white')\n",
    "    \n",
    "    if main_title:\n",
    "        fig.suptitle(main_title, fontsize=16, weight=\"bold\", y=0.98, color='black')\n",
    "\n",
    "    for r in range(n_rows):\n",
    "        for c in range(n_cols):\n",
    "            ax = axes[r, c]\n",
    "            ax.set_facecolor('white')\n",
    "            \n",
    "            img_data = processed_images[r][c]\n",
    "            \n",
    "            if img_data is not None:\n",
    "                ax.imshow(img_data)\n",
    "            \n",
    "            # Force Equal Scaling\n",
    "            ax.set_xlim(0, global_max_w)\n",
    "            ax.set_ylim(global_max_h, 0)\n",
    "            ax.set_aspect('equal')\n",
    "            ax.axis('off')\n",
    "\n",
    "            # Titles and Headers\n",
    "            if rows_of_titles and r < len(rows_of_titles):\n",
    "                ax.set_title(rows_of_titles[r][c], fontsize=10, color='black', pad=0)\n",
    "\n",
    "            if r == 0 and col_headers and c < len(col_headers):\n",
    "                ax.text(0.5, 1, col_headers[c], transform=ax.transAxes, \n",
    "                        ha=\"center\", va=\"bottom\", fontsize=12, weight=\"bold\", color=\"#224499\")\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0.25, top=0.95, bottom=0.02)\n",
    "    plt.show()\n",
    "\n",
    "# def plot_rows_for_radii(cumulative_data, sorted_data, population_images, max_radius: int, pair_rank: int = 0, labels: list[str] = None, main_title: str = None):\n",
    "#     if labels is None: labels = list(cumulative_data.keys())\n",
    "#     all_rows_robots = []\n",
    "#     all_rows_titles = []\n",
    "    \n",
    "#     for r in range(max_radius + 1):\n",
    "#         robots_row = []\n",
    "#         titles_row = []\n",
    "#         for name in labels:\n",
    "#             coords_list = sorted_data[name].get(r, [])\n",
    "#             matrix = cumulative_data[name].get(r)\n",
    "#             if coords_list and pair_rank < len(coords_list):\n",
    "#                 i, j = coords_list[pair_rank]\n",
    "#             else:\n",
    "#                 i, j = (0, 0)\n",
    "#             idx_i, idx_j = int(i), int(j)\n",
    "#             val = matrix[idx_i, idx_j] if matrix is not None else 0.0\n",
    "            \n",
    "#             robots_row.append([population_images[idx_i], population_images[idx_j]])\n",
    "#             titles_row.append(f\"{name}\\nr:{r} <{idx_i},{idx_j}> val={val:.3f}\")\n",
    "            \n",
    "#         all_rows_robots.append(robots_row)\n",
    "#         all_rows_titles.append(titles_row)\n",
    "\n",
    "#     view_grid_of_groups(all_rows_robots, all_rows_titles, col_headers=None, main_title=main_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdcf8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rows_for_radii(cumulative_data, sorted_data, population_images, max_radius: int, \n",
    "                        pair_rank: int = 0, plot_up_to: bool = False, \n",
    "                        labels: list[str] = None, main_title: str = None):\n",
    "    \n",
    "    if labels is None: labels = list(cumulative_data.keys())\n",
    "    \n",
    "    all_rows_robots = []\n",
    "    all_rows_titles = []\n",
    "    \n",
    "    for r in range(max_radius + 1):\n",
    "        robots_row = []\n",
    "        titles_row = []\n",
    "        \n",
    "        for name in labels:\n",
    "            # 1. Get the list of coordinates/indices for this metric & radius\n",
    "            coords_list = sorted_data[name].get(r, [])\n",
    "            n_items = len(coords_list)\n",
    "            \n",
    "            # 2. Determine which items to plot\n",
    "            if n_items == 0:\n",
    "                items_to_process = []\n",
    "            else:\n",
    "                # --- LOGIC UPDATE FOR NEGATIVE RANKS ---\n",
    "                if plot_up_to:\n",
    "                    if pair_rank >= 0:\n",
    "                        # Positive: Take from start up to rank (Top N)\n",
    "                        # e.g. rank=2 -> indices [0, 1, 2]\n",
    "                        end_idx = min(pair_rank + 1, n_items)\n",
    "                        items_to_process = coords_list[:end_idx]\n",
    "                    else:\n",
    "                        # Negative: Take from rank to end (Bottom N)\n",
    "                        # e.g. rank=-2 -> indices [-2, -1]\n",
    "                        # Ensure we don't go out of bounds (e.g. -99 vs len 10)\n",
    "                        start_idx = max(-n_items, pair_rank)\n",
    "                        items_to_process = coords_list[start_idx:]\n",
    "                else:\n",
    "                    # Single Item Mode\n",
    "                    # Python handles negative indexing (list[-1]), \n",
    "                    # but we must check bounds to prevent IndexError if rank is too large/small\n",
    "                    if -n_items <= pair_rank < n_items:\n",
    "                        items_to_process = [coords_list[pair_rank]]\n",
    "                    else:\n",
    "                        items_to_process = []\n",
    "\n",
    "            # 3. Process the selected items (Stitch them all into one group)\n",
    "            group_images = []\n",
    "            title_parts = []\n",
    "            \n",
    "            matrix = cumulative_data[name].get(r)\n",
    "            \n",
    "            for k, item in enumerate(items_to_process):\n",
    "                # LOGIC BRANCH: Is it a Tuple (Pair) or Scalar (Single)?\n",
    "                \n",
    "                # Case A: It's a Tuple/List/Array (e.g., (10, 42))\n",
    "                if isinstance(item, (list, tuple, np.ndarray)) and len(item) == 2:\n",
    "                    idx_i, idx_j = int(item[0]), int(item[1])\n",
    "                    \n",
    "                    # Fetch value from matrix if available\n",
    "                    val = 0.0\n",
    "                    if matrix is not None:\n",
    "                        try:\n",
    "                            val = matrix[idx_i, idx_j]\n",
    "                        except IndexError:\n",
    "                            pass\n",
    "\n",
    "                    group_images.extend([population_images[idx_i], population_images[idx_j]])\n",
    "                    \n",
    "                    # Add a separator pipe '|' if this isn't the first item\n",
    "                    sep = \" | \" if k > 0 else \"\"\n",
    "                    title_parts.append(f\"{sep}<{idx_i},{idx_j}>={val:.2f}\")\n",
    "\n",
    "                # Case B: It's a Scalar/Integer (e.g., 10)\n",
    "                else:\n",
    "                    # Handle if it came as a single-element array or plain int\n",
    "                    idx = int(item) if np.isscalar(item) else int(item[0])\n",
    "                    \n",
    "                    # Fetch value (Fitness) from array if available\n",
    "                    val = 0.0\n",
    "                    if matrix is not None:\n",
    "                         try:\n",
    "                            # If matrix is 1D array\n",
    "                            if matrix.ndim == 1:\n",
    "                                val = matrix[idx]\n",
    "                            # If matrix is 2D but we have 1 index, maybe diagonal?\n",
    "                            elif matrix.ndim == 2:\n",
    "                                val = matrix[idx, idx] \n",
    "                         except IndexError:\n",
    "                            pass\n",
    "\n",
    "                    group_images.append(population_images[idx])\n",
    "                    \n",
    "                    sep = \" | \" if k > 0 else \"\"\n",
    "                    title_parts.append(f\"{sep}#{idx}={val:.2f}\")\n",
    "\n",
    "            # 4. Finalize Row\n",
    "            robots_row.append(group_images)\n",
    "            \n",
    "            # Construct title (limit length if plot_up_to included many items)\n",
    "            full_title_str = \"\".join(title_parts)\n",
    "            if len(full_title_str) > 50: \n",
    "                full_title_str = full_title_str[:47] + \"...\"\n",
    "            \n",
    "            titles_row.append(f\"{name} (r:{r})\\n{full_title_str}\")\n",
    "            \n",
    "        all_rows_robots.append(robots_row)\n",
    "        all_rows_titles.append(titles_row)\n",
    "\n",
    "    view_grid_of_groups(all_rows_robots, all_rows_titles, col_headers=None, main_title=main_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771570a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histograms(data_dict, max_radius=2, bins=100, size_per_plot=4):\n",
    "    \"\"\"\n",
    "    Plots a grid of histograms with dynamic figure sizing to keep plots square.\n",
    "    \n",
    "    Parameters:\n",
    "    - data_dict: Dictionary containing the data (matrices or arrays).\n",
    "    - max_radius: The maximum radius index to plot (rows).\n",
    "    - bins: Number of histogram bins.\n",
    "    - size_per_plot: Width/Height in inches for each individual subplot.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Setup the grid dimensions\n",
    "    metric_keys = list(data_dict.keys())\n",
    "    n_cols = len(metric_keys)\n",
    "    n_rows = max_radius + 1 \n",
    "    \n",
    "    # 2. Dynamic Figure Size Calculation\n",
    "    # We multiply the number of cols/rows by the desired size per plot\n",
    "    dynamic_figsize = (n_cols * size_per_plot, n_rows * size_per_plot)\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=dynamic_figsize, constrained_layout=True)\n",
    "    \n",
    "    # Ensure axes is always 2D array even if 1 row or 1 col\n",
    "    if n_rows == 1 and n_cols == 1:\n",
    "        axes = np.array([[axes]])\n",
    "    elif n_rows == 1: \n",
    "        axes = axes[np.newaxis, :]\n",
    "    elif n_cols == 1: \n",
    "        axes = axes[:, np.newaxis]\n",
    "\n",
    "    # 3. Iterate through Metrics (Columns)\n",
    "    for col_idx, metric_name in enumerate(metric_keys):\n",
    "        \n",
    "        # Get the sub-dictionary for this metric\n",
    "        radius_dict = data_dict[metric_name]\n",
    "        \n",
    "        # 4. Iterate through Radii (Rows)\n",
    "        for r in range(n_rows):\n",
    "            ax = axes[r, col_idx]\n",
    "            \n",
    "            # Safety check: does this radius exist?\n",
    "            if r not in radius_dict:\n",
    "                ax.axis('off')\n",
    "                continue\n",
    "                \n",
    "            raw_data = radius_dict[r]\n",
    "            \n",
    "            # --- DATA PREPROCESSING ---\n",
    "            # If 2D Matrix: Flatten Upper Triangle only (k=1 excludes diagonal)\n",
    "            if raw_data.ndim == 2:\n",
    "                vals = raw_data[np.triu_indices_from(raw_data, k=1)]\n",
    "            # If 1D Array: Use as is\n",
    "            else:\n",
    "                vals = raw_data.flatten()\n",
    "            \n",
    "            # --- PLOTTING ---\n",
    "            sns.histplot(vals, bins=bins, kde=True, ax=ax, \n",
    "                         color=f\"C{col_idx}\", edgecolor='w', linewidth=0.5)\n",
    "            \n",
    "            # --- STATS ANNOTATION ---\n",
    "            if len(vals) > 0:\n",
    "                stats_text = (f\"$\\mu$: {np.mean(vals):.2f}\\n\"\n",
    "                              f\"Min: {np.min(vals):.2f}\\n\"\n",
    "                              f\"Max: {np.max(vals):.2f}\")\n",
    "                \n",
    "                ax.text(0.95, 0.95, stats_text, transform=ax.transAxes, \n",
    "                        fontsize=10, verticalalignment='top', horizontalalignment='right',\n",
    "                        bbox=dict(boxstyle='round', facecolor='white', alpha=0.9))\n",
    "\n",
    "            # --- LABELS & TITLES ---\n",
    "            # Title only on top row\n",
    "            if r == 0:\n",
    "                ax.set_title(metric_name, fontsize=14, fontweight='bold', pad=15)\n",
    "            \n",
    "            # Y Label only on first column\n",
    "            if col_idx == 0:\n",
    "                ax.set_ylabel(f\"Radius {r}\\nCount\", fontsize=12, fontweight='bold')\n",
    "            else:\n",
    "                ax.set_ylabel(\"\")\n",
    "            \n",
    "            # X Label only on bottom row\n",
    "            if r == n_rows - 1:\n",
    "                ax.set_xlabel(\"Value\", fontsize=11)\n",
    "            else:\n",
    "                ax.set_xlabel(\"\")\n",
    "\n",
    "    fig.suptitle(f\"Distribution of Values per Radius (0 to {max_radius})\", fontsize=18, y=1.02, fontweight='bold')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c034169c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_interactive_waterfall_grid(metric_data: dict, sorted_data: dict, population_images: list, max_show_radius: int, follow_idx_list: list[int] | None = None, plot_width=150, plot_height=150, thumbnail_scale=0.5):\n",
    "    \"\"\"\n",
    "    Creates a Grid of Interactive Waterfall (Staircase) plots using PRE-SORTED indices.\n",
    "    \n",
    "    Args:\n",
    "        metric_data: Dictionary {name: {radius: 1D_array_of_scores}}.\n",
    "        sorted_data: Dictionary {name: {radius: [idx_1, idx_2, ... idx_N]}} (The order to plot).\n",
    "        population_images: List of image data.\n",
    "    \"\"\"\n",
    "    # Create thumbnails (Assuming create_thumbnails function exists in your scope)\n",
    "    # If not, ensure you have the logic to convert population_images to base64 strings here.\n",
    "    thumb_images = create_thumbnails(population_images, scale=thumbnail_scale)\n",
    "\n",
    "    n = len(population_images)\n",
    "    \n",
    "    # --- Color/Size Setup (Mapped to Original ID) ---\n",
    "    # We prepare these lists indexed by original ID (0 to N)\n",
    "    # so we can grab them in the correct order later.\n",
    "    base_sizes = [4] * n\n",
    "    rgba_colors = plt.cm.rainbow(np.linspace(0, 1, n))\n",
    "    base_line_colors = [None] * n\n",
    "\n",
    "    if follow_idx_list:\n",
    "        follow_set = set(follow_idx_list)\n",
    "        base_sizes = [8 if i in follow_set else 3 for i in range(n)]\n",
    "        base_line_colors = ['black' if i in follow_set else None for i in range(n)]\n",
    "        \n",
    "        for i in range(n):\n",
    "            if i not in follow_set:\n",
    "                rgba_colors[i] = [0.0, 0.0, 0.0, 0.3] # Grey out others\n",
    "                \n",
    "    base_hex_colors = [to_hex(c, keep_alpha=True) for c in rgba_colors]\n",
    "    \n",
    "    grid_layout = []\n",
    "\n",
    "    # --- Plotting Loop ---\n",
    "    for r in range(max_show_radius + 1):\n",
    "        row_plots = []\n",
    "        for name, data_dict in metric_data.items():\n",
    "            \n",
    "            # Check for data existence in both dictionaries\n",
    "            if r not in data_dict or name not in sorted_data or r not in sorted_data[name]:\n",
    "                 p = figure(title=f\"r:{r} {name} (Missing)\", width=plot_width, height=plot_height)\n",
    "                 row_plots.append(p)\n",
    "                 continue\n",
    "            \n",
    "            # 1. Get the Raw Scores and the Sorted Order\n",
    "            raw_scores = data_dict[r]\n",
    "            sorted_indices = sorted_data[name][r] # This is the list of indices in rank order\n",
    "            \n",
    "            if raw_scores.ndim != 1:\n",
    "                 p = figure(title=f\"r:{r} {name} (Data not 1D)\", width=plot_width, height=plot_height)\n",
    "                 row_plots.append(p)\n",
    "                 continue\n",
    "\n",
    "            # 2. Construct Lists in the Sorted Order\n",
    "            # We iterate through 'sorted_indices' to pick items from the base lists\n",
    "            ordered_scores = []\n",
    "            ordered_ids = []\n",
    "            ordered_imgs = []\n",
    "            ordered_colors = []\n",
    "            ordered_sizes = []\n",
    "            ordered_line_colors = []\n",
    "\n",
    "            for original_idx in sorted_indices:\n",
    "                idx = int(original_idx) # Ensure integer\n",
    "                \n",
    "                # Retrieve data based on original index\n",
    "                ordered_scores.append(raw_scores[idx])\n",
    "                ordered_ids.append(str(idx))\n",
    "                ordered_imgs.append(thumb_images[idx])\n",
    "                ordered_colors.append(base_hex_colors[idx])\n",
    "                ordered_sizes.append(base_sizes[idx])\n",
    "                ordered_line_colors.append(base_line_colors[idx])\n",
    "\n",
    "            # 3. Create DataFrame (Already Sorted)\n",
    "            df = pd.DataFrame({\n",
    "                \"value\": ordered_scores,\n",
    "                \"digit\": ordered_ids,\n",
    "                \"image\": ordered_imgs,\n",
    "                \"color\": ordered_colors,\n",
    "                \"size\": ordered_sizes,\n",
    "                \"line_color\": ordered_line_colors\n",
    "            })\n",
    "            \n",
    "            # The 'rank' is simply the row number now, because we inserted them in order\n",
    "            df[\"rank\"] = df.index\n",
    "\n",
    "            source = ColumnDataSource(df)\n",
    "\n",
    "            # 4. Create Figure\n",
    "            p = figure(title=f\"r:{r} {name}\", width=plot_width, height=plot_height, \n",
    "                       tools=\"pan,wheel_zoom,reset,save\", toolbar_location=\"above\")\n",
    "            \n",
    "            # Font sizes as requested\n",
    "            p.axis.axis_label_text_font_size = \"4pt\"\n",
    "            p.axis.major_label_text_font_size= \"4pt\"\n",
    "            p.title.text_font_size= \"8pt\"\n",
    "\n",
    "            # 5. The Staircase Line\n",
    "            p.step('rank', 'value', source=source, line_width=1, color=\"gray\", mode=\"after\", line_alpha=0.5)\n",
    "\n",
    "            # 6. The Scatter Points\n",
    "            p.scatter('rank', 'value', source=source, color='color', \n",
    "                      line_alpha=1, line_color='line_color', line_width=1, size='size')\n",
    "\n",
    "            # 7. Hover Tool\n",
    "            hover = HoverTool(tooltips=\"\"\"\n",
    "                <div>\n",
    "                    <img src='@image' style='float:left; margin:5px; width:auto; height:auto;'/>\n",
    "                </div>\n",
    "                <div style=\"font-size:12px; font-weight: bold;\">\n",
    "                    <span style='color:#224499'>ID: @digit</span><br>\n",
    "                    <span style='color:#333'>Val: @value</span>\n",
    "                </div>\n",
    "            \"\"\")\n",
    "            p.add_tools(hover)\n",
    "            row_plots.append(p)\n",
    "            \n",
    "        grid_layout.append(row_plots)\n",
    "\n",
    "    show(gridplot(grid_layout))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5773e6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afd13fa",
   "metadata": {},
   "source": [
    "# | STARTING PARAMETERS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091b7bc7",
   "metadata": {},
   "source": [
    "## GLOBAL ANALYSIS SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d15609",
   "metadata": {},
   "outputs": [],
   "source": [
    "POPULATION_SIZE = 100\n",
    "NUM_OF_MODULES = 20\n",
    "\n",
    "MAX_RADIUS = None\n",
    "\n",
    "CONFIG = ctk.SimilarityConfig(\n",
    "    max_tree_radius=MAX_RADIUS, radius_strategy=ctk.RadiusStrategy.NODE_LOCAL\n",
    ")\n",
    "\n",
    "MAX_SHOW_RADIUS = 7\n",
    "\n",
    "FROM_DATABASE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d99c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ariel_experiments.utils.io_canon_pop import load_genotypes_from_database\n",
    "\n",
    "if FROM_DATABASE:\n",
    "    graph_population = load_genotypes_from_database()\n",
    "    \n",
    "    if len(graph_population) > POPULATION_SIZE:\n",
    "        indices = np.linspace(0, len(graph_population) - 1, POPULATION_SIZE, dtype=int)\n",
    "        graph_population = [graph_population[i] for i in indices]\n",
    "\n",
    "    POPULATION = [ctk.from_graph(individual) for individual in graph_population]\n",
    "    POPULATION_SIZE = len(POPULATION)\n",
    "else:\n",
    "    POPULATION = [\n",
    "        ctk.from_graph(generate_random_individual(NUM_OF_MODULES))\n",
    "        for _ in range(POPULATION_SIZE)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baab38b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBTREES = [\n",
    "    ctk.collect_tree_hash_config_mode(individual, config=CONFIG)\n",
    "    for individual in POPULATION\n",
    "]\n",
    "\n",
    "COUNT_MATRIX_DICT = ctk.get_count_matrix(SUBTREES, CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6183f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TAKES THE MOST TIME\n",
    "POPULATION_IMGS = get_population_images(POPULATION_SIZE, scale=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab85a86",
   "metadata": {},
   "source": [
    "### HELPER FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e904a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_tfidf_transformer(count_matrix):\n",
    "    transformer = TfidfTransformer()\n",
    "    return transformer.fit_transform(count_matrix)\n",
    "\n",
    "def apply_umap_n2(count_matrix):\n",
    "    return umap.UMAP(init='random', random_state=42, transform_seed=42,n_jobs=1, metric=\"cosine\", n_neighbors=2).fit_transform(\n",
    "        count_matrix\n",
    "    )\n",
    "  \n",
    "def apply_umap_n10(count_matrix):\n",
    "    return umap.UMAP(init='random', random_state=42, transform_seed=42,n_jobs=1, metric=\"cosine\", n_neighbors=10).fit_transform(\n",
    "        count_matrix\n",
    "    )\n",
    "    \n",
    "def apply_umap_n20(count_matrix):\n",
    "    return umap.UMAP(init='random', random_state=42, transform_seed=42,n_jobs=1, metric=\"cosine\", n_neighbors=20).fit_transform(\n",
    "        count_matrix\n",
    "    )\n",
    "\n",
    "def apply_emb_to_dist(umap_emb_matrix):\n",
    "    condensed_distances = pdist(umap_emb_matrix, metric=\"euclidean\")\n",
    "    return squareform(condensed_distances)\n",
    "\n",
    "def apply_collapse_to_fitness(matrix):\n",
    "    return matrix.sum(axis=1) - matrix.diagonal()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99507aeb",
   "metadata": {},
   "source": [
    "### CALCULATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4fd2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basis ---\n",
    "count_cos_matrix_dict = ctk.matrix_dict_applier(COUNT_MATRIX_DICT, cosine_similarity)\n",
    "\n",
    "tfidf_matrix_dict = ctk.matrix_dict_applier(COUNT_MATRIX_DICT, apply_tfidf_transformer)\n",
    "tfidf_cos_matrix_dict = ctk.matrix_dict_applier(tfidf_matrix_dict, cosine_similarity)\n",
    "\n",
    "\n",
    "# umap ---\n",
    "umap_dict_n2 = ctk.matrix_dict_applier(COUNT_MATRIX_DICT, apply_umap_n2) \n",
    "umapdist_matrix_dict_n2 = ctk.matrix_dict_applier(umap_dict_n2, apply_emb_to_dist)\n",
    "\n",
    "# tfidf\n",
    "tfidf_umap_dict_n2 = ctk.matrix_dict_applier(tfidf_matrix_dict, apply_umap_n2) \n",
    "tfidf_umapdist_matrix_dict_n2 = ctk.matrix_dict_applier(tfidf_umap_dict_n2, apply_emb_to_dist)\n",
    "\n",
    "umap_dict_n10 = ctk.matrix_dict_applier(COUNT_MATRIX_DICT, apply_umap_n10) \n",
    "umapdist_matrix_dict_n10 = ctk.matrix_dict_applier(umap_dict_n10, apply_emb_to_dist)\n",
    "\n",
    "# tfidf\n",
    "tfidf_umap_dict_n10 = ctk.matrix_dict_applier(tfidf_matrix_dict, apply_umap_n10) \n",
    "tfidf_umapdist_matrix_dict_n10 = ctk.matrix_dict_applier(tfidf_umap_dict_n10, apply_emb_to_dist)\n",
    "\n",
    "umap_dict_n20 = ctk.matrix_dict_applier(COUNT_MATRIX_DICT, apply_umap_n20) \n",
    "umapdist_matrix_dict_n20 = ctk.matrix_dict_applier(umap_dict_n20, apply_emb_to_dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5db0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dimension reduction visualization\n",
    "UMAP_EMBEDDINGS = {\n",
    "    \"umap_emb_n2\": umap_dict_n2,\n",
    "    \"tfidf_umap_emb_n2\": tfidf_umap_dict_n2,\n",
    "    \n",
    "    \"umap_emb_n10\": umap_dict_n10,\n",
    "    \"tfidf_umap_emb_n10\": tfidf_umap_dict_n10,\n",
    "    \n",
    "    \"umap_emb_n20\": umap_dict_n20,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2f138a",
   "metadata": {},
   "source": [
    "### CUMULATIVE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbc8cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics applied per unique radius\n",
    "ALL_MATRIX_DATA = {\n",
    "    \"umap_dist_n2\": umapdist_matrix_dict_n2,\n",
    "    \"tfidf_umap_dist_n2\" : tfidf_umapdist_matrix_dict_n2,\n",
    "    \n",
    "    \"umap_dist_n10\": umapdist_matrix_dict_n10,\n",
    "    \"tfidf_umap_dist_n10\" : tfidf_umapdist_matrix_dict_n10,\n",
    "    \n",
    "    \"umap_dist_n20\": umapdist_matrix_dict_n20,\n",
    "    \n",
    "    \"count_cos\": count_cos_matrix_dict,\n",
    "    \"tfidf_cos\": tfidf_cos_matrix_dict,\n",
    "}\n",
    "\n",
    "# each radius contains the cumsum of the previous radiusses\n",
    "CUMULATIVE_MATRIX_DATA = {\n",
    "    \"umap_dist_n2\": get_cumsum_dict(umapdist_matrix_dict_n2),\n",
    "    \"tfidf_umap_dist_n2\" : get_cumsum_dict(tfidf_umapdist_matrix_dict_n2),\n",
    "    \n",
    "    \"umap_dist_n10\": get_cumsum_dict(umapdist_matrix_dict_n10),\n",
    "    \"tfidf_umap_dist_n10\" : get_cumsum_dict(tfidf_umapdist_matrix_dict_n10),\n",
    "    \n",
    "    \"umap_dist_n20\": get_cumsum_dict(umapdist_matrix_dict_n20),\n",
    "    \n",
    "    \"count_cos\": get_cumsum_dict(count_cos_matrix_dict),\n",
    "    \"tfidf_cos\": get_cumsum_dict(tfidf_cos_matrix_dict),\n",
    "}\n",
    "\n",
    "# sort based on the cumsums\n",
    "SORTED_IDX_DATA = {\n",
    "    \"umap_dist_n2\": sorted_idx_dict(CUMULATIVE_MATRIX_DATA[\"umap_dist_n2\"], max_first=False),\n",
    "    \"tfidf_umap_dist_n2\": sorted_idx_dict(CUMULATIVE_MATRIX_DATA[\"tfidf_umap_dist_n2\"], max_first=False),\n",
    "    \n",
    "    \"umap_dist_n10\": sorted_idx_dict(CUMULATIVE_MATRIX_DATA[\"umap_dist_n10\"], max_first=False),\n",
    "    \"tfidf_umap_dist_n10\": sorted_idx_dict(CUMULATIVE_MATRIX_DATA[\"tfidf_umap_dist_n10\"], max_first=False),\n",
    "    \n",
    "    \"umap_dist_n20\": sorted_idx_dict(CUMULATIVE_MATRIX_DATA[\"umap_dist_n20\"], max_first=False),\n",
    "    \n",
    "    \"count_cos\": sorted_idx_dict(CUMULATIVE_MATRIX_DATA[\"count_cos\"], max_first=True),\n",
    "    \"tfidf_cos\": sorted_idx_dict(CUMULATIVE_MATRIX_DATA[\"tfidf_cos\"], max_first=True),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c791f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitness (1d collapsed data) ---\n",
    "\n",
    "# seperate this sor fitness analysis\n",
    "# FITNESS_DATA = {\n",
    "#     'umapdist_fitness_n2': ctk.matrix_dict_applier(CUMULATIVE_MATRIX_DATA['umap_dist_n2'], apply_collapse_to_fitness),\n",
    "#     'tfidf_umapdist_fitness_n2': ctk.matrix_dict_applier(CUMULATIVE_MATRIX_DATA[\"tfidf_umap_dist_n2\"], apply_collapse_to_fitness),\n",
    "    \n",
    "#     'umapdist_fitness_n10': ctk.matrix_dict_applier(CUMULATIVE_MATRIX_DATA[\"umap_dist_n10\"], apply_collapse_to_fitness),\n",
    "#     'tfidf_umapdist_fitness_n10': ctk.matrix_dict_applier(CUMULATIVE_MATRIX_DATA[\"tfidf_umap_dist_n10\"], apply_collapse_to_fitness),\n",
    "    \n",
    "#     'count_cos_fitness': ctk.matrix_dict_applier(CUMULATIVE_MATRIX_DATA[\"count_cos\"], apply_collapse_to_fitness),\n",
    "#     'tfidf_cos_fitness': ctk.matrix_dict_applier(CUMULATIVE_MATRIX_DATA[\"tfidf_cos\"], apply_collapse_to_fitness),\n",
    "    \n",
    "#     # KDE density (not cumul-based)\n",
    "#     'umap_kde_dens_n2': ctk.matrix_dict_applier(umap_dict_n2, calculate_inverse_density_fitness_normalized),\n",
    "#     'umap_kde_dens_n10': ctk.matrix_dict_applier(umap_dict_n10, calculate_inverse_density_fitness_normalized),\n",
    "# }\n",
    "\n",
    "FITNESS_DATA = {\n",
    "    'umapdist_fitness_n2': ctk.matrix_dict_applier(umapdist_matrix_dict_n2, apply_collapse_to_fitness),\n",
    "    'tfidf_umapdist_fitness_n2': ctk.matrix_dict_applier(tfidf_umapdist_matrix_dict_n2, apply_collapse_to_fitness),\n",
    "    \n",
    "    'umapdist_fitness_n10': ctk.matrix_dict_applier(umapdist_matrix_dict_n10, apply_collapse_to_fitness),\n",
    "    'tfidf_umapdist_fitness_n10': ctk.matrix_dict_applier(tfidf_umapdist_matrix_dict_n10, apply_collapse_to_fitness),\n",
    "    \n",
    "    'count_cos_fitness': ctk.matrix_dict_applier(count_cos_matrix_dict, apply_collapse_to_fitness),\n",
    "    'tfidf_cos_fitness': ctk.matrix_dict_applier(tfidf_cos_matrix_dict, apply_collapse_to_fitness),\n",
    "}\n",
    "\n",
    "CUMULATIVE_FITNESS_DATA = {\n",
    "    'umapdist_fitness_n2': get_cumsum_dict(FITNESS_DATA['umapdist_fitness_n2']),    \n",
    "    'tfidf_umapdist_fitness_n2': get_cumsum_dict(FITNESS_DATA['tfidf_umapdist_fitness_n2']),\n",
    "    \n",
    "    'umapdist_fitness_n10': get_cumsum_dict(FITNESS_DATA['umapdist_fitness_n10']),\n",
    "    'tfidf_umapdist_fitness_n10': get_cumsum_dict(FITNESS_DATA['tfidf_umapdist_fitness_n10']),\n",
    "    \n",
    "    'count_cos_fitness': get_cumsum_dict(FITNESS_DATA['count_cos_fitness']),\n",
    "    'tfidf_cos_fitness': get_cumsum_dict(FITNESS_DATA['tfidf_cos_fitness']),\n",
    "}\n",
    "\n",
    "SORTED_FITNESS_IDX = {\n",
    "    'umapdist_fitness_n2': sorted_idx_dict(FITNESS_DATA['umapdist_fitness_n2'], max_first=False),\n",
    "    'tfidf_umapdist_fitness_n2': sorted_idx_dict(FITNESS_DATA['tfidf_umapdist_fitness_n2'], max_first=False),\n",
    "   \n",
    "    'umapdist_fitness_n10': sorted_idx_dict(FITNESS_DATA['umapdist_fitness_n10'], max_first=False),\n",
    "    'tfidf_umapdist_fitness_n10': sorted_idx_dict(FITNESS_DATA['tfidf_umapdist_fitness_n10'], max_first=False),\n",
    "    \n",
    "    'count_cos_fitness': sorted_idx_dict(FITNESS_DATA['count_cos_fitness'], max_first=True),\n",
    "    'tfidf_cos_fitness': sorted_idx_dict(FITNESS_DATA['tfidf_cos_fitness'], max_first=True),\n",
    "    \n",
    "    # KDE density\n",
    "    # 'umap_kde_dens_n2': sorted_idx_dict(FITNESS_DATA['umap_kde_dens_n2'], max_first=True),\n",
    "    # 'umap_kde_dens_n10': sorted_idx_dict(FITNESS_DATA['umap_kde_dens_n10'], max_first=True),\n",
    "}\n",
    "\n",
    "CUMULATIVE_SORTED_FITNESS_IDX = {\n",
    "    'umapdist_fitness_n2': sorted_idx_dict(CUMULATIVE_FITNESS_DATA['umapdist_fitness_n2'], max_first=False),\n",
    "    'tfidf_umapdist_fitness_n2': sorted_idx_dict(CUMULATIVE_FITNESS_DATA['tfidf_umapdist_fitness_n2'], max_first=False),\n",
    "   \n",
    "    'umapdist_fitness_n10': sorted_idx_dict(CUMULATIVE_FITNESS_DATA['umapdist_fitness_n10'], max_first=False),\n",
    "    'tfidf_umapdist_fitness_n10': sorted_idx_dict(CUMULATIVE_FITNESS_DATA['tfidf_umapdist_fitness_n10'], max_first=False),\n",
    "    \n",
    "    'count_cos_fitness': sorted_idx_dict(CUMULATIVE_FITNESS_DATA['count_cos_fitness'], max_first=True),\n",
    "    'tfidf_cos_fitness': sorted_idx_dict(CUMULATIVE_FITNESS_DATA['tfidf_cos_fitness'], max_first=True),\n",
    "    \n",
    "    # KDE density\n",
    "    # 'umap_kde_dens_n2': sorted_idx_dict(CUMULATIVE_FITNESS_DATA['umap_kde_dens_n2'], max_first=True),\n",
    "    # 'umap_kde_dens_n10': sorted_idx_dict(CUMULATIVE_FITNESS_DATA['umap_kde_dens_n10'], max_first=True),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a22c0e",
   "metadata": {},
   "source": [
    "### AGGEREGATED DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18533843",
   "metadata": {},
   "outputs": [],
   "source": [
    "AGG_COUNT_MATRIX_DICT = get_cumsum_dict(COUNT_MATRIX_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50b6eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basis ---\n",
    "agg_count_cos_matrix_dict = ctk.matrix_dict_applier(AGG_COUNT_MATRIX_DICT, cosine_similarity)\n",
    "\n",
    "agg_tfidf_matrix_dict = ctk.matrix_dict_applier(AGG_COUNT_MATRIX_DICT, apply_tfidf_transformer)\n",
    "agg_tfidf_cos_matrix_dict = ctk.matrix_dict_applier(agg_tfidf_matrix_dict, cosine_similarity)\n",
    "\n",
    "\n",
    "# umap ---\n",
    "agg_umap_dict_n2 = ctk.matrix_dict_applier(AGG_COUNT_MATRIX_DICT, apply_umap_n2) \n",
    "agg_umapdist_matrix_dict_n2 = ctk.matrix_dict_applier(agg_umap_dict_n2, apply_emb_to_dist)\n",
    "\n",
    "# tfidf\n",
    "agg_tfidf_umap_dict_n2 = ctk.matrix_dict_applier(agg_tfidf_matrix_dict, apply_umap_n2) \n",
    "agg_tfidf_umapdist_matrix_dict_n2 = ctk.matrix_dict_applier(agg_tfidf_umap_dict_n2, apply_emb_to_dist)\n",
    "\n",
    "agg_umap_dict_n10 = ctk.matrix_dict_applier(AGG_COUNT_MATRIX_DICT, apply_umap_n10) \n",
    "agg_umapdist_matrix_dict_n10 = ctk.matrix_dict_applier(agg_umap_dict_n10, apply_emb_to_dist)\n",
    "\n",
    "# tfidf\n",
    "agg_tfidf_umap_dict_n10 = ctk.matrix_dict_applier(agg_tfidf_matrix_dict, apply_umap_n10) \n",
    "agg_tfidf_umapdist_matrix_dict_n10 = ctk.matrix_dict_applier(agg_tfidf_umap_dict_n10, apply_emb_to_dist)\n",
    "\n",
    "agg_umap_dict_n20 = ctk.matrix_dict_applier(AGG_COUNT_MATRIX_DICT, apply_umap_n20) \n",
    "agg_umapdist_matrix_dict_n20 = ctk.matrix_dict_applier(agg_umap_dict_n20, apply_emb_to_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45850cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dimension reduction visualization\n",
    "AGG_UMAP_EMBEDDINGS = {\n",
    "    \"agg_umap_emb_n2\": agg_umap_dict_n2,\n",
    "    \"agg_tfidf_umap_emb_n2\": agg_tfidf_umap_dict_n2,\n",
    "    \n",
    "    \"agg_umap_emb_n10\": agg_umap_dict_n10,\n",
    "    \"agg_tfidf_umap_emb_n10\": agg_tfidf_umap_dict_n10,\n",
    "    \n",
    "    \"agg_umap_emb_n20\": agg_umap_dict_n20,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaea5327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics applied per unique radius\n",
    "AGG_MATRIX_DATA = {\n",
    "    \"agg_umap_dist_n2\": agg_umapdist_matrix_dict_n2,\n",
    "    \"agg_tfidf_umap_dist_n2\" : agg_tfidf_umapdist_matrix_dict_n2,\n",
    "    \n",
    "    \"agg_umap_dist_n10\": agg_umapdist_matrix_dict_n10,\n",
    "    \"agg_tfidf_umap_dist_n10\" : agg_tfidf_umapdist_matrix_dict_n10,\n",
    "    \n",
    "    \"agg_umap_dist_n20\": agg_umapdist_matrix_dict_n20,\n",
    "    \n",
    "    \"agg_count_cos\": agg_count_cos_matrix_dict,\n",
    "    \"agg_tfidf_cos\": agg_tfidf_cos_matrix_dict,\n",
    "}\n",
    "\n",
    "\n",
    "# sort based on the cumsums\n",
    "AGG_SORTED_IDX_DATA = {\n",
    "    \"agg_umap_dist_n2\": sorted_idx_dict(AGG_MATRIX_DATA[\"agg_umap_dist_n2\"], max_first=False),\n",
    "    \"agg_tfidf_umap_dist_n2\": sorted_idx_dict(AGG_MATRIX_DATA[\"agg_tfidf_umap_dist_n2\"], max_first=False),\n",
    "    \n",
    "    \"agg_umap_dist_n10\": sorted_idx_dict(AGG_MATRIX_DATA[\"agg_umap_dist_n10\"], max_first=False),\n",
    "    \"agg_tfidf_umap_dist_n10\": sorted_idx_dict(AGG_MATRIX_DATA[\"agg_tfidf_umap_dist_n10\"], max_first=False),\n",
    "    \n",
    "    \"agg_umap_dist_n20\": sorted_idx_dict(AGG_MATRIX_DATA[\"agg_umap_dist_n20\"], max_first=False),\n",
    "    \n",
    "    \"agg_count_cos\": sorted_idx_dict(AGG_MATRIX_DATA[\"agg_count_cos\"], max_first=True),\n",
    "    \"agg_tfidf_cos\": sorted_idx_dict(AGG_MATRIX_DATA[\"agg_tfidf_cos\"], max_first=True),\n",
    "}\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7f319f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitness (1d collapsed data) ---\n",
    "AGG_FITNESS_DATA = {\n",
    "    'agg_umapdist_fitness_n2': ctk.matrix_dict_applier(agg_umapdist_matrix_dict_n2, apply_collapse_to_fitness),\n",
    "    'agg_tfidf_umapdist_fitness_n2': ctk.matrix_dict_applier(agg_tfidf_umapdist_matrix_dict_n2, apply_collapse_to_fitness),\n",
    "    \n",
    "    'agg_umapdist_fitness_n10': ctk.matrix_dict_applier(agg_umapdist_matrix_dict_n10, apply_collapse_to_fitness),\n",
    "    'agg_tfidf_umapdist_fitness_n10': ctk.matrix_dict_applier(agg_tfidf_umapdist_matrix_dict_n10, apply_collapse_to_fitness),\n",
    "    \n",
    "    'agg_count_cos_fitness': ctk.matrix_dict_applier(agg_count_cos_matrix_dict, apply_collapse_to_fitness),\n",
    "    'agg_tfidf_cos_fitness': ctk.matrix_dict_applier(agg_tfidf_cos_matrix_dict, apply_collapse_to_fitness),\n",
    "    \n",
    "    #kde\n",
    "    # 'agg_umap_kde_dens_n2': ctk.matrix_dict_applier(agg_umap_dict_n2, calculate_inverse_density_fitness_normalized),\n",
    "    # 'agg_umap_kde_dens_n10': ctk.matrix_dict_applier(agg_umap_dict_n10, calculate_inverse_density_fitness_normalized),\n",
    "}\n",
    "\n",
    "AGG_SORTED_FITNESS_IDX = {\n",
    "    'agg_umapdist_fitness_n2': sorted_idx_dict(AGG_FITNESS_DATA['agg_umapdist_fitness_n2'], max_first=False),\n",
    "    'agg_tfidf_umapdist_fitness_n2': sorted_idx_dict(AGG_FITNESS_DATA['agg_tfidf_umapdist_fitness_n2'], max_first=False),\n",
    "\n",
    "    'agg_umapdist_fitness_n10': sorted_idx_dict(AGG_FITNESS_DATA['agg_umapdist_fitness_n10'], max_first=False),\n",
    "    'agg_tfidf_umapdist_fitness_n10': sorted_idx_dict(AGG_FITNESS_DATA['agg_tfidf_umapdist_fitness_n10'], max_first=False),\n",
    "    \n",
    "    'agg_count_cos_fitness': sorted_idx_dict(AGG_FITNESS_DATA['agg_count_cos_fitness'], max_first=True),\n",
    "    'agg_tfidf_cos_fitness': sorted_idx_dict(AGG_FITNESS_DATA['agg_tfidf_cos_fitness'], max_first=True),\n",
    "\n",
    "    #kde\n",
    "    # 'agg_umap_kde_dens_n2': sorted_idx_dict(AGG_FITNESS_DATA['agg_umap_kde_dens_n2'], max_first=True),\n",
    "    # 'agg_umap_kde_dens_n10': sorted_idx_dict(AGG_FITNESS_DATA['agg_umap_kde_dens_n10'], max_first=True),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166f77e9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c778a2",
   "metadata": {},
   "source": [
    "# | CUMULATIVE VECTORSPACE ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9fed61",
   "metadata": {},
   "source": [
    "## GLOBAL ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c957a2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocabulairy length etc? entropy?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de58d18",
   "metadata": {},
   "source": [
    "### 2D EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4f9bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# idxs = np.linspace(0, POPULATION_SIZE - 1, 10, dtype=int).tolist() # if you want to follow?\n",
    "idxs=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fe3596",
   "metadata": {},
   "outputs": [],
   "source": [
    "console.print(f'following {idxs}')\n",
    "plot_interactive_umap_grid(UMAP_EMBEDDINGS, POPULATION_IMGS, MAX_SHOW_RADIUS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e06c769",
   "metadata": {},
   "source": [
    "## CROSS COMPARISON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19344fb5",
   "metadata": {},
   "source": [
    "### HEATMAPS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fc0687",
   "metadata": {},
   "source": [
    "#### Matrix per radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67804300",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_comparison_heatmaps(ALL_MATRIX_DATA, MAX_SHOW_RADIUS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a128072",
   "metadata": {},
   "source": [
    "#### Cumulative matrix per radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0b648f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_comparison_heatmaps(CUMULATIVE_MATRIX_DATA, MAX_SHOW_RADIUS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc50eea",
   "metadata": {},
   "source": [
    "### HISTOGRAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972d2fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histograms(ALL_MATRIX_DATA, MAX_SHOW_RADIUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee6a688",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histograms(CUMULATIVE_MATRIX_DATA, MAX_SHOW_RADIUS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb44033b",
   "metadata": {},
   "source": [
    "### DYNAMIC ROBOT POSTER VIEWER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884f5caa",
   "metadata": {},
   "source": [
    "#### Most similair pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5eb340",
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_rank = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9624ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rows_for_radii(\n",
    "    cumulative_data=CUMULATIVE_MATRIX_DATA,\n",
    "    sorted_data=SORTED_IDX_DATA,\n",
    "    population_images=POPULATION_IMGS,\n",
    "    max_radius=MAX_SHOW_RADIUS,\n",
    "    pair_rank=similar_rank,\n",
    "    main_title=f\"Comparison Rank {np.abs(similar_rank)} (Most Similar PAIRS)\", \n",
    "    plot_up_to=True \n",
    "\n",
    ")\n",
    "\n",
    "similar_rank += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a9547a",
   "metadata": {},
   "source": [
    "#### Least similar pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca0c947",
   "metadata": {},
   "outputs": [],
   "source": [
    "dif_rank = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194bfb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rows_for_radii(\n",
    "    cumulative_data=CUMULATIVE_MATRIX_DATA,\n",
    "    sorted_data=SORTED_IDX_DATA,\n",
    "    population_images=POPULATION_IMGS,\n",
    "    max_radius=MAX_SHOW_RADIUS,\n",
    "    pair_rank=dif_rank,\n",
    "    main_title=f\"Comparison Rank {np.abs(dif_rank)} (Least Similar PAIRS)\",\n",
    "    plot_up_to=True \n",
    ")\n",
    "\n",
    "dif_rank -= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea83b3e5",
   "metadata": {},
   "source": [
    "## FITNESS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd75c42",
   "metadata": {},
   "source": [
    "### HISTOGRAMS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6620a2dd",
   "metadata": {},
   "source": [
    "##### PER RADIUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7204eb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histograms(FITNESS_DATA, MAX_SHOW_RADIUS, bins=POPULATION_SIZE//3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b035191",
   "metadata": {},
   "source": [
    "##### CUMULATIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8cb0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histograms(CUMULATIVE_FITNESS_DATA, MAX_SHOW_RADIUS, bins=POPULATION_SIZE//3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d986426d",
   "metadata": {},
   "source": [
    "### DYNAMIC ROBOT POSTER PLOTTER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb17174",
   "metadata": {},
   "source": [
    "#### Most diverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00199bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_rank = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c3abd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rows_for_radii(\n",
    "    cumulative_data=CUMULATIVE_FITNESS_DATA,\n",
    "    sorted_data=CUMULATIVE_SORTED_FITNESS_IDX,\n",
    "    population_images=POPULATION_IMGS,\n",
    "    max_radius=MAX_SHOW_RADIUS,\n",
    "    pair_rank=fit_rank,\n",
    "    main_title=f\"Top {np.abs(fit_rank)} Diverse ROBOTS\",\n",
    "    plot_up_to=True \n",
    ")\n",
    "\n",
    "fit_rank -= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60720c74",
   "metadata": {},
   "source": [
    "#### Least diverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc6487b",
   "metadata": {},
   "outputs": [],
   "source": [
    "unfit_rank = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e127423f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rows_for_radii(\n",
    "    cumulative_data=CUMULATIVE_FITNESS_DATA,\n",
    "    sorted_data=CUMULATIVE_SORTED_FITNESS_IDX,\n",
    "    population_images=POPULATION_IMGS,\n",
    "    max_radius=MAX_SHOW_RADIUS,\n",
    "    pair_rank=unfit_rank,\n",
    "    main_title=f\"Least {np.abs(unfit_rank) + 1} Diverse ROBOTS\",\n",
    "    plot_up_to=True \n",
    ")\n",
    "\n",
    "unfit_rank += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed24eb65",
   "metadata": {},
   "source": [
    "### WATERFALL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b35802",
   "metadata": {},
   "source": [
    "#### PER RADIUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b41137a",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = [66, 94]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7034ebe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_interactive_waterfall_grid(\n",
    "    metric_data=FITNESS_DATA, \n",
    "    sorted_data=SORTED_FITNESS_IDX,\n",
    "    population_images=POPULATION_IMGS, \n",
    "    max_show_radius=MAX_SHOW_RADIUS,\n",
    "    follow_idx_list=idxs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a399a6d",
   "metadata": {},
   "source": [
    "#### CUMULATIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1680dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_interactive_waterfall_grid(\n",
    "    metric_data=CUMULATIVE_FITNESS_DATA, \n",
    "    sorted_data=CUMULATIVE_SORTED_FITNESS_IDX,\n",
    "    population_images=POPULATION_IMGS, \n",
    "    max_show_radius=MAX_SHOW_RADIUS,\n",
    "    follow_idx_list=idxs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f06cb29",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e2a580",
   "metadata": {},
   "source": [
    "# | AGGREGATED VECTORSPACE ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92acc563",
   "metadata": {},
   "source": [
    "## GLOBAL ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a0d23e",
   "metadata": {},
   "source": [
    "### 2D EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28deff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs=[94, 96]\n",
    "# idxs = np.linspace(0, POPULATION_SIZE - 1, 10, dtype=int).tolist() # if you want to follow?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f66086a",
   "metadata": {},
   "outputs": [],
   "source": [
    "console.print(f'following {idxs}')\n",
    "plot_interactive_umap_grid(AGG_UMAP_EMBEDDINGS, POPULATION_IMGS, MAX_SHOW_RADIUS, follow_idx_list=idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ab36fd",
   "metadata": {},
   "source": [
    "## CROSS COMPARISON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1599d5",
   "metadata": {},
   "source": [
    "### HEATMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6be978",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_comparison_heatmaps(AGG_MATRIX_DATA, MAX_SHOW_RADIUS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b199279",
   "metadata": {},
   "source": [
    "### HISTOGRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d80bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histograms(AGG_MATRIX_DATA, MAX_SHOW_RADIUS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956f706e",
   "metadata": {},
   "source": [
    "### DYNAMIC ROBOT POSTER PLOTTER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e398d5b7",
   "metadata": {},
   "source": [
    "#### Most similar pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6ff3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_rank = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad244f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rows_for_radii(\n",
    "    cumulative_data=AGG_MATRIX_DATA,\n",
    "    sorted_data=AGG_SORTED_IDX_DATA,\n",
    "    population_images=POPULATION_IMGS,\n",
    "    max_radius=MAX_SHOW_RADIUS,\n",
    "    pair_rank=similar_rank,\n",
    "    main_title=f\"Comparison Rank {np.abs(similar_rank)} (Most Similar PAIRS)\",\n",
    "    plot_up_to=True \n",
    ")\n",
    "\n",
    "similar_rank += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440c8a09",
   "metadata": {},
   "source": [
    "#### Least similar pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201a9c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "dif_rank = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed14fdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rows_for_radii(\n",
    "    cumulative_data=AGG_MATRIX_DATA,\n",
    "    sorted_data=AGG_SORTED_IDX_DATA,\n",
    "    population_images=POPULATION_IMGS,\n",
    "    max_radius=MAX_SHOW_RADIUS,\n",
    "    pair_rank=dif_rank,\n",
    "    main_title=f\"Comparison Rank {np.abs(dif_rank)} (Least Similar PAIRS)\",\n",
    "    plot_up_to=True \n",
    ")\n",
    "\n",
    "dif_rank -= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ebb494",
   "metadata": {},
   "source": [
    "## FITNESS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8aa103a",
   "metadata": {},
   "source": [
    "### HISTOGRAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641bd8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histograms(AGG_FITNESS_DATA, MAX_SHOW_RADIUS, bins=POPULATION_SIZE//3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b8e713",
   "metadata": {},
   "source": [
    "### DYNAMIC ROBOT POSTER PLOTTER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac6435a",
   "metadata": {},
   "source": [
    "#### Most diverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4dd3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_rank = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f62c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rows_for_radii(\n",
    "    cumulative_data=AGG_FITNESS_DATA,\n",
    "    sorted_data=AGG_SORTED_FITNESS_IDX,\n",
    "    population_images=POPULATION_IMGS,\n",
    "    max_radius=MAX_SHOW_RADIUS,\n",
    "    pair_rank=fit_rank,\n",
    "    main_title=f\"Top {np.abs(fit_rank)} Diverse ROBOTS\",\n",
    "    plot_up_to=True \n",
    ")\n",
    "\n",
    "fit_rank -= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78d62d9",
   "metadata": {},
   "source": [
    "#### Least diverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dfd52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "unfit_rank = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d37dc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rows_for_radii(\n",
    "    cumulative_data=AGG_FITNESS_DATA,\n",
    "    sorted_data=AGG_SORTED_FITNESS_IDX,\n",
    "    population_images=POPULATION_IMGS,\n",
    "    max_radius=MAX_SHOW_RADIUS,\n",
    "    pair_rank=unfit_rank,\n",
    "    main_title=f\"Least {np.abs(unfit_rank)+1} Diverse ROBOTS\",\n",
    "    plot_up_to=True \n",
    ")\n",
    "\n",
    "unfit_rank += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66af8236",
   "metadata": {},
   "source": [
    "### WATERFALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ea2818",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=[8,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3276a5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_interactive_waterfall_grid(\n",
    "    metric_data=AGG_FITNESS_DATA, \n",
    "    sorted_data=AGG_SORTED_FITNESS_IDX,\n",
    "    population_images=POPULATION_IMGS, \n",
    "    max_show_radius=MAX_SHOW_RADIUS,\n",
    "    follow_idx_list=idx\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba332c6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936bfa83",
   "metadata": {},
   "source": [
    "## ARBITRARY TESTING HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56341b6",
   "metadata": {},
   "source": [
    "### follow idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f622aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = [66, 94]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e3af79",
   "metadata": {},
   "outputs": [],
   "source": [
    "console.print(f'following {idxs}')\n",
    "plot_interactive_umap_grid(UMAP_EMBEDDINGS, POPULATION_IMGS, MAX_SHOW_RADIUS, follow_idx_list=idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6511b8c3",
   "metadata": {},
   "source": [
    "### interactive heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1476b8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if POPULATION_SIZE < 20:\n",
    "    plot_interactive_heatmaps(ALL_MATRIX_DATA, POPULATION_IMGS, MAX_SHOW_RADIUS)\n",
    "    plot_interactive_heatmaps(CUMULATIVE_MATRIX_DATA, POPULATION_IMGS, MAX_SHOW_RADIUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e52db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "console.print(COUNT_MATRIX_DICT[0][11])\n",
    "console.print(COUNT_MATRIX_DICT[0][32])\n",
    "console.print(COUNT_MATRIX_DICT[0][84])\n",
    "console.print(COUNT_MATRIX_DICT[0][15])\n",
    "\n",
    "\n",
    "console.print(SUBTREES[11])\n",
    "console.print(SUBTREES[32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2279b7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3507f6e",
   "metadata": {},
   "source": [
    "# TODO REFINE THIS!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f339f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_interactive_waterfall_grid(\n",
    "    metric_data=FITNESS_DATA, \n",
    "    sorted_data=SORTED_FITNESS_IDX,\n",
    "    population_images=POPULATION_IMGS, \n",
    "    max_show_radius=MAX_SHOW_RADIUS,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
