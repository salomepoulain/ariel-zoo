{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f3cd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library\n",
    "import json\n",
    "import os\n",
    "from collections import Counter, defaultdict\n",
    "from collections.abc import Callable\n",
    "from hashlib import sha256\n",
    "from pathlib import Path\n",
    "from typing import Any, Never\n",
    "import collections.abc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Third-party libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from joblib import Parallel, delayed\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "from networkx import DiGraph\n",
    "from rich.console import Console\n",
    "from rich.progress import track\n",
    "\n",
    "from ariel.body_phenotypes.robogen_lite.config import (\n",
    "    NUM_OF_FACES,\n",
    "    NUM_OF_ROTATIONS,\n",
    "    NUM_OF_TYPES_OF_MODULES,\n",
    ")\n",
    "from ariel.body_phenotypes.robogen_lite.decoders.hi_prob_decoding import (\n",
    "    HighProbabilityDecoder,\n",
    ")\n",
    "from ariel.body_phenotypes.robogen_lite.decoders.visualize_tree import (\n",
    "    visualize_tree_from_graph,\n",
    ")\n",
    "\n",
    "# Local libraries\n",
    "from ariel.body_phenotypes.robogen_lite.modules.brick import BRICK_MASS\n",
    "from ariel.body_phenotypes.robogen_lite.modules.core import CORE_MASS\n",
    "from ariel.body_phenotypes.robogen_lite.modules.hinge import (\n",
    "    ROTOR_MASS,\n",
    "    STATOR_MASS,\n",
    ")\n",
    "\n",
    "console = Console()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626efb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global constants\n",
    "SCRIPT_NAME = \"Initial\"\n",
    "CWD = Path.cwd()\n",
    "DATA = Path(CWD / \"__data__\" / SCRIPT_NAME)\n",
    "DATA.mkdir(exist_ok=True)\n",
    "SEED = 40\n",
    "\n",
    "# Global functions\n",
    "console = Console()\n",
    "RNG = np.random.default_rng(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81edc0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_body(num_modules: int = 20) -> DiGraph:\n",
    "    \"\"\"Generate random robot with HighProbabilityDecoder.\"\"\"\n",
    "\n",
    "    # \"Type\" probability space\n",
    "    type_probability_space = RNG.random(\n",
    "        size=(num_modules, NUM_OF_TYPES_OF_MODULES),\n",
    "        dtype=np.float32,\n",
    "    )\n",
    "\n",
    "    # \"Connection\" probability space\n",
    "    conn_probability_space = RNG.random(\n",
    "        size=(num_modules, num_modules, NUM_OF_FACES),\n",
    "        dtype=np.float32,\n",
    "    )\n",
    "\n",
    "    # \"Rotation\" probability space\n",
    "    rotation_probability_space = RNG.random(\n",
    "        size=(num_modules, NUM_OF_ROTATIONS),\n",
    "        dtype=np.float32,\n",
    "    )\n",
    "\n",
    "    # Decode the high-probability graph\n",
    "    hpd = HighProbabilityDecoder(num_modules)\n",
    "    hpd.probability_matrices_to_graph(\n",
    "        type_probability_space,\n",
    "        conn_probability_space,\n",
    "        rotation_probability_space,\n",
    "    )\n",
    "\n",
    "    # Decode the high-probability graph\n",
    "    hpd = HighProbabilityDecoder(num_modules)\n",
    "    return hpd.probability_matrices_to_graph(\n",
    "        type_probability_space,\n",
    "        conn_probability_space,\n",
    "        rotation_probability_space,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e4d21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run(\n",
    "#     robot: CoreModule,\n",
    "#     *,\n",
    "#     with_viewer: bool = False,\n",
    "# ) -> None:\n",
    "#     \"\"\"Entry point.\"\"\"\n",
    "#     # MuJoCo configuration\n",
    "#     viz_options = mujoco.MjvOption()  # visualization of various elements\n",
    "\n",
    "#     # Visualization of the corresponding model or decoration element\n",
    "#     viz_options.flags[mujoco.mjtVisFlag.mjVIS_TRANSPARENT] = True\n",
    "#     viz_options.flags[mujoco.mjtVisFlag.mjVIS_ACTUATOR] = True\n",
    "#     viz_options.flags[mujoco.mjtVisFlag.mjVIS_BODYBVH] = True\n",
    "\n",
    "#     # MuJoCo basics\n",
    "#     world = TiltedFlatWorld()\n",
    "\n",
    "#     # Set random colors for geoms\n",
    "#     for i in range(len(robot.spec.geoms)):\n",
    "#         robot.spec.geoms[i].rgba[-1] = 0.5\n",
    "\n",
    "#     # Spawn the robot at the world\n",
    "#     world.spawn(robot.spec)\n",
    "\n",
    "#     # Compile the model\n",
    "#     model = world.spec.compile()\n",
    "#     data = mujoco.MjData(model)\n",
    "\n",
    "#     # Save the model to XML\n",
    "#     xml = world.spec.to_xml()\n",
    "#     with (DATA / f\"{SCRIPT_NAME}.xml\").open(\"w\", encoding=\"utf-8\") as f:\n",
    "#         f.write(xml)\n",
    "\n",
    "#     # Number of actuators and DoFs\n",
    "#     console.log(f\"DoF (model.nv): {model.nv}, Actuators (model.nu): {model.nu}\")\n",
    "\n",
    "#     # Reset state and time of simulation\n",
    "#     mujoco.mj_resetData(model, data)\n",
    "\n",
    "#     # Render\n",
    "#     # single_frame_renderer(model, data, steps=10)\n",
    "\n",
    "#     # View\n",
    "#     if with_viewer:\n",
    "#         viewer.launch(model=model, data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e4673c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delta = 10000  # just a random nr that bigger than 0.1\n",
    "# diversity = 0\n",
    "# nr_of_blocks = []\n",
    "# old_avg_b = 0\n",
    "# old_avg_h = 0\n",
    "# nr_of_hinges = []\n",
    "# learnability = 0  # maybe later\n",
    "# graph_list = []\n",
    "# while delta > 0.00001:\n",
    "#     graph = generate_body()\n",
    "#     graph_list.append(graph)\n",
    "#     graph = dict(graph.nodes)\n",
    "#     hinges = sum(graph[node][\"type\"] == \"HINGE\" for node in graph)\n",
    "#     blocks = sum(graph[node][\"type\"] == \"BRICK\" for node in graph)\n",
    "#     nr_of_blocks.append(blocks)\n",
    "#     nr_of_hinges.append(hinges)\n",
    "\n",
    "#     # skip the first 100\n",
    "#     if len(nr_of_blocks) < 100:\n",
    "#         continue\n",
    "\n",
    "#     # go until we broke\n",
    "#     new_avg_b = np.average(nr_of_blocks)\n",
    "#     new_avg_h = np.average(nr_of_hinges)\n",
    "#     delta = max(abs(old_avg_b - new_avg_b), abs(old_avg_h - new_avg_h))\n",
    "\n",
    "#     if len(graph_list) >= 100_000:\n",
    "#         break\n",
    "\n",
    "#     old_avg_b = new_avg_b\n",
    "#     old_avg_h = new_avg_h\n",
    "\n",
    "# print(\n",
    "#     f\"Done!\\nEnded with a delta of {max(abs(old_avg_b - new_avg_b), abs(old_avg_h - new_avg_h))}\\nThe avg nr of blocks are: {new_avg_b}\\nThe avg nr of hinges is: {new_avg_h}\\nConcluded after {len(graph_list)} generated robots!\"\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48509caa",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a07edc4",
   "metadata": {},
   "source": [
    "### Functions for analysis on individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5d9af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_module_counts(individual: DiGraph) -> dict[str, int]:\n",
    "    counts: dict[str, int] = {\n",
    "        \"core\": sum(\n",
    "            data[\"type\"] == \"CORE\" for _, data in individual.nodes(data=True)\n",
    "        ),\n",
    "        \"brick\": sum(\n",
    "            data[\"type\"] == \"BRICK\" for _, data in individual.nodes(data=True)\n",
    "        ),\n",
    "        \"hinge\": sum(\n",
    "            data[\"type\"] == \"HINGE\" for _, data in individual.nodes(data=True)\n",
    "        ),\n",
    "        \"none\": sum(\n",
    "            data[\"type\"] == \"NONE\" for _, data in individual.nodes(data=True)\n",
    "        ),\n",
    "        \"edges\": len(individual.edges()),\n",
    "    }\n",
    "    counts[\"not-none\"] = counts[\"core\"] + counts[\"brick\"] + counts[\"hinge\"]\n",
    "    assert counts[\"core\"] == 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da2c55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_mass(individual: DiGraph) -> dict[str, float]:\n",
    "    counts = analyze_module_counts(individual)\n",
    "    core_mass = counts[\"core\"] * CORE_MASS\n",
    "    brick_tot_mass = counts[\"brick\"] * BRICK_MASS\n",
    "    hinge_tot_mass = counts[\"hinge\"] * (ROTOR_MASS + STATOR_MASS)\n",
    "    total_mass = core_mass + brick_tot_mass + hinge_tot_mass\n",
    "    return {\"mass\": total_mass}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd620555",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_json_hash(individual: DiGraph) -> dict[str, str]:\n",
    "    \"\"\"Return a SHA-256 hash of a deterministic representation of the graph.\"\"\"\n",
    "    # Collect nodes and edges with attributes, sorted for determinism\n",
    "    nodes = sorted([(n, dict(individual.nodes[n])) for n in individual.nodes()])\n",
    "    edges = sorted([\n",
    "        (u, v, dict(individual.edges[u, v])) for u, v in individual.edges()\n",
    "    ])\n",
    "    # Create a canonical dict\n",
    "    canonical = {\"nodes\": nodes, \"edges\": edges}\n",
    "    # Hash the canonical JSON string\n",
    "    hash_string = sha256(\n",
    "        json.dumps(canonical, sort_keys=True).encode(\"utf-8\"),\n",
    "    ).hexdigest()\n",
    "    return {\"hash\": hash_string}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7235f8",
   "metadata": {},
   "source": [
    "### Parallel running method for individual analysis data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb02d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_individual(\n",
    "    analyzers: Callable[[DiGraph], dict[str, Any]], num_modules=None,\n",
    "):\n",
    "    individual = generate_body(num_modules) if num_modules else generate_body()\n",
    "    results = {\"population\": [individual]}\n",
    "    for analyzer in analyzers:\n",
    "        results.update(analyzer(individual))\n",
    "    return results\n",
    "\n",
    "\n",
    "def analyze_population(\n",
    "    population_size: int,\n",
    "    *,\n",
    "    num_modules: int | None = None,\n",
    "    analyzers: Callable[[DiGraph], dict[str, Any]] | None = None,\n",
    "    n_jobs: int = -1,\n",
    ") -> tuple[dict[str, Any], list[DiGraph]]:\n",
    "    if analyzers is None:\n",
    "        analyzers = [analyze_module_counts, analyze_mass, analyze_json_hash]\n",
    "\n",
    "    if n_jobs != 1:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    if n_jobs == -1:\n",
    "        available_cpus = os.cpu_count()\n",
    "        if available_cpus is not None and available_cpus > 2:\n",
    "            n_jobs = available_cpus - 2\n",
    "        elif available_cpus is not None and available_cpus > 1:\n",
    "            n_jobs = available_cpus - 1\n",
    "        else:\n",
    "            n_jobs = 1\n",
    "\n",
    "    console.log(f\"Using {n_jobs} cpu(s)\")\n",
    "    console.log(f\"Starting analysis of {population_size} individuals...\")\n",
    "\n",
    "    # Parallel execution with progress bar\n",
    "    with Parallel(n_jobs=n_jobs) as parallel:\n",
    "        results = parallel(\n",
    "            delayed(analyze_individual)(analyzers)\n",
    "            for _ in track(\n",
    "                range(population_size),\n",
    "                description=\"Analyzing population\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "    properties_dict = defaultdict(list)\n",
    "    # cast(results, dict)\n",
    "    for result in results:\n",
    "        for key, value in result.items():\n",
    "            properties_dict[key].append(value)\n",
    "\n",
    "    console.log(\"Analysis complete.\")\n",
    "    final_dict = dict(properties_dict)\n",
    "    population = final_dict.pop(\"population\")\n",
    "    return final_dict, population"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0cbe07",
   "metadata": {},
   "source": [
    "### Visualization methods for the analysis on a population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1693e9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_boxplot_from_dict(\n",
    "    properties_dict: dict[str, Any],\n",
    "    keys: list[str] | None = None,\n",
    ") -> None:\n",
    "    # If no keys provided, plot all except 'population'\n",
    "    if keys is None:\n",
    "        keys = list(properties_dict.keys())\n",
    "    # Prepare data for seaborn\n",
    "    data = []\n",
    "    labels = []\n",
    "    for key in keys:\n",
    "        if key in properties_dict:\n",
    "            data.append(properties_dict[key])\n",
    "            labels.append(key)\n",
    "    # Create boxplot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(data=data)\n",
    "    plt.xticks(ticks=range(len(labels)), labels=labels)\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.title(\"Boxplot of Robot Properties\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9596215f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_histogram_from_dict(\n",
    "    properties_dict: dict[str, Any],\n",
    "    keys: list[str] | None = None,\n",
    "    bins: int = 30,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Draw a grouped histogram of the selected keys.\n",
    "    For string-valued keys (e.g., hashes), plot the distribution of their frequencies (separately).\n",
    "    For numeric keys, plot all together in one histogram.\n",
    "    Title is the key names if there are fewer than 3, otherwise \"Histogram of Robot Properties\".\n",
    "    \"\"\"\n",
    "    if keys is None:\n",
    "        keys = list(properties_dict.keys())\n",
    "\n",
    "    valid_keys = [k for k in keys if k in properties_dict]\n",
    "\n",
    "    # Check if all selected keys are numeric\n",
    "    if all(isinstance(properties_dict[k][0], (int, float)) for k in valid_keys):\n",
    "        # Plot all numeric keys together\n",
    "        data = [properties_dict[k] for k in valid_keys]\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        n, bins_, _patches = plt.hist(\n",
    "            data,\n",
    "            bins=bins,\n",
    "            label=valid_keys,\n",
    "            edgecolor=\"black\",\n",
    "            linewidth=1.2,\n",
    "            alpha=0.8,\n",
    "            histtype=\"bar\",\n",
    "            rwidth=0.9,\n",
    "        )\n",
    "        total = n.sum()\n",
    "        plt.gca().yaxis.set_major_formatter(PercentFormatter(xmax=total))\n",
    "        plt.xlabel(\"Value\")\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        plt.legend()\n",
    "        plt.title(\n",
    "            \", \".join(valid_keys)\n",
    "            if len(valid_keys) <= 3\n",
    "            else \"Histogram of Robot Properties\",\n",
    "        )\n",
    "        plt.show()\n",
    "    else:\n",
    "        # Plot string-valued keys separately\n",
    "        for key in valid_keys:\n",
    "            values = properties_dict[key]\n",
    "            if not values:\n",
    "                continue\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            if isinstance(values[0], str):\n",
    "                counts = Counter(values)\n",
    "                freqs = list(counts.values())\n",
    "                n, bins_, _patches = plt.hist(\n",
    "                    freqs,\n",
    "                    bins=bins,\n",
    "                    edgecolor=\"black\",\n",
    "                    linewidth=1.2,\n",
    "                    alpha=0.8,\n",
    "                    rwidth=0.9,\n",
    "                    label=[key],\n",
    "                    histtype=\"bar\",\n",
    "                )\n",
    "                total = n.sum()\n",
    "                plt.gca().yaxis.set_major_formatter(\n",
    "                    PercentFormatter(xmax=total),\n",
    "                )\n",
    "                plt.xlabel(\"Genotype frequency\")\n",
    "                plt.ylabel(\"Number of unique genotypes\")\n",
    "                plt.title(key)\n",
    "                plt.legend()\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a628ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistical_df_from_dict(\n",
    "    properties_dict: dict[str, Any],\n",
    "    keys: list[str] | None = None,\n",
    "    save_file: Path | str | None = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each key in properties_dict:\n",
    "      - If numeric: mean, std, median, count, Q1, Q3, outlier indexes, num_outliers, uniques.\n",
    "      - If non-numeric: key, count, uniques.\n",
    "    Returns a DataFrame with correct dtypes.\n",
    "    \"\"\"\n",
    "    if keys is None:\n",
    "        keys = list(properties_dict)\n",
    "\n",
    "    rows = []\n",
    "    for key in keys:\n",
    "        values = properties_dict[key]\n",
    "        if not values:\n",
    "            continue\n",
    "        uniques = len(set(values))\n",
    "        if isinstance(values[0], (float, int)):\n",
    "            arr = np.asarray(values, dtype=float)\n",
    "            mean = arr.mean()\n",
    "            std = arr.std(ddof=1)\n",
    "            median = np.median(arr)\n",
    "            q1 = np.percentile(arr, 25)\n",
    "            q3 = np.percentile(arr, 75)\n",
    "            iqr = q3 - q1\n",
    "            lower = q1 - 1.5 * iqr\n",
    "            upper = q3 + 1.5 * iqr\n",
    "            outlier_indexes = np.where((arr < lower) | (arr > upper))[\n",
    "                0\n",
    "            ].tolist()\n",
    "            row = {\n",
    "                \"key\": key,\n",
    "                \"count\": len(arr),\n",
    "                \"uniques\": int(uniques),\n",
    "                \"mean\": float(mean),\n",
    "                \"std\": float(std),\n",
    "                \"median\": float(median),\n",
    "                \"Q1\": float(q1),\n",
    "                \"Q3\": float(q3),\n",
    "                \"num_outliers\": len(outlier_indexes),\n",
    "                \"outlier_indexes\": outlier_indexes,\n",
    "            }\n",
    "        else:\n",
    "            row = {\n",
    "                \"key\": key,\n",
    "                \"count\": len(values),\n",
    "                \"uniques\": int(uniques),\n",
    "                \"mean\": None,\n",
    "                \"std\": None,\n",
    "                \"median\": None,\n",
    "                \"Q1\": None,\n",
    "                \"Q3\": None,\n",
    "                \"num_outliers\": None,\n",
    "                \"outlier_indexes\": None,\n",
    "            }\n",
    "        rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame.from_records(rows)\n",
    "    df = df.set_index(\"key\")\n",
    "\n",
    "    # Set dtypes explicitly\n",
    "    df[\"count\"] = df[\"count\"].astype(\"Int64\")\n",
    "    df[\"uniques\"] = df[\"uniques\"].astype(\"Int64\")\n",
    "    for col in [\"mean\", \"std\", \"median\", \"Q1\", \"Q3\"]:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    df[\"num_outliers\"] = df[\"num_outliers\"].astype(\"Int64\")\n",
    "    df[\"outlier_indexes\"] = df[\"outlier_indexes\"].astype(object)\n",
    "\n",
    "    if save_file:\n",
    "        df.to_csv(save_file)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63223e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_df_from_list(value_list: list[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns a DataFrame with:\n",
    "      - index: hash value\n",
    "      - count: number of times the hash appears\n",
    "      - indexes: list of indexes in the original list where the hash appears.\n",
    "    \"\"\"\n",
    "    index_dict = defaultdict(list)\n",
    "    for idx, h in enumerate(value_list):\n",
    "        index_dict[h].append(idx)\n",
    "\n",
    "    results = []\n",
    "    for h, idxs in index_dict.items():\n",
    "        results.append({\n",
    "            \"value\": h,\n",
    "            \"count\": len(idxs),\n",
    "            \"indexes\": idxs,\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    return df.set_index(\"value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf37376",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519c7521",
   "metadata": {},
   "source": [
    "### Running the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56489ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set n_jobs = 1 to not use parallelization. MUST be used rn\n",
    "properties_dict, population = analyze_population(100_000, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a052ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_boxplot_from_dict(properties_dict)\n",
    "\n",
    "create_histogram_from_dict(properties_dict, keys=[\"brick\", \"hinge\", \"none\"])\n",
    "create_histogram_from_dict(properties_dict, keys=[\"not-none\"])\n",
    "create_histogram_from_dict(properties_dict, keys=[\"mass\"])\n",
    "create_histogram_from_dict(properties_dict, keys=[\"edges\"])\n",
    "create_histogram_from_dict(properties_dict, keys=[\"hash\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f606a9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df = statistical_df_from_dict(properties_dict)\n",
    "console.print(stats_df)\n",
    "\n",
    "console.rule(style=\"rule.line dim\")\n",
    "\n",
    "# To get the unique counts per property\n",
    "count_df = count_df_from_list(properties_dict[\"edges\"])\n",
    "console.print(count_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e91cf25",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6468e55b",
   "metadata": {},
   "source": [
    "### Visualize Outliers Interactively"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed630879",
   "metadata": {},
   "source": [
    "Visualize individuals from a key value dictionary where value contains indexes of the individuals from the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981b93e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class IndividualVisualizer:\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         index_dict: dict,\n",
    "#         population: list,\n",
    "#         console=None,\n",
    "#     ) -> None:\n",
    "#         \"\"\"\n",
    "#         index_dict: dict mapping keys to lists of individual indexes (may be empty).\n",
    "#         population: list of individuals (e.g., DiGraph objects).\n",
    "#         console: rich.console.Console instance for printing (optional).\n",
    "#         \"\"\"\n",
    "#         # self._index_dict = {\n",
    "#         #     k: v\n",
    "#         #     for k, v in index_dict.items()\n",
    "#         #     if isinstance(v, (list, tuple, set))\n",
    "#         #     and v  # only non-empty lists/tuples/sets\n",
    "#         # }\n",
    "#         self._dict = self._filter_nested_index_dict(index_dict)\n",
    "#         self._keys = self._create_key_list(self._dict)\n",
    "#         print(self._dict)\n",
    "#         print(self._keys)\n",
    "        \n",
    "#         self._current_nested_idx = 0\n",
    "#         self._nested_idx_dict = 0\n",
    "        \n",
    "#         self._population = population\n",
    "#         # self._key_index = 0\n",
    "#         self._individual_index = 0\n",
    "#         self._direction = 1\n",
    "#         self._console = console or Console()\n",
    "\n",
    "#     def forward(self):\n",
    "#         # if (self._nested_idx_dict\n",
    "        \n",
    "#         # only go forward if possible\n",
    "        \n",
    "#         self._nested_idx_dict[self._current_nested_idx] += 1\n",
    "#         self._current_nested_idx += 1\n",
    "#         self._nested_idx_dict[self._current_nested_idx] = 0\n",
    "        \n",
    "#     def backward(self):\n",
    "#         # only go backwards if possible\n",
    "        \n",
    "#         self._nested_idx_dict.pop(self._current_nested_idx)\n",
    "#         self._current_nested_idx -= 1\n",
    "#         self._nested_idx_dict[self._current_nested_idx] -= 1\n",
    "\n",
    "#     def retrieve_key(self):\n",
    "#         keys, values = \n",
    "        \n",
    "#         for key, value in self._nested_idx_dict.items():\n",
    "#             that_dict = that_dict[list[value -1]]\n",
    "\n",
    "#     def _filter_nested_index_dict(self, index_dict):\n",
    "#         \"\"\"\n",
    "#         Recursively filters a dictionary, keeping only keys whose values are:\n",
    "#         1. A nested dictionary that, after recursive filtering, is not empty.\n",
    "#         2. A non-empty list, tuple, or set containing only integers.\n",
    "        \n",
    "#         Args:\n",
    "#             index_dict (dict): The dictionary (potentially nested) to filter.\n",
    "\n",
    "#         Returns:\n",
    "#             dict: The filtered dictionary, preserving structure.\n",
    "#         \"\"\"\n",
    "#         if not isinstance(index_dict, collections.abc.Mapping):\n",
    "#             raise TypeError\n",
    "\n",
    "#         filtered_dict = {}\n",
    "#         for k, v in index_dict.items():\n",
    "#             if isinstance(v, collections.abc.Mapping):\n",
    "#                 # Case 1: Nested dictionary.  and keep if the result is non-empty.\n",
    "#                 filtered_v = self._filter_nested_index_dict(v)\n",
    "#                 if filtered_v:\n",
    "#                     filtered_dict[k] = filtered_v\n",
    "#             else:\n",
    "#                 # Case 2: Leaf node. Check if it's a non-empty list/tuple/set of ints.\n",
    "#                 is_valid_list = (\n",
    "#                     isinstance(v, (list, tuple, set)) and \n",
    "#                     v and \n",
    "#                     all(isinstance(item, int) for item in v)\n",
    "#                 )\n",
    "                \n",
    "#                 if is_valid_list:\n",
    "#                     filtered_dict[k] = v\n",
    "                \n",
    "#         return filtered_dict\n",
    "\n",
    "#     def _create_key_list(self, dict_of_dicts: dict) -> list:\n",
    "#         # if not isinstance(data, collections.abc.Mapping):\n",
    "#         #     return []\n",
    "#         result = []\n",
    "#         for key, value in dict_of_dicts.items():\n",
    "#             result.append(key)\n",
    "#             if isinstance(value, collections.abc.Mapping):\n",
    "#                 nested_keys_list = self._create_key_list(value)\n",
    "#                 result.append(nested_keys_list)\n",
    "#         return result \n",
    "\n",
    "#     def get_count_from_index(self) -> Never:\n",
    "#         \"\"\"\n",
    "#         Would be cool to select the counts? so switch from main_key to count_key?\n",
    "#         maybe the index_dict is just smart and if it contains a dict, it will createa a sub key selection method??\n",
    "#         \"\"\"\n",
    "#         raise NotImplementedError\n",
    "\n",
    "#     def select_key(self, index=None) -> None:\n",
    "#         if not self._keys:\n",
    "#             self._console.print(\"[red]No keys with individuals found.[/red]\")\n",
    "#             return\n",
    "\n",
    "#         if index is not None:\n",
    "#             if 0 <= index < len(self._keys):\n",
    "#                 self._key_index = index\n",
    "#                 self._individual_index = 0\n",
    "\n",
    "#             self._console.print(\"[red]Index for key out of bounds[/red]\")\n",
    "#             return\n",
    "#         self._key_index = (self._key_index + self._direction) % len(\n",
    "#             self._keys,\n",
    "#         )\n",
    "#         self._individual_index = 0\n",
    "\n",
    "#         index_count = [len(self._dict[key]) for key in self._keys]\n",
    "#         selected_key = self._keys[self._key_index]\n",
    "#         selected_count = index_count[self._key_index]\n",
    "#         key_lines = []\n",
    "#         display_key = selected_key\n",
    "#         if isinstance(selected_key, str):\n",
    "#             max_len = 20\n",
    "#             display_key = (\n",
    "#                 (selected_key[:max_len] + \"…\")\n",
    "#                 if len(selected_key) > max_len\n",
    "#                 else selected_key\n",
    "#             )\n",
    "#         key_lines.append(\n",
    "#             f\"[bold underline]Selected: {self._key_index}/{len(self._keys)} | {display_key} ({selected_count} indexes)[/bold underline]\\n\",\n",
    "#         )\n",
    "#         for i, (key, total_indexes) in enumerate(\n",
    "#             zip(self._keys, index_count, strict=False),\n",
    "#         ):\n",
    "#             if i == self._key_index:\n",
    "#                 key_lines.append(\n",
    "#                     f\"[bold green]{i:>3} > {key} <[/bold green] [yellow]({total_indexes} indexes)[/yellow]\",\n",
    "#                 )\n",
    "#             else:\n",
    "#                 key_lines.append(\n",
    "#                     f\"{i:>3} {key} [dim]({total_indexes} individuals)[/dim]\",\n",
    "#                 )\n",
    "#         self._console.print(\"\\n\".join(key_lines))\n",
    "\n",
    "#     def _print_direction(self) -> None:\n",
    "#         arrow = \"→\" if self._direction == 1 else \"←\"\n",
    "#         self._console.print(\n",
    "#             f\"[cyan]Direction: {'forward' if self._direction == 1 else 'backward'} {arrow}[/cyan]\",\n",
    "#         )\n",
    "\n",
    "#     def toggle_direction(self) -> None:\n",
    "#         self._direction = -self._direction\n",
    "#         arrow = \"→\" if self._direction == 1 else \"←\"\n",
    "#         self._console.print(\n",
    "#             f\"[cyan]Direction toggled. Now: {'forward' if self._direction == 1 else 'backward'} {arrow}[/cyan]\",\n",
    "#         )\n",
    "\n",
    "#     def cycle_through_individual_index(self):\n",
    "#         indexes = self._get_index_list()\n",
    "#         if indexes:\n",
    "#             self._individual_index = (\n",
    "#                 self._individual_index + self._direction\n",
    "#             ) % len(indexes)\n",
    "#         self._show_current_selection()\n",
    "#         return self._get_current_individual_value()\n",
    "\n",
    "#     def visualize_individual(\n",
    "#         self,\n",
    "#         cycle=True,\n",
    "#         visualize_fn=visualize_tree_from_graph,\n",
    "#     ) -> None:\n",
    "#         \"\"\"visualize_fn: function to visualize an individual, e.g. visualize_tree_from_graph.\"\"\"\n",
    "#         if cycle:\n",
    "#             idx = self.cycle_through_individual_index()\n",
    "#         else:\n",
    "#             idx = self._get_current_individual_value()\n",
    "#         if idx is not None and self._population:\n",
    "#             visualize_fn(self._population[idx][0])\n",
    "#         else:\n",
    "#             self._console.print(\"[red]No individual to visualize.[/red]\")\n",
    "\n",
    "#     def _get_index_list(self):\n",
    "#         if not self._keys:\n",
    "#             return []\n",
    "#         key = self._keys[self._key_index]\n",
    "#         return self._dict.get(key, [])\n",
    "\n",
    "#     def _show_current_selection(self) -> None:\n",
    "#         if not self._keys:\n",
    "#             self._console.print(\"[red]No keys with individuals found.[/red]\")\n",
    "#             return\n",
    "#         key = self._keys[self._key_index]\n",
    "#         indexes = self._get_index_list()\n",
    "#         total = len(indexes)\n",
    "#         if indexes:\n",
    "#             idx = self._individual_index % total\n",
    "#             progress_str = f\"[{idx + 1}/{total}]\"\n",
    "#             self._console.print(\n",
    "#                 f\"[bold green]Key:[/bold green] {key} | \"\n",
    "#                 f\"[blue]Individual index:[/blue] {idx} {progress_str} | \"\n",
    "#                 f\"[magenta]Value:[/magenta] {indexes[idx]} | \"\n",
    "#                 f\"[yellow]Total individuals:[/yellow] {total}\",\n",
    "#             )\n",
    "#         else:\n",
    "#             self._console.print(\n",
    "#                 f\"[bold green]Key:[/bold green] {key} | [red]No individuals[/red]\",\n",
    "#             )\n",
    "\n",
    "#     def _get_current_individual_value(self):\n",
    "#         indexes = self._get_index_list()\n",
    "#         if indexes:\n",
    "#             return indexes[self._individual_index % len(indexes)]\n",
    "#         return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc6b5b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6b60a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing the outliers in the visualizer\n",
    "visualizer = IndividualVisualizer(\n",
    "    stats_df[\"outlier_indexes\"].to_dict(),\n",
    "    population,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37be1e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing the outliers in the visualizer\n",
    "visualizer = IndividualVisualizer(\n",
    "    count_df[\"indexes\"].to_dict(),\n",
    "    population,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a9be5e",
   "metadata": {},
   "source": [
    "<!-- The exeperiment shows that the outliers seem to have the same genotype. This leads to the question for how many unique genotypes are actually being created. To run this experiment, a new function should be created that easily parses the given phenotype into a deterministic string. this can than be used in a histogram to count the unique types? -->\n",
    "\n",
    "\n",
    "The visualizer shows that while the phenotype may be roughly the same, the genotypes are all unique. A new determinstic method needs to be invented to create a 1:1 genotype <-> phenotype canonical mapping.\n",
    "\n",
    "so going from (many) genotype -> 1 canonical genotype -> 1 phenotype\n",
    "\n",
    "with this new metric the follownig can be implemented"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54224212",
   "metadata": {},
   "source": [
    "step 1: normalize the ID's. and check again"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7164eeda",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21b088e",
   "metadata": {},
   "source": [
    "### To be implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a39d82c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ariel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
