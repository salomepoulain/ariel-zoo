{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc54dde2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/salo/projects/ariel-zoo/.venv/lib/python3.12/site-packages/numba/np/ufunc/dufunc.py:346: NumbaWarning: Compilation requested for previously compiled argument types ((uint32,)). This has no effect and perhaps indicates a bug in the calling code (compiling a ufunc more than once for the same signature\n",
      "  warnings.warn(msg, errors.NumbaWarning)\n",
      "/home/salo/projects/ariel-zoo/.venv/lib/python3.12/site-packages/numba/np/ufunc/dufunc.py:346: NumbaWarning: Compilation requested for previously compiled argument types ((uint32,)). This has no effect and perhaps indicates a bug in the calling code (compiling a ufunc more than once for the same signature\n",
      "  warnings.warn(msg, errors.NumbaWarning)\n",
      "/home/salo/projects/ariel-zoo/.venv/lib/python3.12/site-packages/numba/np/ufunc/dufunc.py:346: NumbaWarning: Compilation requested for previously compiled argument types ((uint32,)). This has no effect and perhaps indicates a bug in the calling code (compiling a ufunc more than once for the same signature\n",
      "  warnings.warn(msg, errors.NumbaWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "    <style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"e503d3ee-eed9-4114-9815-9d038167dc70\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "'use strict';\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\nconst JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    function drop(id) {\n      const view = Bokeh.index.get_by_id(id)\n      if (view != null) {\n        view.model.document.clear()\n        Bokeh.index.delete(view)\n      }\n    }\n\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n\n    // Clean up Bokeh references\n    if (id != null) {\n      drop(id)\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim()\n            drop(id)\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded(error = null) {\n    const el = document.getElementById(\"e503d3ee-eed9-4114-9815-9d038167dc70\");\n    if (el != null) {\n      const html = (() => {\n        if (typeof root.Bokeh === \"undefined\") {\n          if (error == null) {\n            return \"BokehJS is loading ...\";\n          } else {\n            return \"BokehJS failed to load.\";\n          }\n        } else {\n          const prefix = `BokehJS ${root.Bokeh.version}`;\n          if (error == null) {\n            return `${prefix} successfully loaded.`;\n          } else {\n            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;\n          }\n        }\n      })();\n      el.innerHTML = html;\n\n      if (error != null) {\n        const wrapper = document.createElement(\"div\");\n        wrapper.style.overflow = \"auto\";\n        wrapper.style.height = \"5em\";\n        wrapper.style.resize = \"vertical\";\n        const content = document.createElement(\"div\");\n        content.style.fontFamily = \"monospace\";\n        content.style.whiteSpace = \"pre-wrap\";\n        content.style.backgroundColor = \"rgb(255, 221, 221)\";\n        content.textContent = error.stack ?? error.toString();\n        wrapper.append(content);\n        el.append(wrapper);\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(() => display_loaded(error), 100);\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.8.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.8.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.8.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.8.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.8.1.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n      try {\n            for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n\n      } catch (error) {display_loaded(error);throw error;\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"e503d3ee-eed9-4114-9815-9d038167dc70\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import base64\n",
    "from io import BytesIO\n",
    "from typing import Any\n",
    "\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import umap\n",
    "import umap.plot\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.models import (\n",
    "    BasicTicker,\n",
    "    ColorBar,\n",
    "    ColumnDataSource,\n",
    "    HoverTool,\n",
    "    LinearColorMapper,\n",
    ")\n",
    "from bokeh.plotting import figure, show\n",
    "from matplotlib.colors import to_hex\n",
    "from PIL import Image\n",
    "from rich.console import Console\n",
    "from rich.progress import track\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from ariel_experiments.characterize.canonical.core.toolkit import (\n",
    "    CanonicalToolKit as ctk,\n",
    ")\n",
    "from ariel_experiments.gui_vis.view_mujoco import view\n",
    "from ariel_experiments.utils.initialize import generate_random_individual\n",
    "\n",
    "console = Console()\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81638bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap_row(\n",
    "    matrices: list[np.ndarray],\n",
    "    titles: list[str] = None,\n",
    "    suptitle: str = None,\n",
    "    figsize_per_plot: tuple[int, int] = (5, 6),\n",
    "    cmap: str = \"viridis\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots a horizontal row of heatmaps with local color scaling.\n",
    "\n",
    "    Args:\n",
    "        matrices: List of matrices to plot\n",
    "        titles: Optional list of titles for each subplot\n",
    "        suptitle: Optional overall figure title\n",
    "        figsize_per_plot: (width, height) for each subplot\n",
    "        cmap: Colormap to use\n",
    "    \"\"\"\n",
    "    num_plots = len(matrices)\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=1,\n",
    "        ncols=num_plots,\n",
    "        figsize=(figsize_per_plot[0] * num_plots, figsize_per_plot[1]),\n",
    "        squeeze=False,\n",
    "    )\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    if suptitle:\n",
    "        fig.suptitle(suptitle, fontsize=16)\n",
    "\n",
    "    for i, matrix in enumerate(matrices):\n",
    "        ax = axes[i]\n",
    "\n",
    "        # Local color scaling for maximum contrast\n",
    "        local_vmin = matrix.min()\n",
    "        local_vmax = matrix.max()\n",
    "\n",
    "        sns.heatmap(\n",
    "            matrix,\n",
    "            ax=ax,\n",
    "            cmap=cmap,\n",
    "            vmin=local_vmin,\n",
    "            vmax=local_vmax,\n",
    "            cbar_ax=None,\n",
    "        )\n",
    "\n",
    "        if titles and i < len(titles):\n",
    "            ax.set_title(titles[i])\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d987789",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparison_heatmaps(\n",
    "    all_matrix_data: dict[str, dict[int, Any]],  # Updated type hint\n",
    "    max_show_radius: int,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots a row of heatmaps for each radius.\n",
    "    Row = Radius\n",
    "    Column = Metric\n",
    "    \"\"\"\n",
    "    # 1. Iterate through radii (Rows of the visual)\n",
    "    for r in range(max_show_radius + 1):\n",
    "        row_matrices = []\n",
    "        row_titles = []\n",
    "\n",
    "        # 2. Iterate through metrics (Columns of the visual)\n",
    "        # CHANGE: We use .items() because input is now a dict, not a list of tuples\n",
    "        for name, matrix_dict in all_matrix_data.items():\n",
    "            # DIRECT ACCESS: Get the specific matrix for this radius\n",
    "            if r in matrix_dict:\n",
    "                matrix = matrix_dict[r]\n",
    "            else:\n",
    "                # Fallback if radius is missing\n",
    "                matrix = np.zeros((1, 1))\n",
    "\n",
    "            row_matrices.append(matrix)\n",
    "            row_titles.append(f\"r:{r} {name}\")\n",
    "\n",
    "        # 3. Plot the specific row\n",
    "        plot_heatmap_row(\n",
    "            matrices=row_matrices,\n",
    "            titles=row_titles,\n",
    "            suptitle=f\"Comparison at Radius {r}\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30a6c016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def view_horizontal_groups(robot_tuples, titles=None):\n",
    "#     \"\"\"\n",
    "#     Plots horizontal groups without rescaling images of different sizes.\n",
    "#     Uses pixel-perfect width_ratios.\n",
    "#     \"\"\"\n",
    "\n",
    "#     # --- 1. Pre-fetch ALL images to get dimensions ---\n",
    "#     # We flatten the structure but keep track of where groups split\n",
    "#     processed_items = []  # Will store dicts: {'type': 'img', 'data': img} or {'type': 'gap'}\n",
    "\n",
    "#     # Config for spacing (in pixels, approximately)\n",
    "#     GROUP_GAP_PX = 100  # The big gap between tuples\n",
    "#     ROBOT_GAP_PX = 20  # The small gap between robots in a tuple\n",
    "#     DPI = 100  # Screen dots per inch\n",
    "\n",
    "#     max_height = 0\n",
    "\n",
    "#     group_start_indices = []  # To help us place titles later\n",
    "#     current_index = 0\n",
    "\n",
    "#     for i, group in enumerate(robot_tuples):\n",
    "#         # Record where this group starts in the flat list\n",
    "#         group_start_indices.append(current_index)\n",
    "\n",
    "#         for j, robot in enumerate(group):\n",
    "#             # Generate the image\n",
    "#             img = np.array(\n",
    "#                 view(\n",
    "#                     robot, return_img=True, remove_background=True, tilted=True\n",
    "#                 )\n",
    "#             )\n",
    "#             h, w = img.shape[:2]\n",
    "\n",
    "#             # Update global max height (defines the strip height)\n",
    "#             if h > max_height:\n",
    "#                 max_height = h\n",
    "\n",
    "#             processed_items.append({\n",
    "#                 \"type\": \"img\",\n",
    "#                 \"data\": img,\n",
    "#                 \"width\": w,\n",
    "#                 \"height\": h,\n",
    "#             })\n",
    "#             current_index += 1\n",
    "\n",
    "#             # Add a small gap after every robot, EXCEPT the last one in the group\n",
    "#             if j < len(group) - 1:\n",
    "#                 processed_items.append({\"type\": \"gap\", \"width\": ROBOT_GAP_PX})\n",
    "#                 current_index += 1\n",
    "\n",
    "#         # Add a large gap after every group, EXCEPT the last group\n",
    "#         if i < len(robot_tuples) - 1:\n",
    "#             processed_items.append({\"type\": \"gap\", \"width\": GROUP_GAP_PX})\n",
    "#             current_index += 1\n",
    "\n",
    "#     # --- 2. Calculate Figure Dimensions ---\n",
    "#     # Total width is sum of all image widths + sum of all gap widths\n",
    "#     total_width_px = sum(item[\"width\"] for item in processed_items)\n",
    "\n",
    "#     # Calculate Figure size in Inches (Pixels / DPI)\n",
    "#     fig_width_in = total_width_px / DPI\n",
    "#     fig_height_in = max_height / DPI\n",
    "\n",
    "#     # Add a little buffer for titles at the top (e.g., 0.5 inches)\n",
    "#     title_buffer_in = 0.5\n",
    "#     fig_height_total = fig_height_in + title_buffer_in\n",
    "\n",
    "#     # --- 3. Create Figure with Exact Aspect Ratio ---\n",
    "#     fig = plt.figure(figsize=(fig_width_in, fig_height_total), dpi=DPI)\n",
    "\n",
    "#     # List of widths to tell GridSpec exactly how much space each col gets\n",
    "#     widths = [item[\"width\"] for item in processed_items]\n",
    "\n",
    "#     # One big row, N columns (images + gaps)\n",
    "#     gs = gridspec.GridSpec(\n",
    "#         1, len(processed_items), figure=fig, width_ratios=widths\n",
    "#     )\n",
    "\n",
    "#     # Remove default spacing, we are handling it manually with 'gap' columns\n",
    "#     plt.subplots_adjust(\n",
    "#         left=0,\n",
    "#         right=1,\n",
    "#         bottom=0,\n",
    "#         top=fig_height_in / fig_height_total,\n",
    "#         wspace=0,\n",
    "#         hspace=0,\n",
    "#     )\n",
    "\n",
    "#     # --- 4. Plotting ---\n",
    "#     axes_map = {}  # Map index to ax object to help with titles\n",
    "\n",
    "#     for idx, item in enumerate(processed_items):\n",
    "#         if item[\"type\"] == \"gap\":\n",
    "#             # Skip this column, let it be empty whitespace\n",
    "#             continue\n",
    "\n",
    "#         # Create subplot\n",
    "#         ax = fig.add_subplot(gs[0, idx])\n",
    "\n",
    "#         # Display Image\n",
    "#         # anchor='S' aligns image to Bottom (South) if it's shorter than max_height\n",
    "#         # 'C' would center it. 'N' would align top.\n",
    "#         ax.imshow(\n",
    "#             item[\"data\"], aspect=\"equal\", interpolation=\"none\", origin=\"upper\"\n",
    "#         )\n",
    "\n",
    "#         # Ensure the axes limits match the max_height so alignment works\n",
    "#         # This keeps the \"ceiling\" consistent even for short images\n",
    "#         ax.set_ylim(max_height, 0)\n",
    "#         ax.set_xlim(0, item[\"width\"])\n",
    "\n",
    "#         ax.axis(\"off\")\n",
    "#         axes_map[idx] = ax\n",
    "\n",
    "#     # --- 5. Titles ---\n",
    "#     if titles:\n",
    "#         # We need to find the center of each group\n",
    "#         # We iterate through the original group structure to find start/end indices\n",
    "#         flat_ptr = 0\n",
    "\n",
    "#         for i, group in enumerate(robot_tuples):\n",
    "#             # Find the first ax in this group\n",
    "#             start_ax = axes_map[flat_ptr]\n",
    "\n",
    "#             # Advance pointer to find the last ax in this group\n",
    "#             # Structure in flattened list: [Img, Gap, Img, Gap, Img] ... [Big Gap] ...\n",
    "#             # Length of group items = (len(group) * 2) - 1\n",
    "#             items_in_group = (len(group) * 2) - 1\n",
    "#             end_ptr = flat_ptr + items_in_group - 1\n",
    "\n",
    "#             # If the group has only 1 robot, start and end are same\n",
    "#             if end_ptr not in axes_map:\n",
    "#                 # This happens if end_ptr points to a gap (logic check),\n",
    "#                 # but based on math above, end_ptr should always hit an image.\n",
    "#                 end_ax = start_ax\n",
    "#             else:\n",
    "#                 end_ax = axes_map[end_ptr]\n",
    "\n",
    "#             # Calculate positions in Figure Coordinates (0 to 1)\n",
    "#             bbox_start = start_ax.get_position()\n",
    "#             bbox_end = end_ax.get_position()\n",
    "\n",
    "#             center_x = (bbox_start.x0 + bbox_end.x1) / 2\n",
    "\n",
    "#             # Place Title\n",
    "#             fig.text(\n",
    "#                 center_x,\n",
    "#                 1.0 - (0.2 / fig_height_total),\n",
    "#                 titles[i],\n",
    "#                 ha=\"center\",\n",
    "#                 va=\"top\",\n",
    "#                 fontsize=12,\n",
    "#                 weight=\"bold\",\n",
    "#             )\n",
    "\n",
    "#             # Advance pointer past this group AND the group gap\n",
    "#             flat_ptr += items_in_group + 1\n",
    "\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "134e653b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cum_matrix(matrix_dict):\n",
    "    \"\"\"\n",
    "    Calculates the cumulative sum of matrices keyed by integer radii.\n",
    "    \"\"\"\n",
    "    # 1. Sort the keys to ensure we process 0, then 1, then 2, etc.\n",
    "    sorted_radii = sorted(matrix_dict.keys())\n",
    "\n",
    "    cum_dict = {}\n",
    "    running_sum = None\n",
    "\n",
    "    for r in sorted_radii:\n",
    "        current_matrix = matrix_dict[r]\n",
    "\n",
    "        if running_sum is None:\n",
    "            # First iteration (e.g., radius 0)\n",
    "            # Use .copy() to ensure we don't accidentally modify the input\n",
    "            running_sum = current_matrix.copy()\n",
    "        else:\n",
    "            # Add the current matrix to the accumulated total\n",
    "            running_sum = running_sum + current_matrix\n",
    "\n",
    "        # Store the result in the new dictionary\n",
    "        cum_dict[r] = running_sum\n",
    "\n",
    "    return cum_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b8b2fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sorted_coords_from_matrix(matrix, *, max_first=True):\n",
    "    \"\"\"\n",
    "    Returns (row, col) tuples from the upper triangle, sorted by value.\n",
    "    \"\"\"\n",
    "    rows, cols = np.triu_indices_from(matrix, k=1)\n",
    "    values = matrix[rows, cols]\n",
    "    sort_idx = np.argsort(values)\n",
    "    if max_first:\n",
    "        sort_idx = sort_idx[::-1]\n",
    "    return list(zip(rows[sort_idx], cols[sort_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8628485",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorted_idx_dict(matrix_dict, *, max_first=True):\n",
    "    \"\"\"Return {radius: sorted_coord_list} by applying get_sorted_coords_from_matrix to each matrix.\"\"\"\n",
    "    return {\n",
    "        r: get_sorted_coords_from_matrix(mat, max_first=max_first)\n",
    "        for r, mat in matrix_dict.items()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46492813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def embeddable_image(data, size=(100, 100)):\n",
    "#     \"\"\"\n",
    "#     Simplified version: Accepts HxWx4 (RGBA) or HxWx3 (RGB).\n",
    "#     Returns PNG data-url with aspect ratio preserved.\n",
    "#     \"\"\"\n",
    "#     arr = np.asarray(data)\n",
    "\n",
    "#     # Normalize types\n",
    "#     if np.issubdtype(arr.dtype, np.floating):\n",
    "#         if arr.max() <= 1.0:\n",
    "#             arr = (arr * 255).astype(np.uint8)\n",
    "#         else:\n",
    "#             arr = arr.astype(np.uint8)\n",
    "#     else:\n",
    "#         arr = arr.astype(np.uint8)\n",
    "\n",
    "#     # Detect Mode\n",
    "#     if arr.ndim == 3:\n",
    "#         mode = \"RGBA\" if arr.shape[2] == 4 else \"RGB\"\n",
    "#     else:\n",
    "#         mode = \"L\"  # Grayscale\n",
    "\n",
    "#     # Create Image and Thumbnail\n",
    "#     img = Image.fromarray(arr, mode=mode)\n",
    "#     img.thumbnail(size, Image.Resampling.BICUBIC)  # Keeps aspect ratio\n",
    "\n",
    "#     buffer = BytesIO()\n",
    "#     img.save(buffer, format=\"PNG\")\n",
    "#     return (\n",
    "#         \"data:image/png;base64,\" + base64.b64encode(buffer.getvalue()).decode()\n",
    "#     )\n",
    "\n",
    "\n",
    "# def robot_image(i):\n",
    "#     \"\"\"\n",
    "#     Generates the image for robot i using the global POPULATION and view function.\n",
    "#     \"\"\"\n",
    "#     graph = POPULATION[i].to_graph()\n",
    "#     # Using remove_background=True for transparent PNGs\n",
    "#     img_arr = np.array(\n",
    "#         view(graph, return_img=True, tilted=True, remove_background=True)\n",
    "#     )\n",
    "#     return embeddable_image(img_arr)\n",
    "\n",
    "\n",
    "# def get_population_images(population_size):\n",
    "#     \"\"\"\n",
    "#     Pre-generates all images for the population to avoid re-rendering.\n",
    "#     \"\"\"\n",
    "#     return [\n",
    "#         robot_image(i)\n",
    "#         for i in track(\n",
    "#             range(population_size),\n",
    "#             description=f\"Generating {population_size} images...\",\n",
    "#         )\n",
    "#     ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "661550ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def matrix_to_heatmap_source(matrix, images, metric_name, radius):\n",
    "#     \"\"\"\n",
    "#     Converts an NxN matrix into a Bokeh ColumnDataSource (Long format).\n",
    "#     \"\"\"\n",
    "#     N = matrix.shape[0]\n",
    "\n",
    "#     # Create coordinate grids\n",
    "#     # Note: Bokeh origin (0,0) is bottom-left. Matrices are top-left.\n",
    "#     # We invert y so the plot looks like the matrix.\n",
    "#     x_indices, y_indices = np.meshgrid(np.arange(N), np.arange(N))\n",
    "\n",
    "#     # Flatten arrays\n",
    "#     x_flat = x_indices.flatten()\n",
    "#     y_flat = N - 1 - y_indices.flatten()  # Invert Y for visual matrix layout\n",
    "#     values = matrix.flatten()\n",
    "\n",
    "#     # Map images\n",
    "#     imgs_i = [images[r] for r in y_indices.flatten()]  # Row robot\n",
    "#     imgs_j = [images[c] for c in x_indices.flatten()]  # Col robot\n",
    "\n",
    "#     ids_i = [str(r) for r in y_indices.flatten()]\n",
    "#     ids_j = [str(c) for c in x_indices.flatten()]\n",
    "\n",
    "#     data = {\n",
    "#         \"x\": x_flat,\n",
    "#         \"y\": y_flat,\n",
    "#         \"value\": values,\n",
    "#         \"img_row\": imgs_i,  # Robot on Y axis\n",
    "#         \"img_col\": imgs_j,  # Robot on X axis\n",
    "#         \"id_row\": ids_i,\n",
    "#         \"id_col\": ids_j,\n",
    "#         \"metric\": [metric_name] * len(values),\n",
    "#         \"radius\": [radius] * len(values),\n",
    "#     }\n",
    "#     return ColumnDataSource(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a6c2932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def matrix_to_heatmap_source(matrix, images, metric_name, radius):\n",
    "#     \"\"\"\n",
    "#     Converts an NxN matrix into a Bokeh ColumnDataSource (Long format).\n",
    "#     \"\"\"\n",
    "#     N = matrix.shape[0]\n",
    "#     x_indices, y_indices = np.meshgrid(np.arange(N), np.arange(N))\n",
    "    \n",
    "#     x_flat = x_indices.flatten()\n",
    "#     y_flat = N - 1 - y_indices.flatten() \n",
    "#     values = matrix.flatten()\n",
    "    \n",
    "#     imgs_i = [images[r] for r in y_indices.flatten()]\n",
    "#     imgs_j = [images[c] for c in x_indices.flatten()]\n",
    "    \n",
    "#     ids_i = [str(r) for r in y_indices.flatten()]\n",
    "#     ids_j = [str(c) for c in x_indices.flatten()]\n",
    "    \n",
    "#     data = {\n",
    "#         'x': x_flat, 'y': y_flat, 'value': values,\n",
    "#         'img_row': imgs_i, 'img_col': imgs_j,\n",
    "#         'id_row': ids_i, 'id_col': ids_j,\n",
    "#         'metric': [metric_name] * len(values),\n",
    "#         'radius': [radius] * len(values)\n",
    "#     }\n",
    "#     return ColumnDataSource(data)\n",
    "\n",
    "# def plot_interactive_heatmaps(\n",
    "#     all_matrix_data: dict, \n",
    "#     population_images: list, \n",
    "#     max_show_radius: int, \n",
    "#     plot_width=None, \n",
    "#     plot_height=None, \n",
    "#     palette=\"Reds256\"\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Creates a Grid of Interactive Heatmaps using Bokeh.\n",
    "#     \"\"\"\n",
    "#     num_cols = len(all_matrix_data)\n",
    "    \n",
    "#     # Dynamic Sizing Defaults\n",
    "#     # If width is not specified, make it large for single column, compact for multi-column\n",
    "#     if plot_width is None:\n",
    "#         plot_width = 650 if num_cols == 1 else 350\n",
    "        \n",
    "#     if plot_height is None:\n",
    "#         # Keep heatmaps roughly square-ish (accounting for colorbar width in plot_width)\n",
    "#         plot_height = 600 if num_cols == 1 else 300\n",
    "\n",
    "#     grid_layout = []\n",
    "#     for r in range(max_show_radius + 1):\n",
    "#         row_plots = []\n",
    "#         for name, matrix_dict in all_matrix_data.items():\n",
    "#             if r in matrix_dict:\n",
    "#                 matrix = matrix_dict[r]\n",
    "#             else:\n",
    "#                 matrix = np.zeros((1, 1))\n",
    "            \n",
    "#             source = matrix_to_heatmap_source(matrix, population_images, name, r)\n",
    "#             vmin, vmax = matrix.min(), matrix.max()\n",
    "#             mapper = LinearColorMapper(palette=palette, low=vmin, high=vmax)\n",
    "            \n",
    "#             p = figure(title=f\"r:{r} {name}\", x_range=(-0.5, matrix.shape[1]-0.5), y_range=(-0.5, matrix.shape[0]-0.5), width=plot_width, height=plot_height, tools=\"hover,save,reset\", toolbar_location=\"above\")\n",
    "#             p.axis.visible = False\n",
    "#             p.grid.visible = False\n",
    "#             p.rect(x='x', y='y', width=1, height=1, source=source, fill_color={'field': 'value', 'transform': mapper}, line_color=None)\n",
    "            \n",
    "#             color_bar = ColorBar(color_mapper=mapper, ticker=BasicTicker(), label_standoff=8, border_line_color=None, location=(0,0), width=8)\n",
    "#             p.add_layout(color_bar, 'right')\n",
    "            \n",
    "#             hover = p.select(dict(type=HoverTool))\n",
    "#             hover.tooltips = \"\"\"\n",
    "#             <div style=\"display: flex; flex-direction: column; align-items: center; background: white; padding: 5px;\">\n",
    "#                 <div style=\"font-weight: bold; margin-bottom: 5px;\">@metric (r=@radius) Val: @value{0.000}</div>\n",
    "#                 <div style=\"display: flex; flex-direction: row; gap: 10px;\">\n",
    "#                     <div style=\"text-align: center;\"><span style=\"font-size: 10px;\">Row: @id_row</span><br><img src=\"@img_row\" style=\"max-width: 60px; max-height: 60px; width: auto; height: auto;\"></div>\n",
    "#                     <div style=\"text-align: center;\"><span style=\"font-size: 10px;\">Col: @id_col</span><br><img src=\"@img_col\" style=\"max-width: 60px; max-height: 60px; width: auto; height: auto;\"></div>\n",
    "#                 </div>\n",
    "#             </div>\n",
    "#             \"\"\"\n",
    "#             row_plots.append(p)\n",
    "#         grid_layout.append(row_plots)\n",
    "#     show(gridplot(grid_layout))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fc3973",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7a6e36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def embeddable_image(data, scale=0.5):\n",
    "#     \"\"\"\n",
    "#     Simplified version: Accepts HxWx4 (RGBA) or HxWx3 (RGB).\n",
    "#     Returns PNG data-url with aspect ratio AND relative scale preserved.\n",
    "#     \"\"\"\n",
    "#     arr = np.asarray(data)\n",
    "    \n",
    "#     # Normalize types\n",
    "#     if np.issubdtype(arr.dtype, np.floating):\n",
    "#         if arr.max() <= 1.0:\n",
    "#             arr = (arr * 255).astype(np.uint8)\n",
    "#         else:\n",
    "#             arr = arr.astype(np.uint8)\n",
    "#     else:\n",
    "#         arr = arr.astype(np.uint8)\n",
    "\n",
    "#     # Detect Mode\n",
    "#     if arr.ndim == 3:\n",
    "#         mode = 'RGBA' if arr.shape[2] == 4 else 'RGB'\n",
    "#     else:\n",
    "#         mode = 'L' # Grayscale\n",
    "\n",
    "#     # Create Image\n",
    "#     img = Image.fromarray(arr, mode=mode)\n",
    "    \n",
    "#     # Resize by a constant factor to preserve relative size differences\n",
    "#     # (e.g., a big robot stays big, a small robot stays small)\n",
    "#     if scale != 1.0:\n",
    "#         new_size = (int(img.width * scale), int(img.height * scale))\n",
    "#         img = img.resize(new_size, Image.Resampling.BICUBIC)\n",
    "\n",
    "#     buffer = BytesIO()\n",
    "#     img.save(buffer, format='PNG')\n",
    "#     return 'data:image/png;base64,' + base64.b64encode(buffer.getvalue()).decode()\n",
    "\n",
    "# def robot_image(i):\n",
    "#     \"\"\"\n",
    "#     Generates the image for robot i using the global POPULATION and view function.\n",
    "#     \"\"\"\n",
    "#     graph = POPULATION[i].to_graph()  \n",
    "#     # Using remove_background=True for transparent PNGs\n",
    "#     img_arr = np.array(view(graph, return_img=True, tilted=True, remove_background=True))\n",
    "#     # Apply a 50% scale to keep file sizes manageable while preserving relative scale\n",
    "#     return embeddable_image(img_arr, scale=0.5)\n",
    "\n",
    "# def get_population_images(population_size):\n",
    "#     \"\"\"\n",
    "#     Pre-generates all images for the population to avoid re-rendering.\n",
    "#     \"\"\"\n",
    "#     return [robot_image(i) for i in track(range(population_size), description=f\"Generating {population_size} images...\")]\n",
    "\n",
    "# # --- 2. Interactive Heatmap Functions (Matrix Visualization) ---\n",
    "\n",
    "# def matrix_to_heatmap_source(matrix, images, metric_name, radius):\n",
    "#     \"\"\"\n",
    "#     Converts an NxN matrix into a Bokeh ColumnDataSource (Long format).\n",
    "#     \"\"\"\n",
    "#     N = matrix.shape[0]\n",
    "#     x_indices, y_indices = np.meshgrid(np.arange(N), np.arange(N))\n",
    "    \n",
    "#     x_flat = x_indices.flatten()\n",
    "#     y_flat = N - 1 - y_indices.flatten() \n",
    "#     values = matrix.flatten()\n",
    "    \n",
    "#     imgs_i = [images[r] for r in y_indices.flatten()]\n",
    "#     imgs_j = [images[c] for c in x_indices.flatten()]\n",
    "    \n",
    "#     ids_i = [str(r) for r in y_indices.flatten()]\n",
    "#     ids_j = [str(c) for c in x_indices.flatten()]\n",
    "    \n",
    "#     data = {\n",
    "#         'x': x_flat, 'y': y_flat, 'value': values,\n",
    "#         'img_row': imgs_i, 'img_col': imgs_j,\n",
    "#         'id_row': ids_i, 'id_col': ids_j,\n",
    "#         'metric': [metric_name] * len(values),\n",
    "#         'radius': [radius] * len(values)\n",
    "#     }\n",
    "#     return ColumnDataSource(data)\n",
    "\n",
    "# def plot_interactive_heatmaps(\n",
    "#     all_matrix_data: dict, \n",
    "#     population_images: list, \n",
    "#     max_show_radius: int, \n",
    "#     plot_width=None, \n",
    "#     plot_height=None, \n",
    "#     palette=\"Reds256\"\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Creates a Grid of Interactive Heatmaps using Bokeh.\n",
    "#     \"\"\"\n",
    "#     num_cols = len(all_matrix_data)\n",
    "    \n",
    "#     # Dynamic Sizing Defaults\n",
    "#     # If width is not specified, make it large for single column, compact for multi-column\n",
    "#     if plot_width is None:\n",
    "#         plot_width = 650 if num_cols == 1 else 350\n",
    "        \n",
    "#     if plot_height is None:\n",
    "#         # Keep heatmaps roughly square-ish (accounting for colorbar width in plot_width)\n",
    "#         plot_height = 600 if num_cols == 1 else 300\n",
    "\n",
    "#     grid_layout = []\n",
    "#     for r in range(max_show_radius + 1):\n",
    "#         row_plots = []\n",
    "#         for name, matrix_dict in all_matrix_data.items():\n",
    "#             if r in matrix_dict:\n",
    "#                 matrix = matrix_dict[r]\n",
    "#             else:\n",
    "#                 matrix = np.zeros((1, 1))\n",
    "            \n",
    "#             source = matrix_to_heatmap_source(matrix, population_images, name, r)\n",
    "#             vmin, vmax = matrix.min(), matrix.max()\n",
    "#             mapper = LinearColorMapper(palette=palette, low=vmin, high=vmax)\n",
    "            \n",
    "#             p = figure(title=f\"r:{r} {name}\", x_range=(-0.5, matrix.shape[1]-0.5), y_range=(-0.5, matrix.shape[0]-0.5), width=plot_width, height=plot_height, tools=\"hover,save,reset\", toolbar_location=\"above\")\n",
    "#             p.axis.visible = False\n",
    "#             p.grid.visible = False\n",
    "#             p.rect(x='x', y='y', width=1, height=1, source=source, fill_color={'field': 'value', 'transform': mapper}, line_color=None)\n",
    "            \n",
    "#             color_bar = ColorBar(color_mapper=mapper, ticker=BasicTicker(), label_standoff=8, border_line_color=None, location=(0,0), width=8)\n",
    "#             p.add_layout(color_bar, 'right')\n",
    "            \n",
    "#             hover = p.select(dict(type=HoverTool))\n",
    "#             # UPDATED CSS: Removed max-width/max-height constraints.\n",
    "#             # Using 'width: auto' respects the relative scaling baked into the image data.\n",
    "#             hover.tooltips = \"\"\"\n",
    "#             <div style=\"display: flex; flex-direction: column; align-items: center; background: white; padding: 5px;\">\n",
    "#                 <div style=\"font-weight: bold; margin-bottom: 5px;\">@metric (r=@radius) Val: @value{0.000}</div>\n",
    "#                 <div style=\"display: flex; flex-direction: row; gap: 10px;\">\n",
    "#                     <div style=\"text-align: center;\"><span style=\"font-size: 10px;\">Row: @id_row</span><br><img src=\"@img_row\" style=\"width: auto; height: auto;\"></div>\n",
    "#                     <div style=\"text-align: center;\"><span style=\"font-size: 10px;\">Col: @id_col</span><br><img src=\"@img_col\" style=\"width: auto; height: auto;\"></div>\n",
    "#                 </div>\n",
    "#             </div>\n",
    "#             \"\"\"\n",
    "#             row_plots.append(p)\n",
    "#         grid_layout.append(row_plots)\n",
    "#     show(gridplot(grid_layout))\n",
    "\n",
    "# # --- 3. Interactive UMAP Grid Functions (Scatter Visualization) ---\n",
    "\n",
    "# # def plot_interactive_umap_grid(\n",
    "# #     umap_data: dict, \n",
    "# #     population_images: list, \n",
    "# #     max_show_radius: int,\n",
    "# #     plot_width=None, \n",
    "# #     plot_height=350\n",
    "# # ):\n",
    "# #     \"\"\"\n",
    "# #     Creates a Grid of Interactive UMAP Scatter plots.\n",
    "# #     Row = Radius\n",
    "# #     Column = Metric (different embedding dictionaries)\n",
    "# #     Color = Rainbow by ID (Consistent across all plots)\n",
    "# #     \"\"\"\n",
    "# #     num_cols = len(umap_data)\n",
    "    \n",
    "# #     # Dynamic Sizing Defaults\n",
    "# #     # If width is not specified, make it large for single column, compact for multi-column\n",
    "# #     if plot_width is None:\n",
    "# #         plot_width = 700 if num_cols == 1 else 350\n",
    "        \n",
    "# #     n = len(population_images)\n",
    "    \n",
    "# #     # 1. Pre-calculate Colors (Rainbow by ID)\n",
    "# #     rgba_colors = plt.cm.rainbow(np.linspace(0, 1, n))\n",
    "# #     hex_colors = [to_hex(c) for c in rgba_colors]\n",
    "    \n",
    "# #     grid_layout = []\n",
    "\n",
    "# #     # 2. Iterate Rows (Radius)\n",
    "# #     for r in range(max_show_radius + 1):\n",
    "# #         row_plots = []\n",
    "        \n",
    "# #         # 3. Iterate Columns (Different UMAP methods)\n",
    "# #         for name, matrix_dict in umap_data.items():\n",
    "            \n",
    "# #             # Check if embedding exists for this radius\n",
    "# #             if r in matrix_dict:\n",
    "# #                 emb = matrix_dict[r]\n",
    "# #                 # Handle empty or malformed embeddings\n",
    "# #                 if emb.ndim != 2 or emb.shape[1] != 2:\n",
    "# #                      # Create empty placeholder if data is invalid\n",
    "# #                     p = figure(title=f\"r:{r} {name} (No Data)\", width=plot_width, height=plot_height)\n",
    "# #                     row_plots.append(p)\n",
    "# #                     continue\n",
    "# #             else:\n",
    "# #                  # Create empty placeholder if radius missing\n",
    "# #                 p = figure(title=f\"r:{r} {name} (Missing)\", width=plot_width, height=plot_height)\n",
    "# #                 row_plots.append(p)\n",
    "# #                 continue\n",
    "\n",
    "# #             # Build DataSource\n",
    "# #             robots_df = pd.DataFrame({\n",
    "# #                 \"x\": emb[:, 0],\n",
    "# #                 \"y\": emb[:, 1],\n",
    "# #                 \"digit\": [str(i) for i in range(n)],\n",
    "# #                 \"image\": population_images,\n",
    "# #                 \"color\": hex_colors\n",
    "# #             })\n",
    "# #             source = ColumnDataSource(robots_df)\n",
    "            \n",
    "# #             # Create Figure\n",
    "# #             p = figure(\n",
    "# #                 title=f\"r:{r} {name}\", \n",
    "# #                 width=plot_width, \n",
    "# #                 height=plot_height, \n",
    "# #                 tools=\"pan,wheel_zoom,reset,save\",\n",
    "# #                 toolbar_location=\"above\"\n",
    "# #             )\n",
    "            \n",
    "# #             # Scatter Plot\n",
    "# #             p.scatter(\n",
    "# #                 'x', 'y',\n",
    "# #                 source=source,\n",
    "# #                 color='color',\n",
    "# #                 line_alpha=0.6,\n",
    "# #                 fill_alpha=0.7,\n",
    "# #                 size=8\n",
    "# #             )\n",
    "            \n",
    "# #             # Hover Tool with Image\n",
    "# #             # CSS: Using width: auto to preserve relative size\n",
    "# #             hover = HoverTool(tooltips=\"\"\"\n",
    "# #             <div>\n",
    "# #                 <img src='@image' style='float:left; margin:5px; width:auto; height:auto;'/>\n",
    "# #             </div>\n",
    "# #             <div style=\"font-size:12px; font-weight: bold;\">\n",
    "# #                 <span style='color:#224499'>ID: @digit</span>\n",
    "# #             </div>\n",
    "# #             \"\"\")\n",
    "# #             p.add_tools(hover)\n",
    "            \n",
    "# #             row_plots.append(p)\n",
    "            \n",
    "# #         grid_layout.append(row_plots)\n",
    "        \n",
    "# #     # Display Grid\n",
    "# #     show(gridplot(grid_layout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74051271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def embeddable_image(data, scale=1.0):\n",
    "#     \"\"\"\n",
    "#     Simplified version: Accepts HxWx4 (RGBA) or HxWx3 (RGB).\n",
    "#     Returns PNG data-url with aspect ratio AND relative scale preserved.\n",
    "#     \"\"\"\n",
    "#     arr = np.asarray(data)\n",
    "    \n",
    "#     # Normalize types\n",
    "#     if np.issubdtype(arr.dtype, np.floating):\n",
    "#         if arr.max() <= 1.0:\n",
    "#             arr = (arr * 255).astype(np.uint8)\n",
    "#         else:\n",
    "#             arr = arr.astype(np.uint8)\n",
    "#     else:\n",
    "#         arr = arr.astype(np.uint8)\n",
    "\n",
    "#     # Detect Mode\n",
    "#     if arr.ndim == 3:\n",
    "#         mode = 'RGBA' if arr.shape[2] == 4 else 'RGB'\n",
    "#     else:\n",
    "#         mode = 'L' # Grayscale\n",
    "\n",
    "#     # Create Image\n",
    "#     img = Image.fromarray(arr, mode=mode)\n",
    "    \n",
    "#     # Resize by a constant factor to preserve relative size differences\n",
    "#     if scale != 1.0:\n",
    "#         new_size = (int(img.width * scale), int(img.height * scale))\n",
    "#         img = img.resize(new_size, Image.Resampling.BICUBIC)\n",
    "\n",
    "#     buffer = BytesIO()\n",
    "#     img.save(buffer, format='PNG')\n",
    "#     return 'data:image/png;base64,' + base64.b64encode(buffer.getvalue()).decode()\n",
    "\n",
    "# def robot_image(i):\n",
    "#     \"\"\"\n",
    "#     Generates the image for robot i using the global POPULATION and view function.\n",
    "#     \"\"\"\n",
    "#     graph = POPULATION[i].to_graph()  \n",
    "#     # Using remove_background=True for transparent PNGs\n",
    "#     img_arr = np.array(view(graph, return_img=True, tilted=True, remove_background=True))\n",
    "#     # Apply 1.0 scale (Full Resolution) so images aren't pixelated\n",
    "#     return embeddable_image(img_arr, scale=1.0)\n",
    "\n",
    "# def get_population_images(population_size):\n",
    "#     \"\"\"\n",
    "#     Pre-generates all images for the population to avoid re-rendering.\n",
    "#     \"\"\"\n",
    "#     return [robot_image(i) for i in track(range(population_size), description=f\"Generating {population_size} images...\")]\n",
    "\n",
    "# def decode_base64_image(data_url):\n",
    "#     \"\"\"\n",
    "#     Helper to convert the stored base64 string back to a numpy array for matplotlib.\n",
    "#     \"\"\"\n",
    "#     header, encoded = data_url.split(\",\", 1)\n",
    "#     data = base64.b64decode(encoded)\n",
    "#     return np.array(Image.open(BytesIO(data)))\n",
    "\n",
    "# # --- 2. Interactive Bokeh Functions (Web/Interactive) ---\n",
    "\n",
    "# def matrix_to_heatmap_source(matrix, images, metric_name, radius):\n",
    "#     \"\"\"Converts matrix to Bokeh DataSource.\"\"\"\n",
    "#     N = matrix.shape[0]\n",
    "#     x_indices, y_indices = np.meshgrid(np.arange(N), np.arange(N))\n",
    "#     x_flat = x_indices.flatten()\n",
    "#     y_flat = N - 1 - y_indices.flatten() \n",
    "#     values = matrix.flatten()\n",
    "#     imgs_i = [images[r] for r in y_indices.flatten()]\n",
    "#     imgs_j = [images[c] for c in x_indices.flatten()]\n",
    "#     ids_i = [str(r) for r in y_indices.flatten()]\n",
    "#     ids_j = [str(c) for c in x_indices.flatten()]\n",
    "#     data = {\n",
    "#         'x': x_flat, 'y': y_flat, 'value': values,\n",
    "#         'img_row': imgs_i, 'img_col': imgs_j,\n",
    "#         'id_row': ids_i, 'id_col': ids_j,\n",
    "#         'metric': [metric_name] * len(values),\n",
    "#         'radius': [radius] * len(values)\n",
    "#     }\n",
    "#     return ColumnDataSource(data)\n",
    "\n",
    "# def plot_interactive_heatmaps(all_matrix_data: dict, population_images: list, max_show_radius: int, plot_width=None, plot_height=None, palette=\"Reds256\"):\n",
    "#     \"\"\"Creates a Grid of Interactive Heatmaps using Bokeh.\"\"\"\n",
    "#     num_cols = len(all_matrix_data)\n",
    "#     if plot_width is None: plot_width = 650 if num_cols == 1 else 350\n",
    "#     if plot_height is None: plot_height = 600 if num_cols == 1 else 300\n",
    "\n",
    "#     grid_layout = []\n",
    "#     for r in range(max_show_radius + 1):\n",
    "#         row_plots = []\n",
    "#         for name, matrix_dict in all_matrix_data.items():\n",
    "#             if r in matrix_dict: matrix = matrix_dict[r]\n",
    "#             else: matrix = np.zeros((1, 1))\n",
    "            \n",
    "#             source = matrix_to_heatmap_source(matrix, population_images, name, r)\n",
    "#             vmin, vmax = matrix.min(), matrix.max()\n",
    "#             mapper = LinearColorMapper(palette=palette, low=vmin, high=vmax)\n",
    "            \n",
    "#             p = figure(title=f\"r:{r} {name}\", x_range=(-0.5, matrix.shape[1]-0.5), y_range=(-0.5, matrix.shape[0]-0.5), width=plot_width, height=plot_height, tools=\"hover,save,reset\", toolbar_location=\"above\")\n",
    "#             p.axis.visible = False; p.grid.visible = False\n",
    "#             p.rect(x='x', y='y', width=1, height=1, source=source, fill_color={'field': 'value', 'transform': mapper}, line_color=None)\n",
    "#             color_bar = ColorBar(color_mapper=mapper, ticker=BasicTicker(), label_standoff=8, border_line_color=None, location=(0,0), width=8)\n",
    "#             p.add_layout(color_bar, 'right')\n",
    "            \n",
    "#             hover = p.select(dict(type=HoverTool))\n",
    "#             hover.tooltips = \"\"\"\n",
    "#             <div style=\"display: flex; flex-direction: column; align-items: center; background: white; padding: 5px;\">\n",
    "#                 <div style=\"font-weight: bold; margin-bottom: 5px;\">@metric (r=@radius) Val: @value{0.000}</div>\n",
    "#                 <div style=\"display: flex; flex-direction: row; gap: 10px;\">\n",
    "#                     <div style=\"text-align: center;\"><span style=\"font-size: 10px;\">Row: @id_row</span><br><img src=\"@img_row\" style=\"width: auto; height: auto;\"></div>\n",
    "#                     <div style=\"text-align: center;\"><span style=\"font-size: 10px;\">Col: @id_col</span><br><img src=\"@img_col\" style=\"width: auto; height: auto;\"></div>\n",
    "#                 </div>\n",
    "#             </div>\n",
    "#             \"\"\"\n",
    "#             row_plots.append(p)\n",
    "#         grid_layout.append(row_plots)\n",
    "#     show(gridplot(grid_layout))\n",
    "\n",
    "# # def plot_interactive_umap_grid(umap_data: dict, population_images: list, max_show_radius: int, plot_width=None, plot_height=350):\n",
    "# #     \"\"\"Creates a Grid of Interactive UMAP Scatter plots.\"\"\"\n",
    "# #     num_cols = len(umap_data)\n",
    "# #     if plot_width is None: plot_width = 700 if num_cols == 1 else 350\n",
    "# #     n = len(population_images)\n",
    "# #     rgba_colors = plt.cm.rainbow(np.linspace(0, 1, n))\n",
    "# #     hex_colors = [to_hex(c) for c in rgba_colors]\n",
    "    \n",
    "# #     grid_layout = []\n",
    "# #     for r in range(max_show_radius + 1):\n",
    "# #         row_plots = []\n",
    "# #         for name, matrix_dict in umap_data.items():\n",
    "# #             if r in matrix_dict:\n",
    "# #                 emb = matrix_dict[r]\n",
    "# #                 if emb.ndim != 2 or emb.shape[1] != 2:\n",
    "# #                     p = figure(title=f\"r:{r} {name} (No Data)\", width=plot_width, height=plot_height); row_plots.append(p); continue\n",
    "# #             else:\n",
    "# #                 p = figure(title=f\"r:{r} {name} (Missing)\", width=plot_width, height=plot_height); row_plots.append(p); continue\n",
    "\n",
    "# #             robots_df = pd.DataFrame({\"x\": emb[:, 0], \"y\": emb[:, 1], \"digit\": [str(i) for i in range(n)], \"image\": population_images, \"color\": hex_colors})\n",
    "# #             source = ColumnDataSource(robots_df)\n",
    "# #             p = figure(title=f\"r:{r} {name}\", width=plot_width, height=plot_height, tools=\"pan,wheel_zoom,reset,save\", toolbar_location=\"above\")\n",
    "# #             p.scatter('x', 'y', source=source, color='color', line_alpha=0.6, fill_alpha=0.7, size=8)\n",
    "# #             hover = HoverTool(tooltips=\"\"\"<div><img src='@image' style='float:left; margin:5px; width:auto; height:auto;'/></div><div style=\"font-size:12px; font-weight: bold;\"><span style='color:#224499'>ID: @digit</span></div>\"\"\")\n",
    "# #             p.add_tools(hover)\n",
    "# #             row_plots.append(p)\n",
    "# #         grid_layout.append(row_plots)\n",
    "# #     show(gridplot(grid_layout))\n",
    "\n",
    "# # --- 3. Static Matplotlib Functions (Rows of Pairs) ---\n",
    "\n",
    "# # def view_horizontal_groups(image_data_tuples, titles=None):\n",
    "# #     \"\"\"\n",
    "# #     Plots horizontal groups without rescaling images of different sizes.\n",
    "# #     Uses pixel-perfect width_ratios.\n",
    "# #     Args:\n",
    "# #         image_data_tuples: List of lists containing base64 image strings.\n",
    "# #                            e.g. [[img_str_A, img_str_B], [img_str_C, img_str_D]]\n",
    "# #     \"\"\"\n",
    "# #     # --- 1. Pre-fetch ALL images to get dimensions ---\n",
    "# #     processed_items = []  # Will store dicts: {'type': 'img', 'data': img} or {'type': 'gap'}\n",
    "    \n",
    "# #     GROUP_GAP_PX = 100 \n",
    "# #     ROBOT_GAP_PX = 20  \n",
    "# #     DPI = 100  \n",
    "# #     max_height = 0\n",
    "    \n",
    "# #     # Map from flattened index back to group index for titles\n",
    "# #     axes_map = {} \n",
    "# #     current_index = 0\n",
    "\n",
    "# #     for i, group in enumerate(image_data_tuples):\n",
    "# #         for j, img_str in enumerate(group):\n",
    "# #             # Decode the base64 string to numpy array for plotting\n",
    "# #             img = decode_base64_image(img_str)\n",
    "# #             h, w = img.shape[:2]\n",
    "\n",
    "# #             if h > max_height: max_height = h\n",
    "\n",
    "# #             processed_items.append({\"type\": \"img\", \"data\": img, \"width\": w, \"height\": h})\n",
    "# #             current_index += 1\n",
    "\n",
    "# #             if j < len(group) - 1:\n",
    "# #                 processed_items.append({\"type\": \"gap\", \"width\": ROBOT_GAP_PX})\n",
    "# #                 current_index += 1\n",
    "\n",
    "# #         if i < len(image_data_tuples) - 1:\n",
    "# #             processed_items.append({\"type\": \"gap\", \"width\": GROUP_GAP_PX})\n",
    "# #             current_index += 1\n",
    "\n",
    "# #     # --- 2. Calculate Figure Dimensions ---\n",
    "# #     total_width_px = sum(item.get(\"width\", 0) for item in processed_items)\n",
    "# #     fig_width_in = total_width_px / DPI\n",
    "# #     fig_height_in = max_height / DPI\n",
    "# #     title_buffer_in = 0.5\n",
    "# #     fig_height_total = fig_height_in + title_buffer_in\n",
    "\n",
    "# #     # --- 3. Create Figure ---\n",
    "# #     fig = plt.figure(figsize=(fig_width_in, fig_height_total), dpi=DPI)\n",
    "# #     widths = [item.get(\"width\", 0) for item in processed_items]\n",
    "    \n",
    "# #     gs = gridspec.GridSpec(1, len(processed_items), figure=fig, width_ratios=widths)\n",
    "# #     plt.subplots_adjust(left=0, right=1, bottom=0, top=fig_height_in / fig_height_total, wspace=0, hspace=0)\n",
    "\n",
    "# #     # --- 4. Plotting ---\n",
    "# #     flat_ptr = 0 # To track position in processed_items list\n",
    "\n",
    "# #     for idx, item in enumerate(processed_items):\n",
    "# #         if item[\"type\"] == \"gap\":\n",
    "# #             continue\n",
    "\n",
    "# #         ax = fig.add_subplot(gs[0, idx])\n",
    "# #         ax.imshow(item[\"data\"], aspect=\"equal\", interpolation=\"none\", origin=\"upper\")\n",
    "# #         ax.set_ylim(max_height, 0)\n",
    "# #         ax.set_xlim(0, item[\"width\"])\n",
    "# #         ax.axis(\"off\")\n",
    "        \n",
    "# #         # Store ax in map for title logic\n",
    "# #         axes_map[idx] = ax\n",
    "\n",
    "# #     # --- 5. Titles ---\n",
    "# #     if titles:\n",
    "# #         # We assume the processed_items structure directly maps to groups\n",
    "# #         # Re-iterate to find the start and end axis for each group\n",
    "# #         ptr = 0\n",
    "# #         for i, group in enumerate(image_data_tuples):\n",
    "# #             # Calculate how many items correspond to this group in the flat list\n",
    "# #             # Each robot (except last) adds 1 image + 1 gap. Last robot adds 1 image.\n",
    "# #             # Then there is 1 group gap (except last group).\n",
    "            \n",
    "# #             # Start of group\n",
    "# #             start_idx = ptr\n",
    "# #             start_ax = axes_map[start_idx]\n",
    "            \n",
    "# #             # Find end of group (index of the last robot image in this group)\n",
    "# #             # The number of slots used by robots = (len(group) * 2) - 1\n",
    "# #             # e.g., 2 robots -> [Img, Gap, Img] -> offset is 2\n",
    "# #             offset = (len(group) * 2) - 1\n",
    "# #             end_idx = ptr + offset - 1 \n",
    "# #             end_ax = axes_map[end_idx]\n",
    "            \n",
    "# #             # Calculate Center\n",
    "# #             bbox_start = start_ax.get_position()\n",
    "# #             bbox_end = end_ax.get_position()\n",
    "# #             center_x = (bbox_start.x0 + bbox_end.x1) / 2\n",
    "\n",
    "# #             fig.text(center_x, 1.0 - (0.2 / fig_height_total), titles[i], ha=\"center\", va=\"top\", fontsize=10, weight=\"bold\")\n",
    "            \n",
    "# #             # Move pointer: robots + group gap\n",
    "# #             ptr += offset\n",
    "# #             if i < len(image_data_tuples) - 1:\n",
    "# #                 ptr += 1 # Skip group gap\n",
    "\n",
    "# #     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d552c9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def embeddable_image(data, scale=1.0):\n",
    "#     \"\"\"\n",
    "#     Simplified version: Accepts HxWx4 (RGBA) or HxWx3 (RGB).\n",
    "#     Returns PNG data-url with aspect ratio AND relative scale preserved.\n",
    "#     \"\"\"\n",
    "#     arr = np.asarray(data)\n",
    "    \n",
    "#     # Normalize types\n",
    "#     if np.issubdtype(arr.dtype, np.floating):\n",
    "#         if arr.max() <= 1.0:\n",
    "#             arr = (arr * 255).astype(np.uint8)\n",
    "#         else:\n",
    "#             arr = arr.astype(np.uint8)\n",
    "#     else:\n",
    "#         arr = arr.astype(np.uint8)\n",
    "\n",
    "#     # Detect Mode\n",
    "#     if arr.ndim == 3:\n",
    "#         mode = 'RGBA' if arr.shape[2] == 4 else 'RGB'\n",
    "#     else:\n",
    "#         mode = 'L' # Grayscale\n",
    "\n",
    "#     # Create Image\n",
    "#     img = Image.fromarray(arr, mode=mode)\n",
    "    \n",
    "#     # Resize by a constant factor to preserve relative size differences\n",
    "#     if scale != 1.0:\n",
    "#         new_size = (int(img.width * scale), int(img.height * scale))\n",
    "#         img = img.resize(new_size, Image.Resampling.BICUBIC)\n",
    "\n",
    "#     buffer = BytesIO()\n",
    "#     img.save(buffer, format='PNG')\n",
    "#     return 'data:image/png;base64,' + base64.b64encode(buffer.getvalue()).decode()\n",
    "\n",
    "# def robot_image(i):\n",
    "#     \"\"\"\n",
    "#     Generates the image for robot i using the global POPULATION and view function.\n",
    "#     \"\"\"\n",
    "#     graph = POPULATION[i].to_graph()  \n",
    "#     # Using remove_background=True for transparent PNGs\n",
    "#     img_arr = np.array(view(graph, return_img=True, tilted=True, remove_background=True))\n",
    "#     # Apply 0.6 scale: Consistent global scaling.\n",
    "#     # Keeps relative sizes correct (cores stay same size) but prevents giant tooltips.\n",
    "#     return embeddable_image(img_arr, scale=0.6)\n",
    "\n",
    "# def get_population_images(population_size):\n",
    "#     \"\"\"\n",
    "#     Pre-generates all images for the population to avoid re-rendering.\n",
    "#     \"\"\"\n",
    "#     return [robot_image(i) for i in track(range(population_size), description=f\"Generating {population_size} images...\")]\n",
    "\n",
    "# def decode_base64_image(data_url):\n",
    "#     \"\"\"\n",
    "#     Helper to convert the stored base64 string back to a numpy array for matplotlib.\n",
    "#     \"\"\"\n",
    "#     header, encoded = data_url.split(\",\", 1)\n",
    "#     data = base64.b64decode(encoded)\n",
    "#     return np.array(Image.open(BytesIO(data)))\n",
    "\n",
    "# # --- 2. Interactive Bokeh Functions (Web/Interactive) ---\n",
    "\n",
    "# def matrix_to_heatmap_source(matrix, images, metric_name, radius):\n",
    "#     \"\"\"Converts matrix to Bokeh DataSource.\"\"\"\n",
    "#     N = matrix.shape[0]\n",
    "#     x_indices, y_indices = np.meshgrid(np.arange(N), np.arange(N))\n",
    "#     x_flat = x_indices.flatten()\n",
    "#     y_flat = N - 1 - y_indices.flatten() \n",
    "#     values = matrix.flatten()\n",
    "#     imgs_i = [images[r] for r in y_indices.flatten()]\n",
    "#     imgs_j = [images[c] for c in x_indices.flatten()]\n",
    "#     ids_i = [str(r) for r in y_indices.flatten()]\n",
    "#     ids_j = [str(c) for c in x_indices.flatten()]\n",
    "#     data = {\n",
    "#         'x': x_flat, 'y': y_flat, 'value': values,\n",
    "#         'img_row': imgs_i, 'img_col': imgs_j,\n",
    "#         'id_row': ids_i, 'id_col': ids_j,\n",
    "#         'metric': [metric_name] * len(values),\n",
    "#         'radius': [radius] * len(values)\n",
    "#     }\n",
    "#     return ColumnDataSource(data)\n",
    "\n",
    "# def plot_interactive_heatmaps(all_matrix_data: dict, population_images: list, max_show_radius: int, plot_width=None, plot_height=None, palette=\"Reds256\"):\n",
    "#     \"\"\"Creates a Grid of Interactive Heatmaps using Bokeh.\"\"\"\n",
    "#     num_cols = len(all_matrix_data)\n",
    "#     if plot_width is None: plot_width = 650 if num_cols == 1 else 350\n",
    "#     if plot_height is None: plot_height = 600 if num_cols == 1 else 300\n",
    "\n",
    "#     grid_layout = []\n",
    "#     for r in range(max_show_radius + 1):\n",
    "#         row_plots = []\n",
    "#         for name, matrix_dict in all_matrix_data.items():\n",
    "#             if r in matrix_dict: matrix = matrix_dict[r]\n",
    "#             else: matrix = np.zeros((1, 1))\n",
    "            \n",
    "#             source = matrix_to_heatmap_source(matrix, population_images, name, r)\n",
    "#             vmin, vmax = matrix.min(), matrix.max()\n",
    "#             mapper = LinearColorMapper(palette=palette, low=vmin, high=vmax)\n",
    "            \n",
    "#             p = figure(title=f\"r:{r} {name}\", x_range=(-0.5, matrix.shape[1]-0.5), y_range=(-0.5, matrix.shape[0]-0.5), width=plot_width, height=plot_height, tools=\"hover,save,reset\", toolbar_location=\"above\")\n",
    "#             p.axis.visible = False; p.grid.visible = False\n",
    "#             p.rect(x='x', y='y', width=1, height=1, source=source, fill_color={'field': 'value', 'transform': mapper}, line_color=None)\n",
    "#             color_bar = ColorBar(color_mapper=mapper, ticker=BasicTicker(), label_standoff=8, border_line_color=None, location=(0,0), width=8)\n",
    "#             p.add_layout(color_bar, 'right')\n",
    "            \n",
    "#             hover = p.select(dict(type=HoverTool))\n",
    "#             # REMOVED max-width/height. \n",
    "#             # Images are now naturally scaled by 'robot_image' (0.6x), so relative sizes are correct.\n",
    "#             hover.tooltips = \"\"\"\n",
    "#             <div style=\"display: flex; flex-direction: column; align-items: center; background: white; padding: 5px;\">\n",
    "#                 <div style=\"font-weight: bold; margin-bottom: 5px;\">@metric (r=@radius) Val: @value{0.000}</div>\n",
    "#                 <div style=\"display: flex; flex-direction: row; gap: 10px;\">\n",
    "#                     <div style=\"text-align: center;\"><span style=\"font-size: 10px;\">Row: @id_row</span><br><img src=\"@img_row\" style=\"width: auto; height: auto;\"></div>\n",
    "#                     <div style=\"text-align: center;\"><span style=\"font-size: 10px;\">Col: @id_col</span><br><img src=\"@img_col\" style=\"width: auto; height: auto;\"></div>\n",
    "#                 </div>\n",
    "#             </div>\n",
    "#             \"\"\"\n",
    "#             row_plots.append(p)\n",
    "#         grid_layout.append(row_plots)\n",
    "#     show(gridplot(grid_layout))\n",
    "\n",
    "# # def plot_interactive_umap_grid(umap_data: dict, population_images: list, max_show_radius: int, plot_width=None, plot_height=350):\n",
    "# #     \"\"\"Creates a Grid of Interactive UMAP Scatter plots.\"\"\"\n",
    "# #     num_cols = len(umap_data)\n",
    "# #     if plot_width is None: plot_width = 700 if num_cols == 1 else 350\n",
    "# #     n = len(population_images)\n",
    "# #     rgba_colors = plt.cm.rainbow(np.linspace(0, 1, n))\n",
    "# #     hex_colors = [to_hex(c) for c in rgba_colors]\n",
    "    \n",
    "# #     grid_layout = []\n",
    "# #     for r in range(max_show_radius + 1):\n",
    "# #         row_plots = []\n",
    "# #         for name, matrix_dict in umap_data.items():\n",
    "# #             if r in matrix_dict:\n",
    "# #                 emb = matrix_dict[r]\n",
    "# #                 if emb.ndim != 2 or emb.shape[1] != 2:\n",
    "# #                     p = figure(title=f\"r:{r} {name} (No Data)\", width=plot_width, height=plot_height); row_plots.append(p); continue\n",
    "# #             else:\n",
    "# #                 p = figure(title=f\"r:{r} {name} (Missing)\", width=plot_width, height=plot_height); row_plots.append(p); continue\n",
    "\n",
    "# #             robots_df = pd.DataFrame({\"x\": emb[:, 0], \"y\": emb[:, 1], \"digit\": [str(i) for i in range(n)], \"image\": population_images, \"color\": hex_colors})\n",
    "# #             source = ColumnDataSource(robots_df)\n",
    "# #             p = figure(title=f\"r:{r} {name}\", width=plot_width, height=plot_height, tools=\"pan,wheel_zoom,reset,save\", toolbar_location=\"above\")\n",
    "# #             p.scatter('x', 'y', source=source, color='color', line_alpha=0.6, fill_alpha=0.7, size=8)\n",
    "# #             # REMOVED max-width/height here as well\n",
    "# #             hover = HoverTool(tooltips=\"\"\"<div><img src='@image' style='float:left; margin:5px; width:auto; height:auto;'/></div><div style=\"font-size:12px; font-weight: bold;\"><span style='color:#224499'>ID: @digit</span></div>\"\"\")\n",
    "# #             p.add_tools(hover)\n",
    "# #             row_plots.append(p)\n",
    "# #         grid_layout.append(row_plots)\n",
    "# #     show(gridplot(grid_layout))\n",
    "\n",
    "# # --- 3. Static Matplotlib Functions (Rows of Pairs) ---\n",
    "\n",
    "# # def view_horizontal_groups(image_data_tuples, titles=None):\n",
    "# #     \"\"\"\n",
    "# #     Plots horizontal groups without rescaling images of different sizes.\n",
    "# #     Uses pixel-perfect width_ratios.\n",
    "# #     Args:\n",
    "# #         image_data_tuples: List of lists containing base64 image strings.\n",
    "# #                            e.g. [[img_str_A, img_str_B], [img_str_C, img_str_D]]\n",
    "# #     \"\"\"\n",
    "# #     # --- 1. Pre-fetch ALL images to get dimensions ---\n",
    "# #     processed_items = []  # Will store dicts: {'type': 'img', 'data': img} or {'type': 'gap'}\n",
    "    \n",
    "# #     GROUP_GAP_PX = 100 \n",
    "# #     ROBOT_GAP_PX = 20  \n",
    "# #     # LOWERED DPI to 60. \n",
    "# #     # This makes the images appear physically larger in the figure layout, \n",
    "# #     # preventing the text (titles) from overpowering the visual content.\n",
    "# #     DPI = 60  \n",
    "# #     max_height = 0\n",
    "    \n",
    "# #     # Map from flattened index back to group index for titles\n",
    "# #     axes_map = {} \n",
    "# #     current_index = 0\n",
    "\n",
    "# #     for i, group in enumerate(image_data_tuples):\n",
    "# #         for j, img_str in enumerate(group):\n",
    "# #             # Decode the base64 string to numpy array for plotting\n",
    "# #             img = decode_base64_image(img_str)\n",
    "# #             h, w = img.shape[:2]\n",
    "\n",
    "# #             if h > max_height: max_height = h\n",
    "\n",
    "# #             processed_items.append({\"type\": \"img\", \"data\": img, \"width\": w, \"height\": h})\n",
    "# #             current_index += 1\n",
    "\n",
    "# #             if j < len(group) - 1:\n",
    "# #                 processed_items.append({\"type\": \"gap\", \"width\": ROBOT_GAP_PX})\n",
    "# #                 current_index += 1\n",
    "\n",
    "# #         if i < len(image_data_tuples) - 1:\n",
    "# #             processed_items.append({\"type\": \"gap\", \"width\": GROUP_GAP_PX})\n",
    "# #             current_index += 1\n",
    "\n",
    "# #     # --- 2. Calculate Figure Dimensions ---\n",
    "# #     total_width_px = sum(item.get(\"width\", 0) for item in processed_items)\n",
    "# #     fig_width_in = total_width_px / DPI\n",
    "# #     fig_height_in = max_height / DPI\n",
    "# #     title_buffer_in = 0.5\n",
    "# #     fig_height_total = fig_height_in + title_buffer_in\n",
    "\n",
    "# #     # --- 3. Create Figure ---\n",
    "# #     fig = plt.figure(figsize=(fig_width_in, fig_height_total), dpi=DPI)\n",
    "# #     widths = [item.get(\"width\", 0) for item in processed_items]\n",
    "    \n",
    "# #     gs = gridspec.GridSpec(1, len(processed_items), figure=fig, width_ratios=widths)\n",
    "# #     plt.subplots_adjust(left=0, right=1, bottom=0, top=fig_height_in / fig_height_total, wspace=0, hspace=0)\n",
    "\n",
    "# #     # --- 4. Plotting ---\n",
    "# #     flat_ptr = 0 # To track position in processed_items list\n",
    "\n",
    "# #     for idx, item in enumerate(processed_items):\n",
    "# #         if item[\"type\"] == \"gap\":\n",
    "# #             continue\n",
    "\n",
    "# #         ax = fig.add_subplot(gs[0, idx])\n",
    "# #         ax.imshow(item[\"data\"], aspect=\"equal\", interpolation=\"none\", origin=\"upper\")\n",
    "# #         ax.set_ylim(max_height, 0)\n",
    "# #         ax.set_xlim(0, item[\"width\"])\n",
    "# #         ax.axis(\"off\")\n",
    "        \n",
    "# #         # Store ax in map for title logic\n",
    "# #         axes_map[idx] = ax\n",
    "\n",
    "# #     # --- 5. Titles ---\n",
    "# #     if titles:\n",
    "# #         # We assume the processed_items structure directly maps to groups\n",
    "# #         # Re-iterate to find the start and end axis for each group\n",
    "# #         ptr = 0\n",
    "# #         for i, group in enumerate(image_data_tuples):\n",
    "# #             # Calculate how many items correspond to this group in the flat list\n",
    "# #             # Each robot (except last) adds 1 image + 1 gap. Last robot adds 1 image.\n",
    "# #             # Then there is 1 group gap (except last group).\n",
    "            \n",
    "# #             # Start of group\n",
    "# #             start_idx = ptr\n",
    "# #             start_ax = axes_map[start_idx]\n",
    "            \n",
    "# #             # Find end of group (index of the last robot image in this group)\n",
    "# #             # The number of slots used by robots = (len(group) * 2) - 1\n",
    "# #             # e.g., 2 robots -> [Img, Gap, Img] -> offset is 2\n",
    "# #             offset = (len(group) * 2) - 1\n",
    "# #             end_idx = ptr + offset - 1 \n",
    "# #             end_ax = axes_map[end_idx]\n",
    "            \n",
    "# #             # Calculate Center\n",
    "# #             bbox_start = start_ax.get_position()\n",
    "# #             bbox_end = end_ax.get_position()\n",
    "# #             center_x = (bbox_start.x0 + bbox_end.x1) / 2\n",
    "\n",
    "# #             fig.text(center_x, 1.0 - (0.2 / fig_height_total), titles[i], ha=\"center\", va=\"top\", fontsize=10, weight=\"bold\")\n",
    "            \n",
    "# #             # Move pointer: robots + group gap\n",
    "# #             ptr += offset\n",
    "# #             if i < len(image_data_tuples) - 1:\n",
    "# #                 ptr += 1 # Skip group gap\n",
    "\n",
    "# #     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b37cf6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embeddable_image(data, scale=1.0):\n",
    "    \"\"\"\n",
    "    Simplified version: Accepts HxWx4 (RGBA) or HxWx3 (RGB).\n",
    "    Returns PNG data-url with aspect ratio AND relative scale preserved.\n",
    "    \"\"\"\n",
    "    arr = np.asarray(data)\n",
    "    \n",
    "    # Normalize types\n",
    "    if np.issubdtype(arr.dtype, np.floating):\n",
    "        if arr.max() <= 1.0:\n",
    "            arr = (arr * 255).astype(np.uint8)\n",
    "        else:\n",
    "            arr = arr.astype(np.uint8)\n",
    "    else:\n",
    "        arr = arr.astype(np.uint8)\n",
    "\n",
    "    # Detect Mode\n",
    "    if arr.ndim == 3:\n",
    "        mode = 'RGBA' if arr.shape[2] == 4 else 'RGB'\n",
    "    else:\n",
    "        mode = 'L' # Grayscale\n",
    "\n",
    "    # Create Image\n",
    "    img = Image.fromarray(arr, mode=mode)\n",
    "    \n",
    "    # Resize by a constant factor to preserve relative size differences\n",
    "    if scale != 1.0:\n",
    "        new_size = (int(img.width * scale), int(img.height * scale))\n",
    "        img = img.resize(new_size, Image.Resampling.BICUBIC)\n",
    "\n",
    "    buffer = BytesIO()\n",
    "    img.save(buffer, format='PNG')\n",
    "    return 'data:image/png;base64,' + base64.b64encode(buffer.getvalue()).decode()\n",
    "\n",
    "def robot_image(i):\n",
    "    \"\"\"\n",
    "    Generates the image for robot i using the global POPULATION and view function.\n",
    "    \"\"\"\n",
    "    graph = POPULATION[i].to_graph()  \n",
    "    # Using remove_background=True for transparent PNGs\n",
    "    img_arr = np.array(view(graph, return_img=True, tilted=True, remove_background=True))\n",
    "    \n",
    "    # SCALE 1.0: High Quality for Matplotlib.\n",
    "    return embeddable_image(img_arr, scale=1.0)\n",
    "\n",
    "def get_population_images(population_size):\n",
    "    \"\"\"\n",
    "    Pre-generates all images for the population to avoid re-rendering.\n",
    "    \"\"\"\n",
    "    return [robot_image(i) for i in track(range(population_size), description=f\"Generating {population_size} images...\")]\n",
    "\n",
    "def decode_base64_image(data_url):\n",
    "    \"\"\"Helper to convert base64 string back to numpy array.\"\"\"\n",
    "    header, encoded = data_url.split(\",\", 1)\n",
    "    data = base64.b64decode(encoded)\n",
    "    return np.array(Image.open(BytesIO(data)))\n",
    "\n",
    "def create_thumbnails(image_list, scale=0.5):\n",
    "    \"\"\"\n",
    "    Takes a list of base64 images (HQ) and creates a new list of scaled-down \n",
    "    thumbnails (preserving relative aspect ratio) for use in web tooltips.\n",
    "    \"\"\"\n",
    "    thumbnails = []\n",
    "    for b64_str in image_list:\n",
    "        # Decode\n",
    "        header, encoded = b64_str.split(\",\", 1)\n",
    "        data = base64.b64decode(encoded)\n",
    "        img = Image.open(BytesIO(data))\n",
    "        \n",
    "        # Resize\n",
    "        new_size = (int(img.width * scale), int(img.height * scale))\n",
    "        img_small = img.resize(new_size, Image.Resampling.BICUBIC)\n",
    "        \n",
    "        # Re-encode\n",
    "        buffer = BytesIO()\n",
    "        img_small.save(buffer, format='PNG')\n",
    "        thumb_str = 'data:image/png;base64,' + base64.b64encode(buffer.getvalue()).decode()\n",
    "        thumbnails.append(thumb_str)\n",
    "    return thumbnails\n",
    "\n",
    "# --- 2. Interactive Bokeh Functions (Web/Interactive) ---\n",
    "\n",
    "def matrix_to_heatmap_source(matrix, images, metric_name, radius):\n",
    "    \"\"\"Converts matrix to Bokeh DataSource.\"\"\"\n",
    "    N = matrix.shape[0]\n",
    "    x_indices, y_indices = np.meshgrid(np.arange(N), np.arange(N))\n",
    "    x_flat = x_indices.flatten()\n",
    "    y_flat = N - 1 - y_indices.flatten() \n",
    "    values = matrix.flatten()\n",
    "    imgs_i = [images[r] for r in y_indices.flatten()]\n",
    "    imgs_j = [images[c] for c in x_indices.flatten()]\n",
    "    ids_i = [str(r) for r in y_indices.flatten()]\n",
    "    ids_j = [str(c) for c in x_indices.flatten()]\n",
    "    data = {\n",
    "        'x': x_flat, 'y': y_flat, 'value': values,\n",
    "        'img_row': imgs_i, 'img_col': imgs_j,\n",
    "        'id_row': ids_i, 'id_col': ids_j,\n",
    "        'metric': [metric_name] * len(values),\n",
    "        'radius': [radius] * len(values)\n",
    "    }\n",
    "    return ColumnDataSource(data)\n",
    "\n",
    "def plot_interactive_heatmaps(all_matrix_data: dict, population_images: list, max_show_radius: int, plot_width=None, plot_height=None, palette=\"Reds256\", thumbnail_scale=0.5):\n",
    "    \"\"\"\n",
    "    Creates a Grid of Interactive Heatmaps using Bokeh.\n",
    "    Args:\n",
    "        thumbnail_scale: Factor to scale images down for the tooltip (default 0.5)\n",
    "    \"\"\"\n",
    "    # Create thumbnails specifically for this plot (leaves original list untouched)\n",
    "    thumb_images = create_thumbnails(population_images, scale=thumbnail_scale)\n",
    "\n",
    "    num_cols = len(all_matrix_data)\n",
    "    if plot_width is None: plot_width = 650 if num_cols == 1 else 350\n",
    "    if plot_height is None: plot_height = 600 if num_cols == 1 else 300\n",
    "\n",
    "    grid_layout = []\n",
    "    for r in range(max_show_radius + 1):\n",
    "        row_plots = []\n",
    "        for name, matrix_dict in all_matrix_data.items():\n",
    "            if r in matrix_dict: matrix = matrix_dict[r]\n",
    "            else: matrix = np.zeros((1, 1))\n",
    "            \n",
    "            # Use thumbnails here\n",
    "            source = matrix_to_heatmap_source(matrix, thumb_images, name, r)\n",
    "            vmin, vmax = matrix.min(), matrix.max()\n",
    "            mapper = LinearColorMapper(palette=palette, low=vmin, high=vmax)\n",
    "            \n",
    "            p = figure(title=f\"r:{r} {name}\", x_range=(-0.5, matrix.shape[1]-0.5), y_range=(-0.5, matrix.shape[0]-0.5), width=plot_width, height=plot_height, tools=\"hover,save,reset\", toolbar_location=\"above\")\n",
    "            p.axis.visible = False; p.grid.visible = False\n",
    "            p.rect(x='x', y='y', width=1, height=1, source=source, fill_color={'field': 'value', 'transform': mapper}, line_color=None)\n",
    "            color_bar = ColorBar(color_mapper=mapper, ticker=BasicTicker(), label_standoff=8, border_line_color=None, location=(0,0), width=8)\n",
    "            p.add_layout(color_bar, 'right')\n",
    "            \n",
    "            hover = p.select(dict(type=HoverTool))\n",
    "            # No CSS max-width constraints. We rely on the thumbnail being physically smaller (0.5x)\n",
    "            # but proportional.\n",
    "            hover.tooltips = \"\"\"\n",
    "            <div style=\"display: flex; flex-direction: column; align-items: center; background: white; padding: 5px;\">\n",
    "                <div style=\"font-weight: bold; margin-bottom: 5px;\">@metric (r=@radius) Val: @value{0.000}</div>\n",
    "                <div style=\"display: flex; flex-direction: row; gap: 10px;\">\n",
    "                    <div style=\"text-align: center;\"><span style=\"font-size: 10px;\">Row: @id_row</span><br><img src=\"@img_row\" style=\"width: auto; height: auto;\"></div>\n",
    "                    <div style=\"text-align: center;\"><span style=\"font-size: 10px;\">Col: @id_col</span><br><img src=\"@img_col\" style=\"width: auto; height: auto;\"></div>\n",
    "                </div>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "            row_plots.append(p)\n",
    "        grid_layout.append(row_plots)\n",
    "    show(gridplot(grid_layout))\n",
    "\n",
    "def plot_interactive_umap_grid(umap_data: dict, population_images: list, max_show_radius: int, plot_width=None, plot_height=350, thumbnail_scale=0.5):\n",
    "    \"\"\"\n",
    "    Creates a Grid of Interactive UMAP Scatter plots.\n",
    "    Args:\n",
    "        thumbnail_scale: Factor to scale images down for the tooltip (default 0.5)\n",
    "    \"\"\"\n",
    "    # Create thumbnails specifically for this plot\n",
    "    thumb_images = create_thumbnails(population_images, scale=thumbnail_scale)\n",
    "\n",
    "    num_cols = len(umap_data)\n",
    "    if plot_width is None: plot_width = 700 if num_cols == 1 else 350\n",
    "    n = len(population_images)\n",
    "    rgba_colors = plt.cm.rainbow(np.linspace(0, 1, n))\n",
    "    hex_colors = [to_hex(c) for c in rgba_colors]\n",
    "    \n",
    "    grid_layout = []\n",
    "    for r in range(max_show_radius + 1):\n",
    "        row_plots = []\n",
    "        for name, matrix_dict in umap_data.items():\n",
    "            if r in matrix_dict:\n",
    "                emb = matrix_dict[r]\n",
    "                if emb.ndim != 2 or emb.shape[1] != 2:\n",
    "                    p = figure(title=f\"r:{r} {name} (No Data)\", width=plot_width, height=plot_height); row_plots.append(p); continue\n",
    "            else:\n",
    "                p = figure(title=f\"r:{r} {name} (Missing)\", width=plot_width, height=plot_height); row_plots.append(p); continue\n",
    "\n",
    "            # Use thumb_images here\n",
    "            robots_df = pd.DataFrame({\"x\": emb[:, 0], \"y\": emb[:, 1], \"digit\": [str(i) for i in range(n)], \"image\": thumb_images, \"color\": hex_colors})\n",
    "            source = ColumnDataSource(robots_df)\n",
    "            p = figure(title=f\"r:{r} {name}\", width=plot_width, height=plot_height, tools=\"pan,wheel_zoom,reset,save\", toolbar_location=\"above\")\n",
    "            p.scatter('x', 'y', source=source, color='color', line_alpha=0.6, fill_alpha=0.7, size=8)\n",
    "            hover = HoverTool(tooltips=\"\"\"<div><img src='@image' style='float:left; margin:5px; width:auto; height:auto;'/></div><div style=\"font-size:12px; font-weight: bold;\"><span style='color:#224499'>ID: @digit</span></div>\"\"\")\n",
    "            p.add_tools(hover)\n",
    "            row_plots.append(p)\n",
    "        grid_layout.append(row_plots)\n",
    "    show(gridplot(grid_layout))\n",
    "\n",
    "# --- 3. Static Matplotlib Functions (Rows of Pairs) ---\n",
    "\n",
    "# def view_horizontal_groups(image_data_tuples, titles=None):\n",
    "#     \"\"\"\n",
    "#     Plots horizontal groups without rescaling images of different sizes.\n",
    "#     Uses pixel-perfect width_ratios.\n",
    "#     Args:\n",
    "#         image_data_tuples: List of lists containing base64 image strings (HQ).\n",
    "#     \"\"\"\n",
    "#     # --- 1. Pre-fetch ALL images to get dimensions ---\n",
    "#     processed_items = []  # Will store dicts: {'type': 'img', 'data': img} or {'type': 'gap'}\n",
    "    \n",
    "#     GROUP_GAP_PX = 100 \n",
    "#     ROBOT_GAP_PX = 20  \n",
    "#     DPI = 100 # High DPI for Sharp Text/Images\n",
    "#     max_height = 0\n",
    "    \n",
    "#     # Map from flattened index back to group index for titles\n",
    "#     axes_map = {} \n",
    "#     current_index = 0\n",
    "\n",
    "#     for i, group in enumerate(image_data_tuples):\n",
    "#         for j, img_str in enumerate(group):\n",
    "#             # Decode the base64 string to numpy array for plotting\n",
    "#             img = decode_base64_image(img_str)\n",
    "#             h, w = img.shape[:2]\n",
    "\n",
    "#             if h > max_height: max_height = h\n",
    "\n",
    "#             processed_items.append({\"type\": \"img\", \"data\": img, \"width\": w, \"height\": h})\n",
    "#             current_index += 1\n",
    "\n",
    "#             if j < len(group) - 1:\n",
    "#                 processed_items.append({\"type\": \"gap\", \"width\": ROBOT_GAP_PX})\n",
    "#                 current_index += 1\n",
    "\n",
    "#         if i < len(image_data_tuples) - 1:\n",
    "#             processed_items.append({\"type\": \"gap\", \"width\": GROUP_GAP_PX})\n",
    "#             current_index += 1\n",
    "\n",
    "#     # --- 2. Calculate Figure Dimensions ---\n",
    "#     total_width_px = sum(item.get(\"width\", 0) for item in processed_items)\n",
    "#     fig_width_in = total_width_px / DPI\n",
    "#     fig_height_in = max_height / DPI\n",
    "#     title_buffer_in = 0.5\n",
    "#     fig_height_total = fig_height_in + title_buffer_in\n",
    "\n",
    "#     # --- 3. Create Figure ---\n",
    "#     fig = plt.figure(figsize=(fig_width_in, fig_height_total), dpi=DPI)\n",
    "#     widths = [item.get(\"width\", 0) for item in processed_items]\n",
    "    \n",
    "#     gs = gridspec.GridSpec(1, len(processed_items), figure=fig, width_ratios=widths)\n",
    "#     plt.subplots_adjust(left=0, right=1, bottom=0, top=fig_height_in / fig_height_total, wspace=0, hspace=0)\n",
    "\n",
    "#     # --- 4. Plotting ---\n",
    "#     flat_ptr = 0 # To track position in processed_items list\n",
    "\n",
    "#     for idx, item in enumerate(processed_items):\n",
    "#         if item[\"type\"] == \"gap\":\n",
    "#             continue\n",
    "\n",
    "#         ax = fig.add_subplot(gs[0, idx])\n",
    "#         ax.imshow(item[\"data\"], aspect=\"equal\", interpolation=\"none\", origin=\"upper\")\n",
    "#         ax.set_ylim(max_height, 0)\n",
    "#         ax.set_xlim(0, item[\"width\"])\n",
    "#         ax.axis(\"off\")\n",
    "        \n",
    "#         # Store ax in map for title logic\n",
    "#         axes_map[idx] = ax\n",
    "\n",
    "#     # --- 5. Titles ---\n",
    "#     if titles:\n",
    "#         # We assume the processed_items structure directly maps to groups\n",
    "#         # Re-iterate to find the start and end axis for each group\n",
    "#         ptr = 0\n",
    "#         for i, group in enumerate(image_data_tuples):\n",
    "#             # Calculate how many items correspond to this group in the flat list\n",
    "#             # Each robot (except last) adds 1 image + 1 gap. Last robot adds 1 image.\n",
    "#             # Then there is 1 group gap (except last group).\n",
    "            \n",
    "#             # Start of group\n",
    "#             start_idx = ptr\n",
    "#             start_ax = axes_map[start_idx]\n",
    "            \n",
    "#             # Find end of group (index of the last robot image in this group)\n",
    "#             # The number of slots used by robots = (len(group) * 2) - 1\n",
    "#             # e.g., 2 robots -> [Img, Gap, Img] -> offset is 2\n",
    "#             offset = (len(group) * 2) - 1\n",
    "#             end_idx = ptr + offset - 1 \n",
    "#             end_ax = axes_map[end_idx]\n",
    "            \n",
    "#             # Calculate Center\n",
    "#             bbox_start = start_ax.get_position()\n",
    "#             bbox_end = end_ax.get_position()\n",
    "#             center_x = (bbox_start.x0 + bbox_end.x1) / 2\n",
    "\n",
    "#             fig.text(center_x, 1.0 - (0.2 / fig_height_total), titles[i], ha=\"center\", va=\"top\", fontsize=10, weight=\"bold\")\n",
    "            \n",
    "#             # Move pointer: robots + group gap\n",
    "#             ptr += offset\n",
    "#             if i < len(image_data_tuples) - 1:\n",
    "#                 ptr += 1 # Skip group gap\n",
    "\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff4c1cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _stitch_images_horizontally(images, target_height=None, gap_px=20):\n",
    "    \"\"\"\n",
    "    Stitches images horizontally with white background (handles transparency).\n",
    "    If target_height is provided, pads all images vertically to match that height (alignment: top).\n",
    "    \"\"\"\n",
    "    if not images or all(img is None for img in images):\n",
    "        return None, 0, 0\n",
    "    \n",
    "    valid_images = [img for img in images if img is not None]\n",
    "    if not valid_images: return None, 0, 0\n",
    "\n",
    "    # 1. Normalize Types to uint8 RGB and composite transparent images onto white\n",
    "    normalized_imgs = []\n",
    "    for img in valid_images:\n",
    "        # Handle float 0-1\n",
    "        if np.issubdtype(img.dtype, np.floating):\n",
    "            img = (np.clip(img, 0, 1) * 255).astype(np.uint8)\n",
    "        else:\n",
    "            img = img.astype(np.uint8)\n",
    "        \n",
    "        # Handle Alpha channel - composite onto white background\n",
    "        if len(img.shape) == 3 and img.shape[2] == 4:\n",
    "            # Extract RGB and Alpha\n",
    "            rgb = img[:, :, :3]\n",
    "            alpha = img[:, :, 3:4] / 255.0  # Normalize alpha to 0-1\n",
    "            \n",
    "            # Create white background\n",
    "            white_bg = np.full_like(rgb, 255, dtype=np.uint8)\n",
    "            \n",
    "            # Composite: result = foreground * alpha + background * (1 - alpha)\n",
    "            img = (rgb * alpha + white_bg * (1 - alpha)).astype(np.uint8)\n",
    "        elif len(img.shape) == 3 and img.shape[2] >= 3:\n",
    "            img = img[:, :, :3]\n",
    "            \n",
    "        normalized_imgs.append(img)\n",
    "\n",
    "    # 2. Determine Canvas Height\n",
    "    current_max_h = max(img.shape[0] for img in normalized_imgs)\n",
    "    final_h = target_height if target_height and target_height > current_max_h else current_max_h\n",
    "\n",
    "    # 3. Create White Gap Column\n",
    "    white_gap_col = np.full((final_h, gap_px, 3), 255, dtype=np.uint8)\n",
    "\n",
    "    # 4. Stitching Loop\n",
    "    stitched = None\n",
    "    \n",
    "    for i, img in enumerate(normalized_imgs):\n",
    "        h, w = img.shape[:2]\n",
    "        \n",
    "        # Pad image to final_h (fill bottom with white)\n",
    "        if h < final_h:\n",
    "            pad = np.full((final_h - h, w, 3), 255, dtype=np.uint8)\n",
    "            img = np.vstack((img, pad))\n",
    "            \n",
    "        if stitched is None:\n",
    "            stitched = img\n",
    "        else:\n",
    "            stitched = np.hstack((stitched, white_gap_col, img))\n",
    "            \n",
    "    return stitched, stitched.shape[1], final_h\n",
    "\n",
    "def view_grid_of_groups(rows_of_tuples, rows_of_titles=None, col_headers=None, main_title=None):\n",
    "    \"\"\"\n",
    "    Plots a grid of groups where ALL images are scaled equally (no auto-zoom).\n",
    "    \"\"\"\n",
    "    if not rows_of_tuples: return\n",
    "\n",
    "    n_rows = len(rows_of_tuples)\n",
    "    n_cols = len(rows_of_tuples[0])\n",
    "    ROBOT_GAP_PX = 20\n",
    "    \n",
    "    # --- PASS 1: Calculate Global Max Dimensions and Process Images ---\n",
    "    global_max_h = 0\n",
    "    global_max_w = 0\n",
    "    \n",
    "    grid_data = [[None for _ in range(n_cols)] for _ in range(n_rows)]\n",
    "    \n",
    "    for r in range(n_rows):\n",
    "        for c in range(n_cols):\n",
    "            group_base64_strings = rows_of_tuples[r][c]\n",
    "            images = [decode_base64_image(s) for s in group_base64_strings]\n",
    "            \n",
    "            # Find max height in this specific group to update global max\n",
    "            for img in images:\n",
    "                if img is not None:\n",
    "                    if img.shape[0] > global_max_h: global_max_h = img.shape[0]\n",
    "            \n",
    "            grid_data[r][c] = images\n",
    "\n",
    "    # --- PASS 2: Stitch and Measure Widths ---\n",
    "    processed_images = []\n",
    "    \n",
    "    for r in range(n_rows):\n",
    "        row_imgs = []\n",
    "        for c in range(n_cols):\n",
    "            images = grid_data[r][c]\n",
    "            # Stitch using GLOBAL height (pads bottom with white)\n",
    "            stitched, w, h = _stitch_images_horizontally(images, target_height=global_max_h, gap_px=ROBOT_GAP_PX)\n",
    "            \n",
    "            if w > global_max_w: global_max_w = w\n",
    "            row_imgs.append(stitched)\n",
    "        processed_images.append(row_imgs)\n",
    "\n",
    "    # --- PASS 3: Plot with Fixed Limits ---\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, \n",
    "                             figsize=(4 * n_cols, 2.5 * n_rows), \n",
    "                             squeeze=False,\n",
    "                             facecolor='white')\n",
    "    \n",
    "    if main_title:\n",
    "        fig.suptitle(main_title, fontsize=16, weight=\"bold\", y=0.98, color='black')\n",
    "\n",
    "    for r in range(n_rows):\n",
    "        for c in range(n_cols):\n",
    "            ax = axes[r, c]\n",
    "            ax.set_facecolor('white')\n",
    "            \n",
    "            img_data = processed_images[r][c]\n",
    "            \n",
    "            if img_data is not None:\n",
    "                ax.imshow(img_data)\n",
    "            \n",
    "            # Force Equal Scaling\n",
    "            ax.set_xlim(0, global_max_w)\n",
    "            ax.set_ylim(global_max_h, 0)\n",
    "            ax.set_aspect('equal')\n",
    "            ax.axis('off')\n",
    "\n",
    "            # Titles and Headers\n",
    "            if rows_of_titles and r < len(rows_of_titles):\n",
    "                ax.set_title(rows_of_titles[r][c], fontsize=10, color='black', pad=0)\n",
    "\n",
    "            if r == 0 and col_headers and c < len(col_headers):\n",
    "                ax.text(0.5, 1, col_headers[c], transform=ax.transAxes, \n",
    "                        ha=\"center\", va=\"bottom\", fontsize=12, weight=\"bold\", color=\"#224499\")\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0.25, top=0.95, bottom=0.02)\n",
    "    plt.show()\n",
    "\n",
    "def plot_rows_for_radii(cumulative_data, sorted_data, population_images, max_radius: int, pair_rank: int = 0, labels: list[str] = None, main_title: str = None):\n",
    "    if labels is None: labels = list(cumulative_data.keys())\n",
    "    all_rows_robots = []\n",
    "    all_rows_titles = []\n",
    "    \n",
    "    for r in range(max_radius + 1):\n",
    "        robots_row = []\n",
    "        titles_row = []\n",
    "        for name in labels:\n",
    "            coords_list = sorted_data[name].get(r, [])\n",
    "            matrix = cumulative_data[name].get(r)\n",
    "            if coords_list and pair_rank < len(coords_list):\n",
    "                i, j = coords_list[pair_rank]\n",
    "            else:\n",
    "                i, j = (0, 0)\n",
    "            idx_i, idx_j = int(i), int(j)\n",
    "            val = matrix[idx_i, idx_j] if matrix is not None else 0.0\n",
    "            \n",
    "            robots_row.append([population_images[idx_i], population_images[idx_j]])\n",
    "            titles_row.append(f\"{name}\\nr:{r} ({idx_i},{idx_j}) val={val:.3f}\")\n",
    "            \n",
    "        all_rows_robots.append(robots_row)\n",
    "        all_rows_titles.append(titles_row)\n",
    "\n",
    "    view_grid_of_groups(all_rows_robots, all_rows_titles, col_headers=None, main_title=main_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5773e6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091b7bc7",
   "metadata": {},
   "source": [
    "## GLOBAL ANALYSIS SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67d15609",
   "metadata": {},
   "outputs": [],
   "source": [
    "POPULATION_SIZE = 100\n",
    "NUM_OF_MODULES = 20\n",
    "\n",
    "MAX_RADIUS = None\n",
    "\n",
    "CONFIG = ctk.SimilarityConfig(\n",
    "    max_tree_radius=MAX_RADIUS, radius_strategy=ctk.RadiusStrategy.NODE_LOCAL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "baab38b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "POPULATION = [\n",
    "    ctk.from_graph(generate_random_individual(NUM_OF_MODULES))\n",
    "    for _ in range(POPULATION_SIZE)\n",
    "]\n",
    "\n",
    "SUBTREES = [\n",
    "    ctk.collect_tree_hash_config_mode(individual, config=CONFIG)\n",
    "    for individual in POPULATION\n",
    "]\n",
    "\n",
    "COUNT_MATRIX_DICT = ctk.get_count_matrix(SUBTREES, CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6183f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cce372ae1bb343a6af34ec1f5397ef5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MESA: error: ZINK: failed to choose pdev\n",
      "glx: failed to create drisw screen\n",
      "Dropped Escape call with ulEscapeCode : 0x03007703\n"
     ]
    }
   ],
   "source": [
    "POPULATION_IMGS = get_population_images(POPULATION_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e904a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_tfidf_transformer(count_matrix):\n",
    "    transformer = TfidfTransformer()\n",
    "    tfidf_matrix = transformer.fit_transform(count_matrix)\n",
    "    return cosine_similarity(tfidf_matrix)\n",
    "\n",
    "\n",
    "def apply_umap_n2(count_matrix):\n",
    "    return umap.UMAP(metric=\"cosine\", n_neighbors=2).fit_transform(\n",
    "        count_matrix\n",
    "    )\n",
    "    \n",
    "def apply_umap_n20(count_matrix):\n",
    "    return umap.UMAP(metric=\"cosine\", n_neighbors=20).fit_transform(\n",
    "        count_matrix\n",
    "    )\n",
    "\n",
    "def apply_umap_n40(count_matrix):\n",
    "    return umap.UMAP(metric=\"cosine\", n_neighbors=40).fit_transform(\n",
    "        count_matrix\n",
    "    )\n",
    "\n",
    "def apply_emb_to_dist(umap_emb_matrix):\n",
    "    condensed_distances = pdist(umap_emb_matrix, metric=\"euclidean\")\n",
    "    return squareform(condensed_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4fd2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_matrix_dict = ctk.matrix_dict_applier(COUNT_MATRIX_DICT, cosine_similarity)\n",
    "tfidf_matrix_dict = ctk.matrix_dict_applier(COUNT_MATRIX_DICT, apply_tfidf_transformer)\n",
    "\n",
    "\n",
    "umap_dict_n2 = ctk.matrix_dict_applier(COUNT_MATRIX_DICT, apply_umap_n2) \n",
    "umapdist_matrix_dict_n2 = ctk.matrix_dict_applier(umap_dict_n2, apply_emb_to_dist)\n",
    "\n",
    "umap_dict_n20 = ctk.matrix_dict_applier(COUNT_MATRIX_DICT, apply_umap_n20) \n",
    "umapdist_matrix_dict_n20 = ctk.matrix_dict_applier(umap_dict_n20, apply_emb_to_dist)\n",
    "\n",
    "umap_dict_n40 = ctk.matrix_dict_applier(COUNT_MATRIX_DICT, apply_umap_n40) \n",
    "umapdist_matrix_dict_n40 = ctk.matrix_dict_applier(umap_dict_n40, apply_emb_to_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbc8cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = [\"umap_dist_n2\", \"umap_dist_n20\", \"umap_dist_n40\", \"cosine\", \"tfidf\"]\n",
    "\n",
    "ALL_MATRIX_DATA = {\n",
    "    \"umap_dist_n2\": umapdist_matrix_dict_n2,\n",
    "    \"umap_dist_n20\": umapdist_matrix_dict_n20,\n",
    "    \"umap_dist_n40\": umapdist_matrix_dict_n40,\n",
    "    \"cosine\": cos_matrix_dict,\n",
    "    \"tfidf\": tfidf_matrix_dict,\n",
    "}\n",
    "\n",
    "CUMULATIVE_MATRIX_DATA = {\n",
    "    \"umap_dist_n2\": get_cum_matrix(umapdist_matrix_dict_n2),\n",
    "    \"umap_dist_n20\": get_cum_matrix(umapdist_matrix_dict_n20),\n",
    "    \"umap_dist_n40\": get_cum_matrix(umapdist_matrix_dict_n40),\n",
    "    \"cosine\": get_cum_matrix(cos_matrix_dict),\n",
    "    \"tfidf\": get_cum_matrix(tfidf_matrix_dict),\n",
    "}\n",
    "\n",
    "SORTED_IDX_DATA = {\n",
    "    \"umap_dist_n2\": sorted_idx_dict(CUMULATIVE_MATRIX_DATA[\"umap_dist_n2\"], max_first=False),\n",
    "    \"umap_dist_n20\": sorted_idx_dict(CUMULATIVE_MATRIX_DATA[\"umap_dist_n20\"], max_first=False),\n",
    "    \"umap_dist_n40\": sorted_idx_dict(CUMULATIVE_MATRIX_DATA[\"umap_dist_n40\"], max_first=False),\n",
    "    \"cosine\": sorted_idx_dict(CUMULATIVE_MATRIX_DATA[\"cosine\"], max_first=True),\n",
    "    \"tfidf\": sorted_idx_dict(CUMULATIVE_MATRIX_DATA[\"tfidf\"], max_first=True),\n",
    "}\n",
    "\n",
    "UMAP_EMBEDDINGS = {\n",
    "    \"umap_emb_n2\": umap_dict_n2,\n",
    "    \"umap_emb_n20\": umap_dict_n20,\n",
    "    \"umap_emb_n40\": umap_dict_n40,\n",
    "}\n",
    "\n",
    "MAX_SHOW_RADIUS = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166f77e9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fc0687",
   "metadata": {},
   "source": [
    "### Matrix per radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67804300",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_comparison_heatmaps(ALL_MATRIX_DATA, MAX_SHOW_RADIUS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a128072",
   "metadata": {},
   "source": [
    "### Cumulative matrix per radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0b648f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_comparison_heatmaps(CUMULATIVE_MATRIX_DATA, MAX_SHOW_RADIUS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c14b9b",
   "metadata": {},
   "source": [
    "Interactive Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42cbd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_interactive_heatmaps(CUMULATIVE_MATRIX_DATA, POPULATION_IMGS, MAX_SHOW_RADIUS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de58d18",
   "metadata": {},
   "source": [
    "### Show 2d UMAP embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fe3596",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_interactive_umap_grid(UMAP_EMBEDDINGS, POPULATION_IMGS, MAX_SHOW_RADIUS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884f5caa",
   "metadata": {},
   "source": [
    "### Most Similar Per Radius per metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5eb340",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9624ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'rank {rank}')\n",
    "\n",
    "plot_rows_for_radii(\n",
    "    cumulative_data=CUMULATIVE_MATRIX_DATA,\n",
    "    sorted_data=SORTED_IDX_DATA,\n",
    "    population_images=POPULATION_IMGS,\n",
    "    max_radius=MAX_SHOW_RADIUS,\n",
    "    pair_rank=rank,\n",
    "    labels=LABELS,\n",
    "    main_title=f\"Comparison Rank {np.abs(rank)} (Most Similar)\"  \n",
    ")\n",
    "\n",
    "rank += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a9547a",
   "metadata": {},
   "source": [
    "### Most Similar Per Radius per metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca0c947",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194bfb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'rank {rank}')\n",
    "\n",
    "plot_rows_for_radii(\n",
    "    cumulative_data=CUMULATIVE_MATRIX_DATA,\n",
    "    sorted_data=SORTED_IDX_DATA,\n",
    "    population_images=POPULATION_IMGS,\n",
    "    max_radius=MAX_SHOW_RADIUS,\n",
    "    pair_rank=rank,\n",
    "    labels=LABELS,\n",
    "    main_title=f\"Comparison Rank {np.abs(rank)} (Least Similar)\" \n",
    ")\n",
    "\n",
    "rank -= 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ariel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
