

new thoughts:

- implement more information theory metrics
- information theory gives a way of 'knowing for sure' you get a specific 'diversity' result.

new task: find a way to visualize this from the population to show!!

TLDR: using chemistry and information theory to modify diversity

this toolkit allows:

-> show the effects of how individuals evolve using different 'diversity'/novelty configurations as the only driving force
    - the number of unique parts
    - look nothing like the current population
    - The dominance of the most common part

-> use the static test suite to reveal their own 'diverse' robots throughout their own simulation?


INSIGHT:
-> evolutionary-diversity-driving force != static diversity showcase?

or is it...

the test_suite_visualizer may also showcase based on the different similarity scores?



thought:
-> test-suite can take the X most interesting information theory values
-> plot those values across the simulation together?

-> do i want to plot the mean or do i want to plot the distribution
-> is the matrix even interesting?

-> show robots at the edges and show robots from the center (or the cluster) of what exactly...




THE TEST SUITE:
-> individual robot plotter (may also plot like 10 next to each other)
-> most interesting diversity setting graph-lines-distributions.





TODO:
-> hashVector: add probability distribution (vector)
-> hashVector: add RÃ©nyi entropy alpha (value) to existing value


would be so sick to make this hash-map lower level so it is like using vectors?
so the data array is a vectorozied, but also O(1) lookup with the treehashes


dictionary containing indexes
data is np.array ?



CTK:

rename tfidf to
population_based_diversity


add tfidf laplace smoothing? (i think in the update method)


KL-DIVERGENCE -> float
