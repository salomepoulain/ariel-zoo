{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef8c7f5f",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc54dde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from io import BytesIO\n",
    "from typing import Any\n",
    "\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import umap\n",
    "import umap.plot\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.models import (\n",
    "    BasicTicker,\n",
    "    ColorBar,\n",
    "    ColumnDataSource,\n",
    "    HoverTool,\n",
    "    LinearColorMapper,\n",
    ")\n",
    "from bokeh.plotting import figure, show\n",
    "from matplotlib.colors import to_hex\n",
    "from PIL import Image\n",
    "from rich.console import Console\n",
    "from rich.progress import track\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from ariel_experiments.characterize.canonical.core.toolkit import (\n",
    "    CanonicalToolKit as ctk,\n",
    ")\n",
    "from ariel_experiments.gui_vis.view_mujoco import view\n",
    "from ariel_experiments.utils.initialize import generate_random_individual\n",
    "\n",
    "console = Console()\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207e2a67",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81638bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap_row(\n",
    "    matrices: list[np.ndarray],\n",
    "    titles: list[str] = None,\n",
    "    suptitle: str = None,\n",
    "    figsize_per_plot: tuple[int, int] = (5, 6),\n",
    "    cmap: str = \"viridis\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots a horizontal row of heatmaps with local color scaling.\n",
    "\n",
    "    Args:\n",
    "        matrices: List of matrices to plot\n",
    "        titles: Optional list of titles for each subplot\n",
    "        suptitle: Optional overall figure title\n",
    "        figsize_per_plot: (width, height) for each subplot\n",
    "        cmap: Colormap to use\n",
    "    \"\"\"\n",
    "    num_plots = len(matrices)\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=1,\n",
    "        ncols=num_plots,\n",
    "        figsize=(figsize_per_plot[0] * num_plots, figsize_per_plot[1]),\n",
    "        squeeze=False,\n",
    "    )\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    if suptitle:\n",
    "        fig.suptitle(suptitle, fontsize=16)\n",
    "\n",
    "    for i, matrix in enumerate(matrices):\n",
    "        ax = axes[i]\n",
    "\n",
    "        # Local color scaling for maximum contrast\n",
    "        local_vmin = matrix.min()\n",
    "        local_vmax = matrix.max()\n",
    "\n",
    "        sns.heatmap(\n",
    "            matrix,\n",
    "            ax=ax,\n",
    "            cmap=cmap,\n",
    "            vmin=local_vmin,\n",
    "            vmax=local_vmax,\n",
    "            cbar_ax=None,\n",
    "        )\n",
    "\n",
    "        if titles and i < len(titles):\n",
    "            ax.set_title(titles[i])\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d987789",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparison_heatmaps(\n",
    "    all_matrix_data: dict[str, dict[int, Any]],  # Updated type hint\n",
    "    max_show_radius: int,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots a row of heatmaps for each radius.\n",
    "    Row = Radius\n",
    "    Column = Metric\n",
    "    \"\"\"\n",
    "    # 1. Iterate through radii (Rows of the visual)\n",
    "    for r in range(max_show_radius + 1):\n",
    "        row_matrices = []\n",
    "        row_titles = []\n",
    "\n",
    "        # 2. Iterate through metrics (Columns of the visual)\n",
    "        # CHANGE: We use .items() because input is now a dict, not a list of tuples\n",
    "        for name, matrix_dict in all_matrix_data.items():\n",
    "            # DIRECT ACCESS: Get the specific matrix for this radius\n",
    "            if r in matrix_dict:\n",
    "                matrix = matrix_dict[r]\n",
    "            else:\n",
    "                # Fallback if radius is missing\n",
    "                matrix = np.zeros((1, 1))\n",
    "\n",
    "            row_matrices.append(matrix)\n",
    "            row_titles.append(f\"r:{r} {name}\")\n",
    "\n",
    "        # 3. Plot the specific row\n",
    "        plot_heatmap_row(\n",
    "            matrices=row_matrices,\n",
    "            titles=row_titles,\n",
    "            suptitle=f\"Comparison at Radius {r}\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134e653b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cumsum_dict(matrix_dict):\n",
    "    \"\"\"\n",
    "    Calculates the cumulative sum of matrices keyed by integer radii.\n",
    "    \"\"\"\n",
    "    # 1. Sort the keys to ensure we process 0, then 1, then 2, etc.\n",
    "    sorted_radii = sorted(matrix_dict.keys())\n",
    "\n",
    "    cum_dict = {}\n",
    "    running_sum = None\n",
    "\n",
    "    for r in sorted_radii:\n",
    "        current_matrix = matrix_dict[r]\n",
    "\n",
    "        if running_sum is None:\n",
    "            # First iteration (e.g., radius 0)\n",
    "            # Use .copy() to ensure we don't accidentally modify the input\n",
    "            running_sum = current_matrix.copy()\n",
    "        else:\n",
    "            # Add the current matrix to the accumulated total\n",
    "            running_sum = running_sum + current_matrix\n",
    "\n",
    "        # Store the result in the new dictionary\n",
    "        cum_dict[r] = running_sum\n",
    "\n",
    "    return cum_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8b2fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_sorted_coords_from_matrix(matrix, *, max_first=True):\n",
    "#     \"\"\"\n",
    "#     Returns (row, col) tuples from the upper triangle, sorted by value.\n",
    "#     \"\"\"\n",
    "#     rows, cols = np.triu_indices_from(matrix, k=1)\n",
    "#     values = matrix[rows, cols]\n",
    "#     sort_idx = np.argsort(values)\n",
    "#     if max_first:\n",
    "#         sort_idx = sort_idx[::-1]\n",
    "#     return list(zip(rows[sort_idx], cols[sort_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8628485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sorted_idx_dict(matrix_dict, *, max_first=True):\n",
    "#     \"\"\"Return {radius: sorted_coord_list} by applying get_sorted_coords_from_matrix to each matrix.\"\"\"\n",
    "#     return {\n",
    "#         r: get_sorted_coords_from_matrix(mat, max_first=max_first)\n",
    "#         for r, mat in matrix_dict.items()\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22db6cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorted_idx_dict(data_dict, *, max_first=True):\n",
    "    \"\"\"Return {key: sorted_coords} by applying get_sorted_coords to each item.\"\"\"\n",
    "    return {\n",
    "        k: get_sorted_coords(data, max_first=max_first)\n",
    "        for k, data in data_dict.items()\n",
    "    }\n",
    "\n",
    "def get_sorted_coords(data, *, max_first=True):\n",
    "    \"\"\"\n",
    "    If data is 2D: Returns (row, col) tuples from upper triangle, sorted by value.\n",
    "    If data is 1D: Returns a list of indices, sorted by value.\n",
    "    \"\"\"\n",
    "    # 1. Handle 1D Array\n",
    "    if data.ndim == 1:\n",
    "        sort_idx = np.argsort(data)\n",
    "        if max_first:\n",
    "            sort_idx = sort_idx[::-1]\n",
    "        return sort_idx.tolist() # Returns [5, 2, 9, ...]\n",
    "\n",
    "    # 2. Handle 2D Matrix\n",
    "    elif data.ndim == 2:\n",
    "        rows, cols = np.triu_indices_from(data, k=1)\n",
    "        values = data[rows, cols]\n",
    "        sort_idx = np.argsort(values)\n",
    "        if max_first:\n",
    "            sort_idx = sort_idx[::-1]\n",
    "        return list(zip(rows[sort_idx], cols[sort_idx])) # Returns [(0,1), (3,4), ...]\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Data must be 1D array or 2D matrix.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5270f4f0",
   "metadata": {},
   "source": [
    "images and interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37cf6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embeddable_image(data, scale=1.0):\n",
    "    \"\"\"\n",
    "    Simplified version: Accepts HxWx4 (RGBA) or HxWx3 (RGB).\n",
    "    Returns PNG data-url with aspect ratio AND relative scale preserved.\n",
    "    \"\"\"\n",
    "    arr = np.asarray(data)\n",
    "    \n",
    "    # Normalize types\n",
    "    if np.issubdtype(arr.dtype, np.floating):\n",
    "        if arr.max() <= 1.0:\n",
    "            arr = (arr * 255).astype(np.uint8)\n",
    "        else:\n",
    "            arr = arr.astype(np.uint8)\n",
    "    else:\n",
    "        arr = arr.astype(np.uint8)\n",
    "\n",
    "    # Detect Mode\n",
    "    if arr.ndim == 3:\n",
    "        mode = 'RGBA' if arr.shape[2] == 4 else 'RGB'\n",
    "    else:\n",
    "        mode = 'L' # Grayscale\n",
    "\n",
    "    # Create Image\n",
    "    img = Image.fromarray(arr, mode=mode)\n",
    "    \n",
    "    # Resize by a constant factor to preserve relative size differences\n",
    "    if scale != 1.0:\n",
    "        new_size = (int(img.width * scale), int(img.height * scale))\n",
    "        img = img.resize(new_size, Image.Resampling.BICUBIC)\n",
    "\n",
    "    buffer = BytesIO()\n",
    "    img.save(buffer, format='PNG', optimize=False, compress_level=1)\n",
    "    return 'data:image/png;base64,' + base64.b64encode(buffer.getvalue()).decode()\n",
    "\n",
    "def robot_image(i, scale=1.0):\n",
    "    \"\"\"\n",
    "    Generates the image for robot i using the global POPULATION and view function.\n",
    "    \"\"\"\n",
    "    graph = POPULATION[i].to_graph()  \n",
    "    # Using remove_background=True for transparent PNGs\n",
    "    img_arr = np.array(view(graph, return_img=True, tilted=True, remove_background=True))\n",
    "    \n",
    "    # SCALE 1.0: High Quality for Matplotlib.\n",
    "    return embeddable_image(img_arr, scale=1.0)\n",
    "\n",
    "def get_population_images(population_size, scale=1.0):\n",
    "    \"\"\"\n",
    "    Pre-generates all images for the population to avoid re-rendering.\n",
    "    \"\"\"\n",
    "    return [robot_image(i, scale=scale) for i in track(range(population_size), description=f\"Generating {population_size} images...\")]\n",
    "\n",
    "def decode_base64_image(data_url):\n",
    "    \"\"\"Helper to convert base64 string back to numpy array.\"\"\"\n",
    "    header, encoded = data_url.split(\",\", 1)\n",
    "    data = base64.b64decode(encoded)\n",
    "    return np.array(Image.open(BytesIO(data)))\n",
    "\n",
    "def create_thumbnails(image_list, scale=0.5):\n",
    "    \"\"\"\n",
    "    Takes a list of base64 images (HQ) and creates a new list of scaled-down \n",
    "    thumbnails (preserving relative aspect ratio) for use in web tooltips.\n",
    "    \"\"\"\n",
    "    thumbnails = []\n",
    "    for b64_str in image_list:\n",
    "        # Decode\n",
    "        header, encoded = b64_str.split(\",\", 1)\n",
    "        data = base64.b64decode(encoded)\n",
    "        img = Image.open(BytesIO(data))\n",
    "        \n",
    "        # Resize\n",
    "        new_size = (int(img.width * scale), int(img.height * scale))\n",
    "        img_small = img.resize(new_size, Image.Resampling.BICUBIC)\n",
    "        \n",
    "        # Re-encode\n",
    "        buffer = BytesIO()\n",
    "        img_small.save(buffer, format='PNG')\n",
    "        thumb_str = 'data:image/png;base64,' + base64.b64encode(buffer.getvalue()).decode()\n",
    "        thumbnails.append(thumb_str)\n",
    "    return thumbnails\n",
    "\n",
    "\n",
    "def matrix_to_heatmap_source(matrix, images, metric_name, radius):\n",
    "    \"\"\"Converts matrix to Bokeh DataSource.\"\"\"\n",
    "    N = matrix.shape[0]\n",
    "    x_indices, y_indices = np.meshgrid(np.arange(N), np.arange(N))\n",
    "    x_flat = x_indices.flatten()\n",
    "    y_flat = N - 1 - y_indices.flatten() \n",
    "    values = matrix.flatten()\n",
    "    imgs_i = [images[r] for r in y_indices.flatten()]\n",
    "    imgs_j = [images[c] for c in x_indices.flatten()]\n",
    "    ids_i = [str(r) for r in y_indices.flatten()]\n",
    "    ids_j = [str(c) for c in x_indices.flatten()]\n",
    "    data = {\n",
    "        'x': x_flat, 'y': y_flat, 'value': values,\n",
    "        'img_row': imgs_i, 'img_col': imgs_j,\n",
    "        'id_row': ids_i, 'id_col': ids_j,\n",
    "        'metric': [metric_name] * len(values),\n",
    "        'radius': [radius] * len(values)\n",
    "    }\n",
    "    return ColumnDataSource(data)\n",
    "\n",
    "def plot_interactive_heatmaps(all_matrix_data: dict, population_images: list, max_show_radius: int, plot_width=None, plot_height=None, palette=\"Reds256\", thumbnail_scale=0.5):\n",
    "    \"\"\"\n",
    "    Creates a Grid of Interactive Heatmaps using Bokeh.\n",
    "    Args:\n",
    "        thumbnail_scale: Factor to scale images down for the tooltip (default 0.5)\n",
    "    \"\"\"\n",
    "    # Create thumbnails specifically for this plot (leaves original list untouched)\n",
    "    thumb_images = create_thumbnails(population_images, scale=thumbnail_scale)\n",
    "\n",
    "    num_cols = len(all_matrix_data)\n",
    "    if plot_width is None: plot_width = 650 if num_cols == 1 else 200\n",
    "    if plot_height is None: plot_height = 600 if num_cols == 1 else 200\n",
    "\n",
    "    grid_layout = []\n",
    "    for r in range(max_show_radius + 1):\n",
    "        row_plots = []\n",
    "        for name, matrix_dict in all_matrix_data.items():\n",
    "            if r in matrix_dict: matrix = matrix_dict[r]\n",
    "            else: matrix = np.zeros((1, 1))\n",
    "            \n",
    "            # Use thumbnails here\n",
    "            source = matrix_to_heatmap_source(matrix, thumb_images, name, r)\n",
    "            vmin, vmax = matrix.min(), matrix.max()\n",
    "            mapper = LinearColorMapper(palette=palette, low=vmin, high=vmax)\n",
    "            \n",
    "            p = figure(title=f\"r:{r} {name}\", x_range=(-0.5, matrix.shape[1]-0.5), y_range=(-0.5, matrix.shape[0]-0.5), width=plot_width, height=plot_height, tools=\"hover,save,reset\", toolbar_location=\"above\")\n",
    "            p.axis.visible = False; p.grid.visible = False\n",
    "            p.rect(x='x', y='y', width=1, height=1, source=source, fill_color={'field': 'value', 'transform': mapper}, line_color=None)\n",
    "            color_bar = ColorBar(color_mapper=mapper, ticker=BasicTicker(), label_standoff=8, border_line_color=None, location=(0,0), width=8)\n",
    "            p.add_layout(color_bar, 'right')\n",
    "            \n",
    "            hover = p.select(dict(type=HoverTool))\n",
    "            # No CSS max-width constraints. We rely on the thumbnail being physically smaller (0.5x)\n",
    "            # but proportional.\n",
    "            hover.tooltips = \"\"\"\n",
    "            <div style=\"display: flex; flex-direction: column; align-items: center; background: white; padding: 5px;\">\n",
    "                <div style=\"font-weight: bold; margin-bottom: 5px;\">@metric (r=@radius) Val: @value{0.000}</div>\n",
    "                <div style=\"display: flex; flex-direction: row; gap: 10px;\">\n",
    "                    <div style=\"text-align: center;\"><span style=\"font-size: 10px;\">Row: @id_row</span><br><img src=\"@img_row\" style=\"width: auto; height: auto;\"></div>\n",
    "                    <div style=\"text-align: center;\"><span style=\"font-size: 10px;\">Col: @id_col</span><br><img src=\"@img_col\" style=\"width: auto; height: auto;\"></div>\n",
    "                </div>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "            row_plots.append(p)\n",
    "        grid_layout.append(row_plots)\n",
    "    show(gridplot(grid_layout))\n",
    "\n",
    "def plot_interactive_umap_grid(umap_data: dict, population_images: list, max_show_radius: int, follow_idx_list: list[int] | None= None, plot_width=None, plot_height=200, thumbnail_scale=0.5):\n",
    "    \"\"\"\n",
    "    Creates a Grid of Interactive UMAP Scatter plots.\n",
    "    Args:\n",
    "        thumbnail_scale: Factor to scale images down for the tooltip (default 0.5)\n",
    "    \"\"\"\n",
    "    # Create thumbnails specifically for this plot\n",
    "    thumb_images = create_thumbnails(population_images, scale=thumbnail_scale)\n",
    "\n",
    "    num_cols = len(umap_data)\n",
    "    if plot_width is None: plot_width = 700 if num_cols == 1 else 200\n",
    "    n = len(population_images)\n",
    "    \n",
    "    sizes = [4] * n\n",
    "    rgba_colors = plt.cm.rainbow(np.linspace(0, 1, n))\n",
    "\n",
    "    line_colors = [None] * n\n",
    "    if follow_idx_list:\n",
    "        follow_set = set(follow_idx_list)\n",
    "        sizes = [8 if i in follow_set else 3 for i in range(n)]\n",
    "        line_colors = ['black' if i in follow_set else None for i in range(n)]\n",
    "        \n",
    "        for i in range(n):\n",
    "            if i not in follow_set:\n",
    "                rgba_colors[i] = [0.0, 0.0, 0.0, 0.3]\n",
    "        \n",
    "        \n",
    "    hex_colors = [to_hex(c, keep_alpha=True) for c in rgba_colors]\n",
    "    \n",
    "    \n",
    "    grid_layout = []\n",
    "    for r in range(max_show_radius + 1):\n",
    "        row_plots = []\n",
    "        for name, matrix_dict in umap_data.items():\n",
    "            if r in matrix_dict:\n",
    "                emb = matrix_dict[r]\n",
    "                if emb.ndim != 2 or emb.shape[1] != 2:\n",
    "                    p = figure(title=f\"r:{r} {name} (No Data)\", width=plot_width, height=plot_height); row_plots.append(p); continue\n",
    "            else:\n",
    "                p = figure(title=f\"r:{r} {name} (Missing)\", width=plot_width, height=plot_height); row_plots.append(p); continue\n",
    "\n",
    "            # Use thumb_images here\n",
    "            robots_df = pd.DataFrame({\"x\": emb[:, 0], \"y\": emb[:, 1], \"digit\": [str(i) for i in range(n)], \"image\": thumb_images, \"color\": hex_colors, \"size\": sizes, 'line_color': line_colors})\n",
    "            \n",
    "            if follow_idx_list:\n",
    "                robots_df['sort_order'] = [1 if i in set(follow_idx_list) else 0 for i in range(n)]\n",
    "                robots_df = robots_df.sort_values('sort_order', ascending=True)\n",
    "            source = ColumnDataSource(robots_df)\n",
    "            p = figure(title=f\"r:{r} {name}\", width=plot_width, height=plot_height, tools=\"pan,wheel_zoom,reset,save\", toolbar_location=\"above\")\n",
    "            # p.scatter('x', 'y', source=source, color='color', line_alpha=1, line_color='white', line_width=2, size='size')\n",
    "            p.scatter('x', 'y', source=source, color='color', line_alpha=1, line_color='line_color', line_width=1, size='size')\n",
    "\n",
    "        \n",
    "            hover = HoverTool(tooltips=\"\"\"<div><img src='@image' style='float:left; margin:5px; width:auto; height:auto;'/></div><div style=\"font-size:12px; font-weight: bold;\"><span style='color:#224499'>ID: @digit</span></div>\"\"\")\n",
    "            p.add_tools(hover)\n",
    "            row_plots.append(p)\n",
    "        grid_layout.append(row_plots)\n",
    "    show(gridplot(grid_layout))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b751a9d9",
   "metadata": {},
   "source": [
    "for overview plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4c1cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _stitch_images_horizontally(images, target_height=None, gap_px=20):\n",
    "    \"\"\"\n",
    "    Stitches images horizontally with white background (handles transparency).\n",
    "    If target_height is provided, pads all images vertically to match that height (alignment: top).\n",
    "    \"\"\"\n",
    "    if not images or all(img is None for img in images):\n",
    "        return None, 0, 0\n",
    "    \n",
    "    valid_images = [img for img in images if img is not None]\n",
    "    if not valid_images: return None, 0, 0\n",
    "\n",
    "    # 1. Normalize Types to uint8 RGB and composite transparent images onto white\n",
    "    normalized_imgs = []\n",
    "    for img in valid_images:\n",
    "        # Handle float 0-1\n",
    "        if np.issubdtype(img.dtype, np.floating):\n",
    "            img = (np.clip(img, 0, 1) * 255).astype(np.uint8)\n",
    "        else:\n",
    "            img = img.astype(np.uint8)\n",
    "        \n",
    "        # Handle Alpha channel - composite onto white background\n",
    "        if len(img.shape) == 3 and img.shape[2] == 4:\n",
    "            # Extract RGB and Alpha\n",
    "            rgb = img[:, :, :3]\n",
    "            alpha = img[:, :, 3:4] / 255.0  # Normalize alpha to 0-1\n",
    "            \n",
    "            # Create white background\n",
    "            white_bg = np.full_like(rgb, 255, dtype=np.uint8)\n",
    "            \n",
    "            # Composite: result = foreground * alpha + background * (1 - alpha)\n",
    "            img = (rgb * alpha + white_bg * (1 - alpha)).astype(np.uint8)\n",
    "        elif len(img.shape) == 3 and img.shape[2] >= 3:\n",
    "            img = img[:, :, :3]\n",
    "            \n",
    "        normalized_imgs.append(img)\n",
    "\n",
    "    # 2. Determine Canvas Height\n",
    "    current_max_h = max(img.shape[0] for img in normalized_imgs)\n",
    "    final_h = target_height if target_height and target_height > current_max_h else current_max_h\n",
    "\n",
    "    # 3. Create White Gap Column\n",
    "    white_gap_col = np.full((final_h, gap_px, 3), 255, dtype=np.uint8)\n",
    "\n",
    "    # 4. Stitching Loop\n",
    "    stitched = None\n",
    "    \n",
    "    for i, img in enumerate(normalized_imgs):\n",
    "        h, w = img.shape[:2]\n",
    "        \n",
    "        # Pad image to final_h (fill bottom with white)\n",
    "        if h < final_h:\n",
    "            pad = np.full((final_h - h, w, 3), 255, dtype=np.uint8)\n",
    "            img = np.vstack((img, pad))\n",
    "            \n",
    "        if stitched is None:\n",
    "            stitched = img\n",
    "        else:\n",
    "            stitched = np.hstack((stitched, white_gap_col, img))\n",
    "            \n",
    "    return stitched, stitched.shape[1], final_h\n",
    "\n",
    "def view_grid_of_groups(rows_of_tuples, rows_of_titles=None, col_headers=None, main_title=None):\n",
    "    \"\"\"\n",
    "    Plots a grid of groups where ALL images are scaled equally (no auto-zoom).\n",
    "    \"\"\"\n",
    "    if not rows_of_tuples: return\n",
    "\n",
    "    n_rows = len(rows_of_tuples)\n",
    "    n_cols = len(rows_of_tuples[0])\n",
    "    ROBOT_GAP_PX = 20\n",
    "    \n",
    "    # --- PASS 1: Calculate Global Max Dimensions and Process Images ---\n",
    "    global_max_h = 0\n",
    "    global_max_w = 0\n",
    "    \n",
    "    grid_data = [[None for _ in range(n_cols)] for _ in range(n_rows)]\n",
    "    \n",
    "    for r in range(n_rows):\n",
    "        for c in range(n_cols):\n",
    "            group_base64_strings = rows_of_tuples[r][c]\n",
    "            images = [decode_base64_image(s) for s in group_base64_strings]\n",
    "            \n",
    "            # Find max height in this specific group to update global max\n",
    "            for img in images:\n",
    "                if img is not None:\n",
    "                    if img.shape[0] > global_max_h: global_max_h = img.shape[0]\n",
    "            \n",
    "            grid_data[r][c] = images\n",
    "\n",
    "    # --- PASS 2: Stitch and Measure Widths ---\n",
    "    processed_images = []\n",
    "    \n",
    "    for r in range(n_rows):\n",
    "        row_imgs = []\n",
    "        for c in range(n_cols):\n",
    "            images = grid_data[r][c]\n",
    "            # Stitch using GLOBAL height (pads bottom with white)\n",
    "            stitched, w, h = _stitch_images_horizontally(images, target_height=global_max_h, gap_px=ROBOT_GAP_PX)\n",
    "            \n",
    "            if w > global_max_w: global_max_w = w\n",
    "            row_imgs.append(stitched)\n",
    "        processed_images.append(row_imgs)\n",
    "\n",
    "    # --- PASS 3: Plot with Fixed Limits ---\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, \n",
    "                             figsize=(4 * n_cols, 2.5 * n_rows), \n",
    "                             squeeze=False,\n",
    "                             facecolor='white')\n",
    "    \n",
    "    if main_title:\n",
    "        fig.suptitle(main_title, fontsize=16, weight=\"bold\", y=0.98, color='black')\n",
    "\n",
    "    for r in range(n_rows):\n",
    "        for c in range(n_cols):\n",
    "            ax = axes[r, c]\n",
    "            ax.set_facecolor('white')\n",
    "            \n",
    "            img_data = processed_images[r][c]\n",
    "            \n",
    "            if img_data is not None:\n",
    "                ax.imshow(img_data)\n",
    "            \n",
    "            # Force Equal Scaling\n",
    "            ax.set_xlim(0, global_max_w)\n",
    "            ax.set_ylim(global_max_h, 0)\n",
    "            ax.set_aspect('equal')\n",
    "            ax.axis('off')\n",
    "\n",
    "            # Titles and Headers\n",
    "            if rows_of_titles and r < len(rows_of_titles):\n",
    "                ax.set_title(rows_of_titles[r][c], fontsize=10, color='black', pad=0)\n",
    "\n",
    "            if r == 0 and col_headers and c < len(col_headers):\n",
    "                ax.text(0.5, 1, col_headers[c], transform=ax.transAxes, \n",
    "                        ha=\"center\", va=\"bottom\", fontsize=12, weight=\"bold\", color=\"#224499\")\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0.25, top=0.95, bottom=0.02)\n",
    "    plt.show()\n",
    "\n",
    "# def plot_rows_for_radii(cumulative_data, sorted_data, population_images, max_radius: int, pair_rank: int = 0, labels: list[str] = None, main_title: str = None):\n",
    "#     if labels is None: labels = list(cumulative_data.keys())\n",
    "#     all_rows_robots = []\n",
    "#     all_rows_titles = []\n",
    "    \n",
    "#     for r in range(max_radius + 1):\n",
    "#         robots_row = []\n",
    "#         titles_row = []\n",
    "#         for name in labels:\n",
    "#             coords_list = sorted_data[name].get(r, [])\n",
    "#             matrix = cumulative_data[name].get(r)\n",
    "#             if coords_list and pair_rank < len(coords_list):\n",
    "#                 i, j = coords_list[pair_rank]\n",
    "#             else:\n",
    "#                 i, j = (0, 0)\n",
    "#             idx_i, idx_j = int(i), int(j)\n",
    "#             val = matrix[idx_i, idx_j] if matrix is not None else 0.0\n",
    "            \n",
    "#             robots_row.append([population_images[idx_i], population_images[idx_j]])\n",
    "#             titles_row.append(f\"{name}\\nr:{r} <{idx_i},{idx_j}> val={val:.3f}\")\n",
    "            \n",
    "#         all_rows_robots.append(robots_row)\n",
    "#         all_rows_titles.append(titles_row)\n",
    "\n",
    "#     view_grid_of_groups(all_rows_robots, all_rows_titles, col_headers=None, main_title=main_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdcf8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rows_for_radii(cumulative_data, sorted_data, population_images, max_radius: int, \n",
    "                        pair_rank: int = 0, plot_up_to: bool = False, \n",
    "                        labels: list[str] = None, main_title: str = None):\n",
    "    \n",
    "    if labels is None: labels = list(cumulative_data.keys())\n",
    "    \n",
    "    all_rows_robots = []\n",
    "    all_rows_titles = []\n",
    "    \n",
    "    for r in range(max_radius + 1):\n",
    "        robots_row = []\n",
    "        titles_row = []\n",
    "        \n",
    "        for name in labels:\n",
    "            # 1. Get the list of coordinates/indices for this metric & radius\n",
    "            coords_list = sorted_data[name].get(r, [])\n",
    "            n_items = len(coords_list)\n",
    "            \n",
    "            # 2. Determine which items to plot\n",
    "            if n_items == 0:\n",
    "                items_to_process = []\n",
    "            else:\n",
    "                # --- LOGIC UPDATE FOR NEGATIVE RANKS ---\n",
    "                if plot_up_to:\n",
    "                    if pair_rank >= 0:\n",
    "                        # Positive: Take from start up to rank (Top N)\n",
    "                        # e.g. rank=2 -> indices [0, 1, 2]\n",
    "                        end_idx = min(pair_rank + 1, n_items)\n",
    "                        items_to_process = coords_list[:end_idx]\n",
    "                    else:\n",
    "                        # Negative: Take from rank to end (Bottom N)\n",
    "                        # e.g. rank=-2 -> indices [-2, -1]\n",
    "                        # Ensure we don't go out of bounds (e.g. -99 vs len 10)\n",
    "                        start_idx = max(-n_items, pair_rank)\n",
    "                        items_to_process = coords_list[start_idx:]\n",
    "                else:\n",
    "                    # Single Item Mode\n",
    "                    # Python handles negative indexing (list[-1]), \n",
    "                    # but we must check bounds to prevent IndexError if rank is too large/small\n",
    "                    if -n_items <= pair_rank < n_items:\n",
    "                        items_to_process = [coords_list[pair_rank]]\n",
    "                    else:\n",
    "                        items_to_process = []\n",
    "\n",
    "            # 3. Process the selected items (Stitch them all into one group)\n",
    "            group_images = []\n",
    "            title_parts = []\n",
    "            \n",
    "            matrix = cumulative_data[name].get(r)\n",
    "            \n",
    "            for k, item in enumerate(items_to_process):\n",
    "                # LOGIC BRANCH: Is it a Tuple (Pair) or Scalar (Single)?\n",
    "                \n",
    "                # Case A: It's a Tuple/List/Array (e.g., (10, 42))\n",
    "                if isinstance(item, (list, tuple, np.ndarray)) and len(item) == 2:\n",
    "                    idx_i, idx_j = int(item[0]), int(item[1])\n",
    "                    \n",
    "                    # Fetch value from matrix if available\n",
    "                    val = 0.0\n",
    "                    if matrix is not None:\n",
    "                        try:\n",
    "                            val = matrix[idx_i, idx_j]\n",
    "                        except IndexError:\n",
    "                            pass\n",
    "\n",
    "                    group_images.extend([population_images[idx_i], population_images[idx_j]])\n",
    "                    \n",
    "                    # Add a separator pipe '|' if this isn't the first item\n",
    "                    sep = \" | \" if k > 0 else \"\"\n",
    "                    title_parts.append(f\"{sep}<{idx_i},{idx_j}>={val:.2f}\")\n",
    "\n",
    "                # Case B: It's a Scalar/Integer (e.g., 10)\n",
    "                else:\n",
    "                    # Handle if it came as a single-element array or plain int\n",
    "                    idx = int(item) if np.isscalar(item) else int(item[0])\n",
    "                    \n",
    "                    # Fetch value (Fitness) from array if available\n",
    "                    val = 0.0\n",
    "                    if matrix is not None:\n",
    "                         try:\n",
    "                            # If matrix is 1D array\n",
    "                            if matrix.ndim == 1:\n",
    "                                val = matrix[idx]\n",
    "                            # If matrix is 2D but we have 1 index, maybe diagonal?\n",
    "                            elif matrix.ndim == 2:\n",
    "                                val = matrix[idx, idx] \n",
    "                         except IndexError:\n",
    "                            pass\n",
    "\n",
    "                    group_images.append(population_images[idx])\n",
    "                    \n",
    "                    sep = \" | \" if k > 0 else \"\"\n",
    "                    title_parts.append(f\"{sep}#{idx}={val:.2f}\")\n",
    "\n",
    "            # 4. Finalize Row\n",
    "            robots_row.append(group_images)\n",
    "            \n",
    "            # Construct title (limit length if plot_up_to included many items)\n",
    "            full_title_str = \"\".join(title_parts)\n",
    "            if len(full_title_str) > 50: \n",
    "                full_title_str = full_title_str[:47] + \"...\"\n",
    "            \n",
    "            titles_row.append(f\"{name} (r:{r})\\n{full_title_str}\")\n",
    "            \n",
    "        all_rows_robots.append(robots_row)\n",
    "        all_rows_titles.append(titles_row)\n",
    "\n",
    "    view_grid_of_groups(all_rows_robots, all_rows_titles, col_headers=None, main_title=main_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771570a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histograms(data_dict, max_radius=2, bins=100, size_per_plot=4):\n",
    "    \"\"\"\n",
    "    Plots a grid of histograms with dynamic figure sizing to keep plots square.\n",
    "    \n",
    "    Parameters:\n",
    "    - data_dict: Dictionary containing the data (matrices or arrays).\n",
    "    - max_radius: The maximum radius index to plot (rows).\n",
    "    - bins: Number of histogram bins.\n",
    "    - size_per_plot: Width/Height in inches for each individual subplot.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Setup the grid dimensions\n",
    "    metric_keys = list(data_dict.keys())\n",
    "    n_cols = len(metric_keys)\n",
    "    n_rows = max_radius + 1 \n",
    "    \n",
    "    # 2. Dynamic Figure Size Calculation\n",
    "    # We multiply the number of cols/rows by the desired size per plot\n",
    "    dynamic_figsize = (n_cols * size_per_plot, n_rows * size_per_plot)\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=dynamic_figsize, constrained_layout=True)\n",
    "    \n",
    "    # Ensure axes is always 2D array even if 1 row or 1 col\n",
    "    if n_rows == 1 and n_cols == 1:\n",
    "        axes = np.array([[axes]])\n",
    "    elif n_rows == 1: \n",
    "        axes = axes[np.newaxis, :]\n",
    "    elif n_cols == 1: \n",
    "        axes = axes[:, np.newaxis]\n",
    "\n",
    "    # 3. Iterate through Metrics (Columns)\n",
    "    for col_idx, metric_name in enumerate(metric_keys):\n",
    "        \n",
    "        # Get the sub-dictionary for this metric\n",
    "        radius_dict = data_dict[metric_name]\n",
    "        \n",
    "        # 4. Iterate through Radii (Rows)\n",
    "        for r in range(n_rows):\n",
    "            ax = axes[r, col_idx]\n",
    "            \n",
    "            # Safety check: does this radius exist?\n",
    "            if r not in radius_dict:\n",
    "                ax.axis('off')\n",
    "                continue\n",
    "                \n",
    "            raw_data = radius_dict[r]\n",
    "            \n",
    "            # --- DATA PREPROCESSING ---\n",
    "            # If 2D Matrix: Flatten Upper Triangle only (k=1 excludes diagonal)\n",
    "            if raw_data.ndim == 2:\n",
    "                vals = raw_data[np.triu_indices_from(raw_data, k=1)]\n",
    "            # If 1D Array: Use as is\n",
    "            else:\n",
    "                vals = raw_data.flatten()\n",
    "            \n",
    "            # --- PLOTTING ---\n",
    "            sns.histplot(vals, bins=bins, kde=True, ax=ax, \n",
    "                         color=f\"C{col_idx}\", edgecolor='w', linewidth=0.5)\n",
    "            \n",
    "            # --- STATS ANNOTATION ---\n",
    "            if len(vals) > 0:\n",
    "                stats_text = (f\"$\\mu$: {np.mean(vals):.2f}\\n\"\n",
    "                              f\"Min: {np.min(vals):.2f}\\n\"\n",
    "                              f\"Max: {np.max(vals):.2f}\")\n",
    "                \n",
    "                ax.text(0.95, 0.95, stats_text, transform=ax.transAxes, \n",
    "                        fontsize=10, verticalalignment='top', horizontalalignment='right',\n",
    "                        bbox=dict(boxstyle='round', facecolor='white', alpha=0.9))\n",
    "\n",
    "            # --- LABELS & TITLES ---\n",
    "            # Title only on top row\n",
    "            if r == 0:\n",
    "                ax.set_title(metric_name, fontsize=14, fontweight='bold', pad=15)\n",
    "            \n",
    "            # Y Label only on first column\n",
    "            if col_idx == 0:\n",
    "                ax.set_ylabel(f\"Radius {r}\\nCount\", fontsize=12, fontweight='bold')\n",
    "            else:\n",
    "                ax.set_ylabel(\"\")\n",
    "            \n",
    "            # X Label only on bottom row\n",
    "            if r == n_rows - 1:\n",
    "                ax.set_xlabel(\"Value\", fontsize=11)\n",
    "            else:\n",
    "                ax.set_xlabel(\"\")\n",
    "\n",
    "    fig.suptitle(f\"Distribution of Values per Radius (0 to {max_radius})\", fontsize=18, y=1.02, fontweight='bold')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5773e6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091b7bc7",
   "metadata": {},
   "source": [
    "### GLOBAL ANALYSIS SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d15609",
   "metadata": {},
   "outputs": [],
   "source": [
    "POPULATION_SIZE = 500\n",
    "NUM_OF_MODULES = 20\n",
    "\n",
    "MAX_RADIUS = None\n",
    "\n",
    "CONFIG = ctk.SimilarityConfig(\n",
    "    max_tree_radius=MAX_RADIUS, radius_strategy=ctk.RadiusStrategy.NODE_LOCAL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baab38b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "POPULATION = [\n",
    "    ctk.from_graph(generate_random_individual(NUM_OF_MODULES))\n",
    "    for _ in range(POPULATION_SIZE)\n",
    "]\n",
    "\n",
    "SUBTREES = [\n",
    "    ctk.collect_tree_hash_config_mode(individual, config=CONFIG)\n",
    "    for individual in POPULATION\n",
    "]\n",
    "\n",
    "COUNT_MATRIX_DICT = ctk.get_count_matrix(SUBTREES, CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06d9b30",
   "metadata": {},
   "source": [
    "most time consuming step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6183f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "POPULATION_IMGS = get_population_images(POPULATION_SIZE, scale=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab85a86",
   "metadata": {},
   "source": [
    "#### Matrix Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e904a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_tfidf_transformer(count_matrix):\n",
    "    transformer = TfidfTransformer()\n",
    "    return transformer.fit_transform(count_matrix)\n",
    "\n",
    "def apply_umap_n2(count_matrix):\n",
    "    return umap.UMAP(init='random', random_state=42, transform_seed=42,n_jobs=1, metric=\"cosine\", n_neighbors=2).fit_transform(\n",
    "        count_matrix\n",
    "    )\n",
    "  \n",
    "def apply_umap_n10(count_matrix):\n",
    "    return umap.UMAP(init='random', random_state=42, transform_seed=42,n_jobs=1, metric=\"cosine\", n_neighbors=10).fit_transform(\n",
    "        count_matrix\n",
    "    )\n",
    "    \n",
    "def apply_umap_n20(count_matrix):\n",
    "    return umap.UMAP(init='random', random_state=42, transform_seed=42,n_jobs=1, metric=\"cosine\", n_neighbors=20).fit_transform(\n",
    "        count_matrix\n",
    "    )\n",
    "\n",
    "def apply_emb_to_dist(umap_emb_matrix):\n",
    "    condensed_distances = pdist(umap_emb_matrix, metric=\"euclidean\")\n",
    "    return squareform(condensed_distances)\n",
    "\n",
    "def apply_collapse_to_fitness(matrix):\n",
    "    return matrix.sum(axis=1) - matrix.diagonal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4fd2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basis ---\n",
    "count_cos_matrix_dict = ctk.matrix_dict_applier(COUNT_MATRIX_DICT, cosine_similarity)\n",
    "\n",
    "tfidf_matrix_dict = ctk.matrix_dict_applier(COUNT_MATRIX_DICT, apply_tfidf_transformer)\n",
    "tfidf_cos_matrix_dict = ctk.matrix_dict_applier(tfidf_matrix_dict, cosine_similarity)\n",
    "\n",
    "\n",
    "# umap ---\n",
    "umap_dict_n2 = ctk.matrix_dict_applier(COUNT_MATRIX_DICT, apply_umap_n2) \n",
    "umapdist_matrix_dict_n2 = ctk.matrix_dict_applier(umap_dict_n2, apply_emb_to_dist)\n",
    "\n",
    "# tfidf\n",
    "tfidf_umap_dict_n2 = ctk.matrix_dict_applier(tfidf_matrix_dict, apply_umap_n2) \n",
    "tfidf_umapdist_matrix_dict_n2 = ctk.matrix_dict_applier(tfidf_umap_dict_n2, apply_emb_to_dist)\n",
    "\n",
    "umap_dict_n10 = ctk.matrix_dict_applier(COUNT_MATRIX_DICT, apply_umap_n10) \n",
    "umapdist_matrix_dict_n10 = ctk.matrix_dict_applier(umap_dict_n10, apply_emb_to_dist)\n",
    "\n",
    "# tfidf\n",
    "tfidf_umap_dict_n10 = ctk.matrix_dict_applier(tfidf_matrix_dict, apply_umap_n10) \n",
    "tfidf_umapdist_matrix_dict_n10 = ctk.matrix_dict_applier(tfidf_umap_dict_n10, apply_emb_to_dist)\n",
    "\n",
    "umap_dict_n20 = ctk.matrix_dict_applier(COUNT_MATRIX_DICT, apply_umap_n20) \n",
    "umapdist_matrix_dict_n20 = ctk.matrix_dict_applier(umap_dict_n20, apply_emb_to_dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5db0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dimension reduction visualization\n",
    "UMAP_EMBEDDINGS = {\n",
    "    \"umap_emb_n2\": umap_dict_n2,\n",
    "    \"tfidf_umap_emb_n2\": tfidf_umap_dict_n2,\n",
    "    \n",
    "    \"umap_emb_n10\": umap_dict_n10,\n",
    "    \"tfidf_umap_emb_n10\": tfidf_umap_dict_n10,\n",
    "    \n",
    "    \"umap_emb_n20\": umap_dict_n20,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2f138a",
   "metadata": {},
   "source": [
    "#### Matrix-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbc8cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics applied per unique radius\n",
    "ALL_MATRIX_DATA = {\n",
    "    \"umap_dist_n2\": umapdist_matrix_dict_n2,\n",
    "    \"tfidf_umap_dist_n2\" : tfidf_umapdist_matrix_dict_n2,\n",
    "    \n",
    "    \"umap_dist_n10\": umapdist_matrix_dict_n10,\n",
    "    \"tfidf_umap_dist_n10\" : tfidf_umapdist_matrix_dict_n10,\n",
    "    \n",
    "    \"umap_dist_n20\": umapdist_matrix_dict_n20,\n",
    "    \n",
    "    \"count_cos\": count_cos_matrix_dict,\n",
    "    \"tfidf_cos\": tfidf_cos_matrix_dict,\n",
    "}\n",
    "\n",
    "# each radius contains the cumsum of the previous radiusses\n",
    "CUMULATIVE_MATRIX_DATA = {\n",
    "    \"umap_dist_n2\": get_cumsum_dict(umapdist_matrix_dict_n2),\n",
    "    \"tfidf_umap_dist_n2\" : get_cumsum_dict(tfidf_umapdist_matrix_dict_n2),\n",
    "    \n",
    "    \"umap_dist_n10\": get_cumsum_dict(umapdist_matrix_dict_n10),\n",
    "    \"tfidf_umap_dist_n10\" : get_cumsum_dict(tfidf_umapdist_matrix_dict_n10),\n",
    "    \n",
    "    \"umap_dist_n20\": get_cumsum_dict(umapdist_matrix_dict_n20),\n",
    "    \n",
    "    \"count_cos\": get_cumsum_dict(count_cos_matrix_dict),\n",
    "    \"tfidf_cos\": get_cumsum_dict(tfidf_cos_matrix_dict),\n",
    "}\n",
    "\n",
    "# sort based on the cumsums\n",
    "SORTED_IDX_DATA = {\n",
    "    \"umap_dist_n2\": sorted_idx_dict(CUMULATIVE_MATRIX_DATA[\"umap_dist_n2\"], max_first=False),\n",
    "    \"tfidf_umap_dist_n2\": sorted_idx_dict(CUMULATIVE_MATRIX_DATA[\"tfidf_umap_dist_n2\"], max_first=False),\n",
    "    \n",
    "    \"umap_dist_n10\": sorted_idx_dict(CUMULATIVE_MATRIX_DATA[\"umap_dist_n10\"], max_first=False),\n",
    "    \"tfidf_umap_dist_n10\": sorted_idx_dict(CUMULATIVE_MATRIX_DATA[\"tfidf_umap_dist_n10\"], max_first=False),\n",
    "    \n",
    "    \"umap_dist_n20\": sorted_idx_dict(CUMULATIVE_MATRIX_DATA[\"umap_dist_n20\"], max_first=False),\n",
    "    \n",
    "    \"count_cos\": sorted_idx_dict(CUMULATIVE_MATRIX_DATA[\"count_cos\"], max_first=True),\n",
    "    \"tfidf_cos\": sorted_idx_dict(CUMULATIVE_MATRIX_DATA[\"tfidf_cos\"], max_first=True),\n",
    "}\n",
    " \n",
    "MAX_SHOW_RADIUS = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34ac870",
   "metadata": {},
   "source": [
    "#### Array Data [fitness]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da22a419",
   "metadata": {},
   "source": [
    "TODO: entropy?\n",
    "TODO: KDE on the umap?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876208e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "# def calculate_inverse_density_fitness(umap_embeddings, bandwidth=0.1):\n",
    "#     \"\"\"\n",
    "#     Calculates fitness based on the inverse of local density.\n",
    "#     Higher Fitness = Sparser Region = More Unique.\n",
    "#     \"\"\"\n",
    "#     # 1. Initialize KDE Model\n",
    "#     # bandwidth is crucial: smaller = more localized density, larger = smoother.\n",
    "#     kde = KernelDensity(kernel='gaussian', bandwidth=bandwidth)\n",
    "    \n",
    "#     # 2. Fit the model to the 2D/3D embeddings\n",
    "#     kde.fit(umap_embeddings)\n",
    "    \n",
    "#     # 3. Score samples to get the log-probability density\n",
    "#     # log_density is usually preferred for numerical stability\n",
    "#     log_density = kde.score_samples(umap_embeddings)\n",
    "    \n",
    "#     # 4. Convert Log-Density to Density\n",
    "#     density = np.exp(log_density)\n",
    "    \n",
    "#     # 5. Calculate Inverse Density Fitness\n",
    "#     # Add a tiny epsilon to prevent division by zero\n",
    "#     fitness_inverse_density = 1.0 / (density + 1e-6)\n",
    "    \n",
    "#     return fitness_inverse_density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2837927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitness (1d collapsed data) ---\n",
    "FITNESS_DATA = {\n",
    "    'umapdist_fitness_n2': ctk.matrix_dict_applier(umapdist_matrix_dict_n2, apply_collapse_to_fitness),\n",
    "    'tfidf_umapdist_fitness_n2': ctk.matrix_dict_applier(tfidf_umapdist_matrix_dict_n2, apply_collapse_to_fitness),\n",
    "    \n",
    "    'umapdist_fitness_n10': ctk.matrix_dict_applier(umapdist_matrix_dict_n10, apply_collapse_to_fitness),\n",
    "    'tfidf_umapdist_fitness_n10': ctk.matrix_dict_applier(tfidf_umapdist_matrix_dict_n10, apply_collapse_to_fitness),\n",
    "    \n",
    "    'count_cos_fitness': ctk.matrix_dict_applier(count_cos_matrix_dict, apply_collapse_to_fitness),\n",
    "    'tfidf_cos_fitness': ctk.matrix_dict_applier(tfidf_cos_matrix_dict, apply_collapse_to_fitness),\n",
    "}\n",
    "\n",
    "CUMULATIVE_FITNESS_DATA = {\n",
    "    'umapdist_fitness_n2': get_cumsum_dict(FITNESS_DATA['umapdist_fitness_n2']),    \n",
    "    'tfidf_umapdist_fitness_n2': get_cumsum_dict(FITNESS_DATA['tfidf_umapdist_fitness_n2']),\n",
    "    \n",
    "    'umapdist_fitness_n10': get_cumsum_dict(FITNESS_DATA['umapdist_fitness_n10']),\n",
    "    'tfidf_umapdist_fitness_n10': get_cumsum_dict(FITNESS_DATA['tfidf_umapdist_fitness_n10']),\n",
    "    \n",
    "    'count_cos_fitness': get_cumsum_dict(FITNESS_DATA['count_cos_fitness']),\n",
    "    'tfidf_cos_fitness': get_cumsum_dict(FITNESS_DATA['tfidf_cos_fitness']),\n",
    "}\n",
    "\n",
    "SORTED_FITNESS_IDX = {\n",
    "    'umapdist_fitness_n2': sorted_idx_dict(FITNESS_DATA['umapdist_fitness_n2'], max_first=False),\n",
    "    'umapdist_fitness_n10': sorted_idx_dict(FITNESS_DATA['umapdist_fitness_n10'], max_first=False),\n",
    "    \n",
    "    'count_cos_fitness': sorted_idx_dict(FITNESS_DATA['count_cos_fitness'], max_first=True),\n",
    "    'tfidf_cos_fitness': sorted_idx_dict(FITNESS_DATA['tfidf_cos_fitness'], max_first=True),\n",
    "    \n",
    "    'tfidf_umapdist_fitness_n2': sorted_idx_dict(FITNESS_DATA['tfidf_umapdist_fitness_n2'], max_first=False),\n",
    "    'tfidf_umapdist_fitness_n10': sorted_idx_dict(FITNESS_DATA['tfidf_umapdist_fitness_n10'], max_first=False)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166f77e9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19344fb5",
   "metadata": {},
   "source": [
    "### HISTOGRAMS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fc0687",
   "metadata": {},
   "source": [
    "#### Matrix per radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67804300",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_comparison_heatmaps(ALL_MATRIX_DATA, MAX_SHOW_RADIUS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a128072",
   "metadata": {},
   "source": [
    "#### Cumulative matrix per radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0b648f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_comparison_heatmaps(CUMULATIVE_MATRIX_DATA, MAX_SHOW_RADIUS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c14b9b",
   "metadata": {},
   "source": [
    "Interactive Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42cbd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "if POPULATION_SIZE < 20:\n",
    "    plot_interactive_heatmaps(ALL_MATRIX_DATA, POPULATION_IMGS, MAX_SHOW_RADIUS)\n",
    "    plot_interactive_heatmaps(CUMULATIVE_MATRIX_DATA, POPULATION_IMGS, MAX_SHOW_RADIUS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc50eea",
   "metadata": {},
   "source": [
    "### HISTOGRAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972d2fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histograms(ALL_MATRIX_DATA, MAX_SHOW_RADIUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee6a688",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histograms(CUMULATIVE_MATRIX_DATA, MAX_SHOW_RADIUS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de58d18",
   "metadata": {},
   "source": [
    "### 2D EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fe3596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# idxs = np.linspace(0, POPULATION_SIZE - 1, 10, dtype=int).tolist() # if you want to follow?\n",
    "idxs=None\n",
    "console.print(f'following {idxs}')\n",
    "plot_interactive_umap_grid(UMAP_EMBEDDINGS, POPULATION_IMGS, MAX_SHOW_RADIUS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb44033b",
   "metadata": {},
   "source": [
    "### DYNAMIC ROBOT POSTER VIEWER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884f5caa",
   "metadata": {},
   "source": [
    "#### Most Similar Per Radius per metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5eb340",
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_rank = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9624ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rows_for_radii(\n",
    "    cumulative_data=CUMULATIVE_MATRIX_DATA,\n",
    "    sorted_data=SORTED_IDX_DATA,\n",
    "    population_images=POPULATION_IMGS,\n",
    "    max_radius=MAX_SHOW_RADIUS,\n",
    "    pair_rank=similar_rank,\n",
    "    main_title=f\"Comparison Rank {np.abs(similar_rank)} (Most Similar)\"  \n",
    ")\n",
    "\n",
    "similar_rank += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a9547a",
   "metadata": {},
   "source": [
    "#### Least Similar Per Radius per metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca0c947",
   "metadata": {},
   "outputs": [],
   "source": [
    "dif_rank = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194bfb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rows_for_radii(\n",
    "    cumulative_data=CUMULATIVE_MATRIX_DATA,\n",
    "    sorted_data=SORTED_IDX_DATA,\n",
    "    population_images=POPULATION_IMGS,\n",
    "    max_radius=MAX_SHOW_RADIUS,\n",
    "    pair_rank=dif_rank,\n",
    "    main_title=f\"Comparison Rank {np.abs(dif_rank)} (Least Similar)\",\n",
    "    # plot_up_to=True \n",
    ")\n",
    "\n",
    "dif_rank -= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f06cb29",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ebb494",
   "metadata": {},
   "source": [
    "### FITNESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641bd8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histograms(FITNESS_DATA, MAX_SHOW_RADIUS, bins=POPULATION_SIZE//3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9538aef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histograms(CUMULATIVE_FITNESS_DATA, MAX_SHOW_RADIUS, bins=POPULATION_SIZE//3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83a1907",
   "metadata": {},
   "source": [
    "TFIDF R3 CLUSTERING VERY COOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f62c90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = SORTED_FITNESS_IDX['count_cos_fitness'][4][:3]\n",
    "console.print(f'following {idxs}')\n",
    "plot_interactive_umap_grid(UMAP_EMBEDDINGS, POPULATION_IMGS, MAX_SHOW_RADIUS, follow_idx_list=idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b584f80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = SORTED_FITNESS_IDX['count_cos_fitness'][4][-5:]\n",
    "console.print(f'following {idxs}')\n",
    "plot_interactive_umap_grid(UMAP_EMBEDDINGS, POPULATION_IMGS, MAX_SHOW_RADIUS, follow_idx_list=idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4dd3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_rank = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f62c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rows_for_radii(\n",
    "    cumulative_data=CUMULATIVE_FITNESS_DATA,\n",
    "    sorted_data=SORTED_FITNESS_IDX,\n",
    "    population_images=POPULATION_IMGS,\n",
    "    max_radius=MAX_SHOW_RADIUS,\n",
    "    pair_rank=fit_rank,\n",
    "    main_title=f\"Top {np.abs(fit_rank) + 1} Diverse\",\n",
    "    plot_up_to=True \n",
    ")\n",
    "\n",
    "fit_rank += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dfd52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "unfit_rank = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d37dc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rows_for_radii(\n",
    "    cumulative_data=CUMULATIVE_FITNESS_DATA,\n",
    "    sorted_data=SORTED_FITNESS_IDX,\n",
    "    population_images=POPULATION_IMGS,\n",
    "    max_radius=MAX_SHOW_RADIUS,\n",
    "    pair_rank=unfit_rank,\n",
    "    main_title=f\"Least {np.abs(unfit_rank) + 1} Diverse\",\n",
    "    plot_up_to=True \n",
    ")\n",
    "\n",
    "unfit_rank -= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba332c6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936bfa83",
   "metadata": {},
   "source": [
    "### arbitrary tests?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e3af79",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = [11, 32]\n",
    "console.print(f'following {idxs}')\n",
    "plot_interactive_umap_grid(UMAP_EMBEDDINGS, POPULATION_IMGS, MAX_SHOW_RADIUS, follow_idx_list=idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e52db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "console.print(COUNT_MATRIX_DICT[0][11])\n",
    "console.print(COUNT_MATRIX_DICT[0][32])\n",
    "console.print(COUNT_MATRIX_DICT[0][84])\n",
    "console.print(COUNT_MATRIX_DICT[0][15])\n",
    "\n",
    "\n",
    "console.print(SUBTREES[11])\n",
    "console.print(SUBTREES[32])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
